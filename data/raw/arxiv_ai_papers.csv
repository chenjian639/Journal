id,title,abstract,authors,journal,year,published_date,categories
2511.07419v1,"Routing Manifold Alignment Improves Generalization of Mixture-of-Experts
  LLMs","Sparse Mixture-of-Experts (MoE) have been widely adopted in recent large
language models since it can efficiently scale up the model capability without
increasing the inference cost. However, evaluations on broad downstream tasks
reveal a consistent suboptimality of the routers in existing MoE LLMs, which
results in a severe performance gap (e.g., 10-20% in accuracy) to the optimal
routing. In this paper, we show that aligning the manifold of routing weights
with that of task embedding can effectively reduce the gap and improve MoE
LLMs' generalization performance. Our method, ""Routing Manifold Alignment
(RoMA)"", introduces an additional manifold regularization term in the
post-training objective and only requires lightweight finetuning of routers
(with other parameters frozen). Specifically, the regularization encourages the
routing weights of each sample to be close to those of its successful neighbors
(whose routing weights lead to correct answers) in a task embedding space.
Consequently, samples targeting similar tasks will share similar expert choices
across layers. Building such bindings between tasks and experts over different
samples is essential to achieve better generalization. Moreover, RoMA
demonstrates the advantage of unifying the task understanding (by embedding
models) with solution generation (by MoE LLMs). In experiments, we finetune
routers in OLMoE, DeepSeekMoE, and Qwen3-MoE using RoMA. Evaluations on diverse
benchmarks and extensive comparisons with baselines show the substantial
improvement brought by RoMA.","Zhongyang Li, Ziyue Li, Tianyi Zhou",arXiv,2025,2025-11-10 18:59:53+00:00,cs.LG
2511.07417v1,Language Generation with Infinite Contamination,"We study language generation in the limit, where an algorithm observes an
adversarial enumeration of strings from an unknown target language $K$ and must
eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan
[KM24] proved that generation is achievable in surprisingly general settings.
But their generator suffers from ``mode collapse,'' producing from an
ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25]
require the generator's output to be ``dense'' in the target language. They
showed that generation with density, surprisingly, remains achievable at the
same generality.
  Both results assume perfect data: no noisy insertions and no omissions. This
raises a central question: how much contamination can generation tolerate?
Recent works made partial progress on this question by studying (non-dense)
generation with either finite amounts of noise (but no omissions) or omissions
(but no noise).
  We characterize robustness under contaminated enumerations: 1. Generation
under Contamination: Language generation in the limit is achievable for all
countable collections iff the fraction of contaminated examples converges to
zero. When this fails, we characterize which collections are generable. 2.
Dense Generation under Contamination: Dense generation is strictly less robust
to contamination than generation. As a byproduct, we resolve an open question
of Raman and Raman [ICML25] by showing that generation is possible with only
membership oracle access under finitely many contaminated examples.
  Finally, we introduce a beyond-worst-case model inspired by curriculum
learning and prove that dense generation is achievable even with infinite
contamination provided the fraction of contaminated examples converges to zero.
This suggests curriculum learning may be crucial for learning from noisy web
data.","Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou",arXiv,2025,2025-11-10 18:59:39+00:00,"stat.ML, cs.AI, cs.CL, cs.DS, cs.LG"
2511.07416v1,Robot Learning from a Physical World Model,"We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.","Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang",arXiv,2025,2025-11-10 18:59:07+00:00,"cs.RO, cs.AI, cs.CV"
2511.07414v1,Wasserstein-Cramér-Rao Theory of Unbiased Estimation,"The quantity of interest in the classical Cram\'er-Rao theory of unbiased
estimation (e.g., the Cram\'er-Rao lower bound, its exact attainment for
exponential families, and asymptotic efficiency of maximum likelihood
estimation) is the variance, which represents the instability of an estimator
when its value is compared to the value for an independently-sampled data set
from the same distribution. In this paper we are interested in a quantity which
represents the instability of an estimator when its value is compared to the
value for an infinitesimal additive perturbation of the original data set; we
refer to this as the ""sensitivity"" of an estimator. The resulting theory of
sensitivity is based on the Wasserstein geometry in the same way that the
classical theory of variance is based on the Fisher-Rao (equivalently,
Hellinger) geometry, and this insight allows us to determine a collection of
results which are analogous to the classical case: a Wasserstein-Cram\'er-Rao
lower bound for the sensitivity of any unbiased estimator, a characterization
of models in which there exist unbiased estimators achieving the lower bound
exactly, and some concrete results that show that the Wasserstein projection
estimator achieves the lower bound asymptotically. We use these results to
treat many statistical examples, sometimes revealing new optimality properties
for existing estimators and other times revealing entirely new estimators.","Nicolás García Trillos, Adam Quinn Jaffe, Bodhisattva Sen",arXiv,2025,2025-11-10 18:58:18+00:00,"math.ST, math.OC, stat.ME, stat.ML, stat.TH, 62B11, 62F10, 62F12, 35Q49, 49Q22"
2511.07413v1,DigiData: Training and Evaluating General-Purpose Mobile Control Agents,"AI agents capable of controlling user interfaces have the potential to
transform human interaction with digital devices. To accelerate this
transformation, two fundamental building blocks are essential: high-quality
datasets that enable agents to achieve complex and human-relevant goals, and
robust evaluation methods that allow researchers and practitioners to rapidly
enhance agent performance. In this paper, we introduce DigiData, a large-scale,
high-quality, diverse, multi-modal dataset designed for training mobile control
agents. Unlike existing datasets, which derive goals from unstructured
interactions, DigiData is meticulously constructed through comprehensive
exploration of app features, resulting in greater diversity and higher goal
complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating
mobile control agents on real-world complex tasks. We demonstrate that the
commonly used step-accuracy metric falls short in reliably assessing mobile
control agents and, to address this, we propose dynamic evaluation protocols
and AI-powered evaluations as rigorous alternatives for agent assessment. Our
contributions aim to significantly advance the development of mobile control
agents, paving the way for more intuitive and effective human-device
interactions.","Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan, Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, Nitin Kamra, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer, Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway, Joseph Tighe",arXiv,2025,2025-11-10 18:57:35+00:00,"cs.AI, cs.CL, cs.HC, cs.LG"
2511.07412v1,"TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for
  Embodied AI Research","Developing embodied AI for intelligent surgical systems requires safe,
controllable environments for continual learning and evaluation. However,
safety regulations and operational constraints in operating rooms (ORs) limit
embodied agents from freely perceiving and interacting in realistic settings.
Digital twins provide high-fidelity, risk-free environments for exploration and
training. How we may create photorealistic and dynamic digital representations
of ORs that capture relevant spatial, visual, and behavioral complexity remains
unclear. We introduce TwinOR, a framework for constructing photorealistic,
dynamic digital twins of ORs for embodied AI research. The system reconstructs
static geometry from pre-scan videos and continuously models human and
equipment motion through multi-view perception of OR activities. The static and
dynamic components are fused into an immersive 3D environment that supports
controllable simulation and embodied exploration. The proposed framework
reconstructs complete OR geometry with centimeter level accuracy while
preserving dynamic interaction across surgical workflows, enabling realistic
renderings and a virtual playground for embodied AI systems. In our
experiments, TwinOR simulates stereo and monocular sensor streams for geometry
understanding and visual localization tasks. Models such as FoundationStereo
and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
reported accuracy on real indoor datasets, demonstrating that TwinOR provides
sensor-level realism sufficient for perception and localization challenges. By
establishing a real-to-sim pipeline for constructing dynamic, photorealistic
digital twins of OR environments, TwinOR enables the safe, scalable, and
data-efficient development and benchmarking of embodied AI, ultimately
accelerating the deployment of embodied AI from sim-to-real.","Han Zhang, Yiqing Shen, Roger D. Soberanis-Mukul, Ankita Ghosh, Hao Ding, Lalithkumar Seenivasan, Jose L. Porras, Zhekai Mao, Chenjia Li, Wenjie Xiao, Lonny Yarmus, Angela Christine Argento, Masaru Ishii, Mathias Unberath",arXiv,2025,2025-11-10 18:57:09+00:00,"cs.CV, cs.RO"
2511.07409v1,DIMO: Diverse 3D Motion Generation for Arbitrary Objects,"We present DIMO, a generative approach capable of generating diverse 3D
motions for arbitrary objects from a single image. The core idea of our work is
to leverage the rich priors in well-trained video models to extract the common
motion patterns and then embed them into a shared low-dimensional latent space.
Specifically, we first generate multiple videos of the same object with diverse
motions. We then embed each motion into a latent vector and train a shared
motion decoder to learn the distribution of motions represented by a structured
and compact motion representation, i.e., neural key point trajectories. The
canonical 3D Gaussians are then driven by these key points and fused to model
the geometry and appearance. During inference time with learned latent space,
we can instantly sample diverse 3D motions in a single-forward pass and support
several interesting applications including 3D motion interpolation and
language-guided motion generation. Our project page is available at
https://linzhanm.github.io/dimo.","Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis",arXiv,2025,2025-11-10 18:56:49+00:00,cs.CV
2511.07407v1,Unified Humanoid Fall-Safety Policy from a Few Demonstrations,"Falling is an inherent risk of humanoid mobility. Maintaining stability is
thus a primary safety focus in robot control and learning, yet no existing
approach fully averts loss of balance. When instability does occur, prior work
addresses only isolated aspects of falling: avoiding falls, choreographing a
controlled descent, or standing up afterward. Consequently, humanoid robots
lack integrated strategies for impact mitigation and prompt recovery when real
falls defy these scripts. We aim to go beyond keeping balance to make the
entire fall-and-recovery process safe and autonomous: prevent falls when
possible, reduce impact when unavoidable, and stand up when fallen. By fusing
sparse human demonstrations with reinforcement learning and an adaptive
diffusion-based memory of safe reactions, we learn adaptive whole-body
behaviors that unify fall prevention, impact mitigation, and rapid recovery in
one policy. Experiments in simulation and on a Unitree G1 demonstrate robust
sim-to-real transfer, lower impact forces, and consistently fast recovery
across diverse disturbances, pointing towards safer, more resilient humanoids
in real environments. Videos are available at https://firm2025.github.io/.","Zhengjie Xu, Ye Li, Kwan-yee Lin, Stella X. Yu",arXiv,2025,2025-11-10 18:56:31+00:00,cs.RO
2511.07406v1,Entangled Schrödinger Bridge Matching,"Simulating trajectories of multi-particle systems on complex energy
landscapes is a central task in molecular dynamics (MD) and drug discovery, but
remains challenging at scale due to computationally expensive and long
simulations. Previous approaches leverage techniques such as flow or
Schr\""odinger bridge matching to implicitly learn joint trajectories through
data snapshots. However, many systems, including biomolecular systems and
heterogeneous cell populations, undergo dynamic interactions that evolve over
their trajectory and cannot be captured through static snapshots. To close this
gap, we introduce Entangled Schr\""odinger Bridge Matching (EntangledSBM), a
framework that learns the first- and second-order stochastic dynamics of
interacting, multi-particle systems where the direction and magnitude of each
particle's path depend dynamically on the paths of the other particles. We
define the Entangled Schr\""odinger Bridge (EntangledSB) problem as solving a
coupled system of bias forces that entangle particle velocities. We show that
our framework accurately simulates heterogeneous cell populations under
perturbations and rare transitions in high-dimensional biomolecular systems.","Sophia Tang, Yinuo Zhang, Pranam Chatterjee",arXiv,2025,2025-11-10 18:55:35+00:00,"cs.LG, q-bio.BM"
2511.07405v1,"SPOT: An Annotated French Corpus and Benchmark for Detecting Critical
  Interventions in Online Conversations","We introduce SPOT (Stopping Points in Online Threads), the first annotated
corpus translating the sociological concept of stopping point into a
reproducible NLP task. Stopping points are ordinary critical interventions that
pause or redirect online discussions through a range of forms (irony, subtle
doubt or fragmentary arguments) that frameworks like counterspeech or social
correction often overlook. We operationalize this concept as a binary
classification task and provide reliable annotation guidelines. The corpus
contains 43,305 manually annotated French Facebook comments linked to URLs
flagged as false information by social media users, enriched with contextual
metadata (article, post, parent comment, page or group, and source). We
benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs
under various prompting strategies. Results show that fine-tuned encoders
outperform prompted LLMs in F1 score by more than 10 percentage points,
confirming the importance of supervised learning for emerging non-English
social media tasks. Incorporating contextual metadata further improves encoder
models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along
with the annotation guidelines and code in our code repository, to foster
transparency and reproducible research.","Manon Berriche, Célia Nouri, Chloé Clavel, Jean-Philippe Cointet",arXiv,2025,2025-11-10 18:54:40+00:00,"cs.CL, cs.CY"
2511.07403v1,"SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial
  Rewards","Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.","Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark",arXiv,2025,2025-11-10 18:52:47+00:00,"cs.CV, cs.AI, cs.CL, cs.LG"
2511.07399v1,"StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video
  Generation","Generative models are reshaping the live-streaming industry by redefining how
content is created, styled, and delivered. Previous image-based streaming
diffusion models have powered efficient and creative live streaming products
but have hit limits on temporal consistency due to the foundation of
image-based designs. Recent advances in video diffusion have markedly improved
temporal consistency and sampling efficiency for offline generation. However,
offline generation systems primarily optimize throughput by batching large
workloads. In contrast, live online streaming operates under strict
service-level objectives (SLOs): time-to-first-frame must be minimal, and every
frame must meet a per-frame deadline with low jitter. Besides, scalable
multi-GPU serving for real-time streams remains largely unresolved so far. To
address this, we present StreamDiffusionV2, a training-free pipeline for
interactive live streaming with video diffusion models. StreamDiffusionV2
integrates an SLO-aware batching scheduler and a block scheduler, together with
a sink-token--guided rolling KV cache, a motion-aware noise controller, and
other system-level optimizations. Moreover, we introduce a scalable pipeline
orchestration that parallelizes the diffusion process across denoising steps
and network layers, achieving near-linear FPS scaling without violating latency
guarantees. The system scales seamlessly across heterogeneous GPU environments
and supports flexible denoising steps (e.g., 1--4), enabling both
ultra-low-latency and higher-quality modes. Without TensorRT or quantization,
StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS
with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four
H100 GPUs, making state-of-the-art generative live streaming practical and
accessible--from individual creators to enterprise-scale platforms.","Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li, Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt Keutzer, Akio Kodaira, Chenfeng Xu",arXiv,2025,2025-11-10 18:51:28+00:00,"cs.CV, cs.LG"
2511.07398v1,Solving bilevel optimization via sequential minimax optimization,"In this paper we propose a sequential minimax optimization (SMO) method for
solving a class of constrained bilevel optimization problems in which the
lower-level part is a possibly nonsmooth convex optimization problem, while the
upper-level part is a possibly nonconvex optimization problem. Specifically,
SMO applies a first-order method to solve a sequence of minimax subproblems,
which are obtained by employing a hybrid of modified augmented Lagrangian and
penalty schemes on the bilevel optimization problems. Under suitable
assumptions, we establish an operation complexity of
$O(\varepsilon^{-7}\log\varepsilon^{-1})$ and
$O(\varepsilon^{-6}\log\varepsilon^{-1})$, measured in terms of fundamental
operations, for SMO in finding an $\varepsilon$-KKT solution of the bilevel
optimization problems with merely convex and strongly convex lower-level
objective functions, respectively. The latter result improves the previous
best-known operation complexity by a factor of $\varepsilon^{-1}$. Preliminary
numerical results demonstrate significantly superior computational performance
compared to the recently developed first-order penalty method.","Zhaosong Lu, Sanyou Mei",arXiv,2025,2025-11-10 18:51:05+00:00,"math.OC, cs.LG, cs.NA, math.NA, stat.ML, 90C26, 90C30, 90C47, 90C99, 65K05"
2511.07397v1,ConvFill: Model Collaboration for Responsive Conversational Voice Agents,"Deploying conversational voice agents with large language models faces a
critical challenge: cloud-based foundation models provide deep reasoning and
domain knowledge but introduce latency that disrupts natural conversation,
while on-device models respond immediately but lack sophistication. We propose
conversational infill, a task where a lightweight on-device model generates
contextually appropriate dialogue while seamlessly incorporating streaming
knowledge from a powerful backend model. This approach decouples response
latency from model capability, enabling systems that feel responsive while
accessing the full power of large-scale models. We present ConvFill, a 360M
parameter model trained on synthetic multi-domain conversations. Evaluation
across multiple backend models shows that conversational infill can be
successfully learned, with ConvFill achieving accuracy improvements of 36-42%
over standalone small models of the same size while consistently retaining
sub-200ms response latencies. Our results demonstrate the promise of this
approach for building on-device conversational agents that are both immediately
responsive and knowledgeable.","Vidya Srinivas, Zachary Englhardt, Maximus Powers, Shwetak Patel, Vikram Iyer",arXiv,2025,2025-11-10 18:50:30+00:00,cs.CL
2511.07396v1,"C3PO: Optimized Large Language Model Cascades with Probabilistic Cost
  Constraints for Reasoning","Large language models (LLMs) have achieved impressive results on complex
reasoning tasks, but their high inference cost remains a major barrier to
real-world deployment. A promising solution is to use cascaded inference, where
small, cheap models handle easy queries, and only the hardest examples are
escalated to more powerful models. However, existing cascade methods typically
rely on supervised training with labeled data, offer no theoretical
generalization guarantees, and provide limited control over test-time
computational cost. We introduce C3PO (Cost Controlled Cascaded Prediction
Optimization), a self-supervised framework for optimizing LLM cascades under
probabilistic cost constraints. By focusing on minimizing regret with respect
to the most powerful model (MPM), C3PO avoids the need for labeled data by
constructing a cascade using only unlabeled model outputs. It leverages
conformal prediction to bound the probability that inference cost exceeds a
user-specified budget. We provide theoretical guarantees on both cost control
and generalization error, and show that our optimization procedure is effective
even with small calibration sets. Empirically, C3PO achieves state-of-the-art
performance across a diverse set of reasoning benchmarks including GSM8K,
MATH-500, BigBench-Hard and AIME, outperforming strong LLM cascading baselines
in both accuracy and cost-efficiency. Our results demonstrate that principled,
label-free cascade optimization can enable scalable LLM deployment.","Antonios Valkanas, Soumyasundar Pal, Pavel Rumiantsev, Yingxue Zhang, Mark Coates",arXiv,2025,2025-11-10 18:50:27+00:00,cs.LG
2511.07391v1,Extending QAOA-GPT to Higher-Order Quantum Optimization Problems,"The recently proposed QAOA-GPT framework demonstrated that generative
pre-trained transformers can learn mappings between problem graphs and
optimized quantum circuits for the Quantum Approximate Optimization Algorithm
(QAOA). In this work, we extend QAOA-GPT to Higher-Order Unconstrained Binary
Optimization (HUBO) problems, focusing on spin-glass Hamiltonians that include
cubic interaction terms. Using FEATHER graph embeddings to encode topological
information, we train the model on graph-circuit pairs generated via ADAPT-QAOA
and evaluate its performance on 8- and 16-qubit instances embedded on heavy-hex
lattices. The generative model produces adaptive QAOA-like circuits and
corresponding variational parameters in a single forward pass, bypassing the
iterative classical optimization loop. The generated circuits achieve average
approximation ratios exceeding 0.95, closely matching classically optimized
ADAPT-QAOA results, while maintaining consistent parameter distributions across
circuit depths. These results demonstrate that QAOA-GPT generalizes effectively
to higher-order cost Hamiltonians and complex energy landscapes, establishing
generative modeling as a scalable pathway toward autonomous variational circuit
design and quantum algorithm discovery in the NISQ era.","Leanto Sunny, Abhinav Rijal, George Siopsis",arXiv,2025,2025-11-10 18:46:38+00:00,quant-ph
2511.07390v1,A Diffusion Model to Shrink Proteins While Maintaining Their Function,"Many proteins useful in modern medicine or bioengineering are challenging to
make in the lab, fuse with other proteins in cells, or deliver to tissues in
the body, because their sequences are too long. Shortening these sequences
typically involves costly, time-consuming experimental campaigns. Ideally, we
could instead use modern models of massive databases of sequences from nature
to learn how to propose shrunken proteins that resemble sequences found in
nature. Unfortunately, these models struggle to efficiently search the
combinatorial space of all deletions, and are not trained with inductive biases
to learn how to delete. To address this gap, we propose SCISOR, a novel
discrete diffusion model that deletes letters from sequences to generate
protein samples that resemble those found in nature. To do so, SCISOR trains a
de-noiser to reverse a forward noising process that adds random insertions to
natural sequences. As a generative model, SCISOR fits evolutionary sequence
data competitively with previous large models. In evaluation, SCISOR achieves
state-of-the-art predictions of the functional effects of deletions on
ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein
sequences, and show that its suggested deletions result in significantly more
realistic proteins and more often preserve functional motifs than previous
models of evolutionary sequences.","Ethan Baron, Alan N. Amin, Ruben Weitzman, Debora Marks, Andrew Gordon Wilson",arXiv,2025,2025-11-10 18:46:24+00:00,"cs.LG, q-bio.QM"
2511.07388v1,Policy Learning for Perturbance-wise Linear Quadratic Control Problem,"We study finite horizon linear quadratic control with additive noise in a
perturbancewise framework that unifies the classical model, a constraint
embedded affine policy class, and a distributionally robust formulation with a
Wasserstein ambiguity set. Based on an augmented affine representation, we
model feasibility as an affine perturbation and unknown noise as distributional
perturbation from samples, thereby addressing constrained implementation and
model uncertainty in a single scheme. First, we construct an implementable
policy gradient method that accommodates nonzero noise means estimated from
data. Second, we analyze its convergence under constant stepsizes chosen as
simple polynomials of problem parameters, ensuring global decrease of the value
function. Finally, numerical studies: mean variance portfolio allocation and
dynamic benchmark tracking on real data, validating stable convergence and
illuminating sensitivity tradeoffs across horizon length, trading cost
intensity, state penalty scale, and estimation window.","Haoran Zhang, Wenhao Zhang, Xianping Wu",arXiv,2025,2025-11-10 18:45:02+00:00,math.OC
2511.07384v1,"Teaching Pretrained Language Models to Think Deeper with Retrofitted
  Recurrence","Recent advances in depth-recurrent language models show that recurrence can
decouple train-time compute and parameter count from test-time compute. In this
work, we study how to convert existing pretrained non-recurrent language models
into depth-recurrent models. We find that using a curriculum of recurrences to
increase the effective depth of the model over the course of training preserves
performance while reducing total computational cost. In our experiments, on
mathematics, we observe that converting pretrained models to recurrent ones
results in better performance at a given compute budget than simply
post-training the original non-recurrent language model.","Sean McLeish, Ang Li, John Kirchenbauer, Dayal Singh Kalra, Brian R. Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Jonas Geiping, Tom Goldstein, Micah Goldblum",arXiv,2025,2025-11-10 18:43:07+00:00,"cs.CL, cs.AI, cs.LG"
2511.07381v1,Residual Rotation Correction using Tactile Equivariance,"Visuotactile policy learning augments vision-only policies with tactile
input, facilitating contact-rich manipulation. However, the high cost of
tactile data collection makes sample efficiency the key requirement for
developing visuotactile policies. We present EquiTac, a framework that exploits
the inherent SO(2) symmetry of in-hand object rotation to improve sample
efficiency and generalization for visuotactile policy learning. EquiTac first
reconstructs surface normals from raw RGB inputs of vision-based tactile
sensors, so rotations of the normal vector field correspond to in-hand object
rotations. An SO(2)-equivariant network then predicts a residual rotation
action that augments a base visuomotor policy at test time, enabling real-time
rotation correction without additional reorientation demonstrations. On a real
robot, EquiTac accurately achieves robust zero-shot generalization to unseen
in-hand orientations with very few training samples, where baselines fail even
with more training data. To our knowledge, this is the first tactile learning
method to explicitly encode tactile equivariance for policy learning, yielding
a lightweight, symmetry-aware module that improves reliability in contact-rich
tasks.","Yizhe Zhu, Zhang Ye, Boce Hu, Haibo Zhao, Yu Qi, Dian Wang, Robert Platt",arXiv,2025,2025-11-10 18:41:34+00:00,"cs.RO, 14J60 (Primary) 14F05, 14J26 (Secondary), 14J60 (Primary) 14F05,
  14J26 (Secondary)"
2511.07379v1,"LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic
  Graphs","Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes
domains, such as financial forecasting, recommendation systems, and fraud
detection. However, their susceptibility to poisoning attacks poses a critical
security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a
novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades
TGNN performance by an average of 29.47% across 4 widely benchmark datasets and
4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage
approach: (1) sparsify the graph by removing high-impact edges using any of the
16 tested temporal importance metrics, (2) strategically replace removed edges
with adversarial negatives via LoReTTA's novel degree-preserving negative
sampling algorithm. Our plug-and-play design eliminates the need for expensive
surrogate models while adhering to realistic unnoticeability constraints.
LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8%
on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains
undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA
adversarial defense training methods, establishing its effectiveness,
unnoticeability, and robustness.","Himanshu Pal, Venkata Sai Pranav Bachina, Ankit Gangwal, Charu Sharma",arXiv,2025,2025-11-10 18:41:02+00:00,"cs.LG, cs.AI"
2511.07378v1,"Transformers Provably Learn Chain-of-Thought Reasoning with Length
  Generalization","The ability to reason lies at the core of artificial intelligence (AI), and
challenging problems usually call for deeper and longer reasoning to tackle. A
crucial question about AI reasoning is whether models can extrapolate learned
reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In
this work, we present a theoretical analysis of transformers learning on
synthetic state-tracking tasks with gradient descent. We mathematically prove
how the algebraic structure of state-tracking problems governs the degree of
extrapolation of the learned CoT. Specifically, our theory characterizes the
length generalization of transformers through the mechanism of attention
concentration, linking the retrieval robustness of the attention layer to the
state-tracking task structure of long-context reasoning. Moreover, for
transformers with limited reasoning length, we prove that a recursive
self-training scheme can progressively extend the range of solvable problem
lengths. To our knowledge, we provide the first optimization guarantee that
constant-depth transformers provably learn $\mathsf{NC}^1$-complete problems
with CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$,
unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails.
Finally, we present a broad set of experiments supporting our theoretical
results, confirming the length generalization behaviors and the mechanism of
attention concentration.","Yu Huang, Zixin Wen, Aarti Singh, Yuejie Chi, Yuxin Chen",arXiv,2025,2025-11-10 18:40:24+00:00,"cs.LG, cs.AI, math.OC, stat.ML"
2511.07377v1,Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion,"LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.","June Moh Goo, Zichao Zeng, Jan Boehm",arXiv,2025,2025-11-10 18:38:15+00:00,"cs.CV, cs.AI, cs.RO"
2511.07372v1,"Provable Benefit of Curriculum in Transformer Tree-Reasoning
  Post-Training","Recent curriculum techniques in the post-training stage of LLMs have been
widely observed to outperform non-curriculum approaches in enhancing reasoning
performance, yet a principled understanding of why and to what extent they work
remains elusive. To address this gap, we develop a theoretical framework
grounded in the intuition that progressively learning through manageable steps
is more efficient than directly tackling a hard reasoning task, provided each
stage stays within the model's effective competence. Under mild complexity
conditions linking consecutive curriculum stages, we show that curriculum
post-training avoids the exponential complexity bottleneck.
  To substantiate this result, drawing insights from the Chain-of-Thoughts
(CoTs) solving mathematical problems such as Countdown and parity, we model CoT
generation as a states-conditioned autoregressive reasoning tree, define a
uniform-branching base model to capture pretrained behavior, and formalize
curriculum stages as either depth-increasing (longer reasoning chains) or
hint-decreasing (shorter prefixes) subtasks. Our analysis shows that, under
outcome-only reward signals, reinforcement learning finetuning achieves high
accuracy with polynomial sample complexity, whereas direct learning suffers
from an exponential bottleneck. We further establish analogous guarantees for
test-time scaling, where curriculum-aware querying reduces both reward oracle
calls and sampling cost from exponential to polynomial order.","Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Hau-San Wong, Qingfu Zhang, Taiji Suzuki",arXiv,2025,2025-11-10 18:29:54+00:00,cs.LG
2511.07368v1,"Consistency Is Not Always Correct: Towards Understanding the Role of
  Exploration in Post-Training Reasoning","Foundation models exhibit broad knowledge but limited task-specific
reasoning, motivating post-training strategies such as RLVR and inference
scaling with outcome or process reward models (ORM/PRM). While recent work
highlights the role of exploration and entropy stability in improving pass@K,
empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce
existing tree-like reasoning paths rather than expanding the reasoning scope,
raising the question of why exploration helps at all if no new patterns emerge.
  To reconcile this paradox, we adopt the perspective of Kim et al. (2025),
viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a
symmetry) reasoning steps as low- versus high-probability Markov transitions,
and formalize post-training dynamics through Multi-task Tree-structured Markov
Chains (TMC). In this tractable model, pretraining corresponds to tree
expansion, while post-training corresponds to chain-of-thought reweighting. We
show that several phenomena recently observed in empirical studies arise
naturally in this setting: (1) RLVR induces a squeezing effect, reducing
reasoning entropy and forgetting some correct paths; (2) population rewards of
ORM/PRM encourage consistency rather than accuracy, thereby favoring common
patterns; and (3) certain rare, high-uncertainty reasoning paths by the base
model are responsible for solving hard problem instances.
  Together, these explain why exploration -- even when confined to the base
model's reasoning scope -- remains essential: it preserves access to rare but
crucial reasoning traces needed for difficult cases, which are squeezed out by
RLVR or unfavored by inference scaling. Building on this, we further show that
exploration strategies such as rejecting easy instances and KL regularization
help preserve rare reasoning traces. Empirical simulations corroborate our
theoretical results.","Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang, Hau-San Wong, Taiji Suzuki",arXiv,2025,2025-11-10 18:25:26+00:00,"cs.LG, cs.AI"
2511.07367v1,Machine-Learning Accelerated Calculations of Reduced Density Matrices,"$n$-particle reduced density matrices ($n$-RDMs) play a central role in
understanding correlated phases of matter. Yet the calculation of $n$-RDMs is
often computationally inefficient for strongly-correlated states, particularly
when the system sizes are large. In this work, we propose to use neural network
(NN) architectures to accelerate the calculation of, and even predict, the
$n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs are
often smooth functions over the Brillouin zone (BZ) (certainly true for gapped
states) and are thus interpolable, allowing NNs trained on small-size $n$-RDMs
to predict large-size ones. Building on this intuition, we devise two NNs: (i)
a self-attention NN that maps random RDMs to physical ones, and (ii) a
Sinusoidal Representation Network (SIREN) that directly maps momentum-space
coordinates to RDM values. We test the NNs in three 2D models: the pair-pair
correlation functions of the Richardson model of superconductivity, the
translationally-invariant 1-RDM in a four-band model with short-range
repulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model.
We find that a SIREN trained on a $6\times 6$ momentum mesh can predict the
$18\times 18$ pair-pair correlation function with a relative accuracy of
$0.839$. The NNs trained on $6\times 6 \sim 8\times 8$ meshes can provide
high-quality initial guesses for $50\times 50$ translation-invariant
Hartree-Fock (HF) and $30\times 30$ fully translation-breaking-allowed HF,
reducing the number of iterations required for convergence by up to $91.63\%$
and $92.78\%$, respectively, compared to random initializations. Our results
illustrate the potential of using NN-based methods for interpolable $n$-RDMs,
which might open a new avenue for future research on strongly correlated
phases.","Awwab A. Azam, Lexu Zhao, Jiabin Yu",arXiv,2025,2025-11-10 18:23:34+00:00,"cond-mat.str-el, cs.AI"
2511.07366v1,"UAV-Assisted Resilience in 6G and Beyond Network Energy Saving: A
  Multi-Agent DRL Approach","This paper investigates the unmanned aerial vehicle (UAV)-assisted resilience
perspective in the 6G network energy saving (NES) scenario. More specifically,
we consider multiple ground base stations (GBSs) and each GBS has three
different sectors/cells in the terrestrial networks, and multiple cells are
turned off due to NES or incidents, e.g., disasters, hardware failures, or
outages. To address this, we propose a Multi-Agent Deep Deterministic Policy
Gradient (MADDPG) framework to enable UAV-assisted communication by jointly
optimizing UAV trajectories, transmission power, and user-UAV association under
a sleeping ground base station (GBS) strategy. This framework aims to ensure
the resilience of active users in the network and the long-term operability of
UAVs. Specifically, it maximizes service coverage for users during power
outages or NES zones, while minimizing the energy consumption of UAVs.
Simulation results demonstrate that the proposed MADDPG policy consistently
achieves high coverage ratio across different testing episodes, outperforming
other baselines. Moreover, the MADDPG framework attains the lowest total energy
consumption, with a reduction of approximately 24\% compared to the
conventional all GBS ON configuration, while maintaining a comparable user
service rate. These results confirm the effectiveness of the proposed approach
in achieving a superior trade-off between energy efficiency and service
performance, supporting the development of sustainable and resilient
UAV-assisted cellular networks.","Dao Lan Vy Dinh, Anh Nguyen Thi Mai, Hung Tran, Giang Quynh Le Vu, Tu Dac Ho, Zhenni Pan, Vo Nhan Van, Symeon Chatzinotas, Dinh-Hieu Tran",arXiv,2025,2025-11-10 18:23:03+00:00,"cs.NI, cs.LG"
2511.07365v1,Private Sketches for Linear Regression,"Linear regression is frequently applied in a variety of domains. In order to
improve the efficiency of these methods, various methods have been developed
that compute summaries or \emph{sketches} of the datasets. Certain domains,
however, contain sensitive data which necessitates that the application of
these statistical methods does not reveal private information. Differentially
private (DP) linear regression methods have been developed for mitigating this
problem. These techniques typically involve estimating a noisy version of the
parameter vector. Instead, we propose releasing private sketches of the
datasets. We present differentially private sketches for the problems of least
squares regression, as well as least absolute deviations regression. The
availability of these private sketches facilitates the application of commonly
available solvers for regression, without the risk of privacy leakage.","Shrutimoy Das, Debanuj Nayak, Anirban Dasgupta",arXiv,2025,2025-11-10 18:22:40+00:00,"cs.LG, stat.ML"
2511.07364v1,"Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence
  Estimation for Failure Detection","Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.","Vaibhav Mavi, Shubh Jaroria, Weiqi Sun",arXiv,2025,2025-11-10 18:19:51+00:00,"cs.LG, cs.AI, cs.CL"
2511.07362v1,Inference-Time Scaling of Diffusion Models for Infrared Data Generation,"Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.","Kai A. Horstmann, Maxim Clouser, Kia Khezeli",arXiv,2025,2025-11-10 18:18:38+00:00,"cs.CV, cs.AI, cs.LG"
2511.07347v1,"Walsh-Hadamard Neural Operators for Solving PDEs with Discontinuous
  Coefficients","Neural operators have emerged as powerful tools for learning solution
operators of partial differential equations (PDEs). However, standard spectral
methods based on Fourier transforms struggle with problems involving
discontinuous coefficients due to the Gibbs phenomenon and poor representation
of sharp interfaces. We introduce the Walsh-Hadamard Neural Operator (WHNO),
which leverages Walsh-Hadamard transforms-a spectral basis of rectangular wave
functions naturally suited for piecewise constant fields-combined with
learnable spectral weights that transform low-sequency Walsh coefficients to
capture global dependencies efficiently. We validate WHNO on three problems:
steady-state Darcy flow (preliminary validation), heat conduction with
discontinuous thermal conductivity, and the 2D Burgers equation with
discontinuous initial conditions. In controlled comparisons with Fourier Neural
Operators (FNO) under identical conditions, WHNO demonstrates superior accuracy
with better preservation of sharp solution features at material interfaces.
Critically, we discover that weighted ensemble combinations of WHNO and FNO
achieve substantial improvements over either model alone: for both heat
conduction and Burgers equation, optimal ensembles reduce mean squared error by
35-40 percent and maximum error by up to 25 percent compared to individual
models. This demonstrates that Walsh-Hadamard and Fourier representations
capture complementary aspects of discontinuous PDE solutions, with WHNO
excelling at sharp interfaces while FNO captures smooth features effectively.","Giorrgio M. Cavallazzi, Miguel Perex Cuadrado, Alfredo Pinelli",arXiv,2025,2025-11-10 17:49:20+00:00,"physics.comp-ph, cs.LG"
2511.07343v1,TNT: Improving Chunkwise Training for Test-Time Memorization,"Recurrent neural networks (RNNs) with deep test-time memorization modules,
such as Titans and TTT, represent a promising, linearly-scaling paradigm
distinct from Transformers. While these expressive models do not yet match the
peak performance of state-of-the-art Transformers, their potential has been
largely untapped due to prohibitively slow training and low hardware
utilization. Existing parallelization methods force a fundamental conflict
governed by the chunksize hyperparameter: large chunks boost speed but degrade
performance, necessitating a fixed, suboptimal compromise. To solve this
challenge, we introduce TNT, a novel training paradigm that decouples training
efficiency from inference performance through a two-stage process. Stage one is
an efficiency-focused pre-training phase utilizing a hierarchical memory. A
global module processes large, hardware-friendly chunks for long-range context,
while multiple parallel local modules handle fine-grained details. Crucially,
by periodically resetting local memory states, we break sequential dependencies
to enable massive context parallelization. Stage two is a brief fine-tuning
phase where only the local memory modules are adapted to a smaller,
high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated
on Titans and TTT models, TNT achieves a substantial acceleration in training
speed-up to 17 times faster than the most accurate baseline configuration -
while simultaneously improving model accuracy. This improvement removes a
critical scalability barrier, establishing a practical foundation for
developing expressive RNNs and facilitating future work to close the
performance gap with Transformers.","Zeman Li, Ali Behrouz, Yuan Deng, Peilin Zhong, Praneeth Kacham, Mahdi Karami, Meisam Razaviyayn, Vahab Mirrokni",arXiv,2025,2025-11-10 17:45:09+00:00,"cs.LG, cs.AI"
2511.07339v1,GiBS: Generative Input-side Basis-driven Structures,"Designing large-scale metasurfaces with nonlocal optical effects remains
challenging due to the immense dimensionality and fabrication constraints of
conventional optimization methods. We introduce GiBS (Generative Input-side
Basis-driven Structures), an inverse-design framework that represents the
entire device using a compact set of coefficients from smooth parametric bases
such as Fourier or Chebyshev functions. This formulation compresses the design
space by more than an order of magnitude, enabling efficient optimization of
complex, broadband, and aperiodic geometries. GiBS integrates this
low-dimensional representation with an autoencoder-based manifold-learning
workflow to map the relationship between geometry and optical response,
facilitating rapid exploration, discovery of high-performance designs, and
systematic analysis of fabrication sensitivity. The inherent smoothness of the
basis functions ensures manufacturability while capturing the asymmetry
required for nonlocal optical interactions. We experimentally validated the
framework through the realization of a PEDOT:PSS broadband scattering
metasurface, whose measured response closely matched full-wave simulations
across 500-1100 nm. These results establish GiBS as a scalable, data-efficient,
and fabrication-aware platform for the inverse design of multifunctional
metasurfaces, bridging AI-guided representation learning with experimentally
realizable photonic architectures.","Reza Marzban, Ashkan Zandi, Ali Adibi",arXiv,2025,2025-11-10 17:40:12+00:00,physics.optics
2511.07338v1,DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas,"Simulating human profiles by instilling personas into large language models
(LLMs) is rapidly transforming research in agentic behavioral simulation, LLM
personalization, and human-AI alignment. However, most existing synthetic
personas remain shallow and simplistic, capturing minimal attributes and
failing to reflect the rich complexity and diversity of real human identities.
We introduce DEEPPERSONA, a scalable generative engine for synthesizing
narrative-complete synthetic personas through a two-stage, taxonomy-guided
method. First, we algorithmically construct the largest-ever human-attribute
taxonomy, comprising over hundreds of hierarchically organized attributes, by
mining thousands of real user-ChatGPT conversations. Second, we progressively
sample attributes from this taxonomy, conditionally generating coherent and
realistic personas that average hundreds of structured attributes and roughly 1
MB of narrative text, two orders of magnitude deeper than prior works.
Intrinsic evaluations confirm significant improvements in attribute diversity
(32 percent higher coverage) and profile uniqueness (44 percent greater)
compared to state-of-the-art baselines. Extrinsically, our personas enhance
GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on
average across ten metrics and substantially narrow (by 31.7 percent) the gap
between simulated LLM citizens and authentic human responses in social surveys.
Our generated national citizens reduced the performance gap on the Big Five
personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA
thus provides a rigorous, scalable, and privacy-free platform for high-fidelity
human simulation and personalized AI research.","Zhen Wang, Yufan Zhou, Zhongyan Luo, Lyumanshan Ye, Adam Wood, Man Yao, Luoshang Pan",arXiv,2025,2025-11-10 17:37:56+00:00,"cs.AI, cs.LG, 68T07, 68T20, I.2.7; I.2.6; I.2.11"
2511.07332v1,Grounding Computer Use Agents on Human Demonstrations,"Building reliable computer-use agents requires grounding: accurately
connecting natural language instructions to the correct on-screen elements.
While large datasets exist for web and mobile interactions, high-quality
resources for desktop environments are limited. To address this gap, we
introduce GroundCUA, a large-scale desktop grounding dataset built from expert
human demonstrations. It covers 87 applications across 12 categories and
includes 56K screenshots, with every on-screen element carefully annotated for
a total of over 3.56M human-verified annotations. From these demonstrations, we
generate diverse instructions that capture a wide range of real-world tasks,
providing high-quality data for model training. Using GroundCUA, we develop the
GroundNext family of models that map instructions to their target UI elements.
At both 3B and 7B scales, GroundNext achieves state-of-the-art results across
five benchmarks using supervised fine-tuning, while requiring less than
one-tenth the training data of prior work. Reinforcement learning post-training
further improves performance, and when evaluated in an agentic setting on the
OSWorld benchmark using o3 as planner, GroundNext attains comparable or
superior results to models trained with substantially more data,. These results
demonstrate the critical role of high-quality, expert-driven datasets in
advancing general-purpose computer-use agents.","Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar",arXiv,2025,2025-11-10 17:35:21+00:00,"cs.LG, cs.AI"
2511.07329v1,"Preparation of Fractal-Inspired Computational Architectures for Advanced
  Large Language Model Analysis","It introduces FractalNet, a fractal-inspired computational architectures for
advanced large language model analysis that mainly challenges model diversity
on a large scale in an efficient manner. The new set-up involves a
template-driven generator, runner, and evaluation framework that, through
systematic permutations of convolutional, normalization, activation, and
dropout layers, can create more than 1,200 variants of neural networks. Fractal
templates allow for structural recursion and multi-column pathways, thus,
models become deeper and wider in a balanced way. Training utilizes PyTorch,
Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out
on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based
architectures are capable of strong performance and are computationally
efficient. The paper positions fractal design as a feasible and
resource-efficient method of automated architecture exploration.","Yash Mittal, Dmitry Ignatov, Radu Timofte",arXiv,2025,2025-11-10 17:31:39+00:00,"cs.LG, cs.CV"
2511.07328v1,"Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder
  Training","Retrieval-Augmented Generation (RAG) methods enhance LLM performance by
efficiently filtering relevant context for LLMs, reducing hallucinations and
inference cost. However, most existing RAG methods focus on single-step
retrieval, which is often insufficient for answering complex questions that
require multi-step search. Recently, multi-step retrieval approaches have
emerged, typically involving the fine-tuning of small LLMs to perform
multi-step retrieval. This type of fine-tuning is highly resource-intensive and
does not enable the use of larger LLMs. In this work, we propose Q-RAG, a novel
approach that fine-tunes the Embedder model for multi-step retrieval using
reinforcement learning (RL). Q-RAG offers a competitive, resource-efficient
alternative to existing multi-step retrieval methods for open-domain question
answering and achieves state-of-the-art results on the popular long-context
benchmarks Babilong and RULER for contexts up to 10M tokens.","Artyom Sorokin, Nazar Buzun, Alexander Anokhin, Oleg Inozemcev, Egor Vedernikov, Petr Anokhin, Mikhail Burtsev, Trushkov Alexey, Yin Wenshuai, Evgeny Burnaev",arXiv,2025,2025-11-10 17:31:02+00:00,"cs.LG, cs.IR"
2511.07327v1,"IterResearch: Rethinking Long-Horizon Agents via Markovian State
  Reconstruction","Recent advances in deep-research agents have shown promise for autonomous
knowledge construction through dynamic reasoning over external sources.
However, existing approaches rely on a mono-contextual paradigm that
accumulates all information in a single, expanding context window, leading to
context suffocation and noise contamination that limit their effectiveness on
long-horizon tasks. We introduce IterResearch, a novel iterative deep-research
paradigm that reformulates long-horizon research as a Markov Decision Process
with strategic workspace reconstruction. By maintaining an evolving report as
memory and periodically synthesizing insights, our approach preserves
consistent reasoning capacity across arbitrary exploration depths. We further
develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning
framework that incentivizes efficient exploration through geometric reward
discounting and enables stable distributed training via adaptive downsampling.
Extensive experiments demonstrate that IterResearch achieves substantial
improvements over existing open-source agents with average +14.5pp across six
benchmarks and narrows the gap with frontier proprietary systems. Remarkably,
our paradigm exhibits unprecedented interaction scaling, extending to 2048
interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves
as an effective prompting strategy, improving frontier models by up to 19.2pp
over ReAct on long-horizon tasks. These findings position IterResearch as a
versatile solution for long-horizon reasoning, effective both as a trained
agent and as a prompting paradigm for frontier models.","Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",arXiv,2025,2025-11-10 17:30:08+00:00,"cs.AI, cs.CL"
2511.07325v1,Garbage Vulnerable Point Monitoring using IoT and Computer Vision,"This paper proposes a smart way to manage municipal solid waste by using the
Internet of Things (IoT) and computer vision (CV) to monitor illegal waste
dumping at garbage vulnerable points (GVPs) in urban areas. The system can
quickly detect and monitor dumped waste using a street-level camera and object
detection algorithm. Data was collected from the Sangareddy district in
Telangana, India. A series of comprehensive experiments was carried out using
the proposed dataset to assess the accuracy and overall performance of various
object detection models. Specifically, we performed an in-depth evaluation of
YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models,
YOLO11m achieved the highest accuracy of 92.39\% in waste detection,
demonstrating its effectiveness in detecting waste. Additionally, it attains an
mAP@50 of 0.91, highlighting its high precision. These findings confirm that
the object detection model is well-suited for monitoring and tracking waste
dumping events at GVP locations. Furthermore, the system effectively captures
waste disposal patterns, including hourly, daily, and weekly dumping trends,
ensuring comprehensive daily and nightly monitoring.","R. Kumar, A. Lall, S. Chaudhari, M. Kale, A. Vattem",arXiv,2025,2025-11-10 17:27:51+00:00,"cs.CV, cs.LG"
2511.07322v1,"FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework
  for Equity Research Report Generation","While LLMs have shown great success in financial tasks like stock prediction
and question answering, their application in fully automating Equity Research
Report generation remains uncharted territory. In this paper, we formulate the
Equity Research Report (ERR) Generation task for the first time. To address the
data scarcity and the evaluation metrics absence, we present an open-source
evaluation benchmark for ERR generation - FinRpt. We frame a Dataset
Construction Pipeline that integrates 7 financial data types and produces a
high-quality ERR dataset automatically, which could be used for model training
and evaluation. We also introduce a comprehensive evaluation system including
11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent
framework specifically tailored to address this task, named FinRpt-Gen, and
train several LLM-based agents on the proposed datasets using Supervised
Fine-Tuning and Reinforcement Learning. Experimental results indicate the data
quality and metrics effectiveness of the benchmark FinRpt and the strong
performance of FinRpt-Gen, showcasing their potential to drive innovation in
the ERR generation field. All code and datasets are publicly available.","Song Jin, Shuqi Li, Shukun Zhang, Rui Yan",arXiv,2025,2025-11-10 17:22:32+00:00,"cs.CL, cs.AI"
2511.07321v1,YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting,"Fast and flexible 3D scene reconstruction from unstructured image collections
remains a significant challenge. We present YoNoSplat, a feedforward model that
reconstructs high-quality 3D Gaussian Splatting representations from an
arbitrary number of images. Our model is highly versatile, operating
effectively with both posed and unposed, calibrated and uncalibrated inputs.
YoNoSplat predicts local Gaussians and camera poses for each view, which are
aggregated into a global representation using either predicted or provided
poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and
camera parameters, we introduce a novel mixing training strategy. This approach
mitigates the entanglement between the two tasks by initially using
ground-truth poses to aggregate local Gaussians and gradually transitioning to
a mix of predicted and ground-truth poses, which prevents both training
instability and exposure bias. We further resolve the scale ambiguity problem
by a novel pairwise camera-distance normalization scheme and by embedding
camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic
parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates
exceptional efficiency, reconstructing a scene from 100 views (at 280x518
resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves
state-of-the-art performance on standard benchmarks in both pose-free and
pose-dependent settings. Our project page is at
https://botaoye.github.io/yonosplat/.","Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, Marc Pollefeys",arXiv,2025,2025-11-10 17:21:54+00:00,cs.CV
2511.07318v1,"When Bias Pretends to Be Truth: How Spurious Correlations Undermine
  Hallucination Detection in LLMs","Despite substantial advances, large language models (LLMs) continue to
exhibit hallucinations, generating plausible yet incorrect responses. In this
paper, we highlight a critical yet previously underexplored class of
hallucinations driven by spurious correlations -- superficial but statistically
prominent associations between features (e.g., surnames) and attributes (e.g.,
nationality) present in the training data. We demonstrate that these spurious
correlations induce hallucinations that are confidently generated, immune to
model scaling, evade current detection methods, and persist even after refusal
fine-tuning. Through systematically controlled synthetic experiments and
empirical evaluations on state-of-the-art open-source and proprietary LLMs
(including GPT-5), we show that existing hallucination detection methods, such
as confidence-based filtering and inner-state probing, fundamentally fail in
the presence of spurious correlations. Our theoretical analysis further
elucidates why these statistical biases intrinsically undermine
confidence-based detection techniques. Our findings thus emphasize the urgent
need for new approaches explicitly designed to address hallucinations caused by
spurious correlations.","Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun, Kaifeng Lyu, Jian Li",arXiv,2025,2025-11-10 17:19:27+00:00,"cs.CL, cs.AI, cs.LG"
2511.07317v1,"RLVE: Scaling Up Reinforcement Learning for Language Models with
  Adaptive Verifiable Environments","We introduce Reinforcement Learning (RL) with Adaptive Verifiable
Environments (RLVE), an approach using verifiable environments that
procedurally generate problems and provide algorithmically verifiable rewards,
to scale up RL for language models (LMs). RLVE enables each verifiable
environment to dynamically adapt its problem difficulty distribution to the
policy model's capabilities as training progresses. In contrast, static data
distributions often lead to vanishing learning signals when problems are either
too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a
large-scale suite of 400 verifiable environments carefully developed through
manual environment engineering. Using RLVE-Gym, we show that environment
scaling, i.e., expanding the collection of training environments, consistently
improves generalizable reasoning capabilities. RLVE with joint training across
all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement
across six reasoning benchmarks, starting from one of the strongest 1.5B
reasoning LMs. By comparison, continuing this LM's original RL training yields
only a 0.49% average absolute gain despite using over 3x more compute. We
release our code publicly.","Zhiyuan Zeng, Hamish Ivison, Yiping Wang, Lifan Yuan, Shuyue Stella Li, Zhuorui Ye, Siting Li, Jacqueline He, Runlong Zhou, Tong Chen, Chenyang Zhao, Yulia Tsvetkov, Simon Shaolei Du, Natasha Jaques, Hao Peng, Pang Wei Koh, Hannaneh Hajishirzi",arXiv,2025,2025-11-10 17:18:35+00:00,"cs.CL, cs.LG"
2511.07313v1,"De-Individualizing fMRI Signals via Mahalanobis Whitening and Bures
  Geometry","Functional connectivity has been widely investigated to understand brain
disease in clinical studies and imaging-based neuroscience, and analyzing
changes in functional connectivity has proven to be valuable for understanding
and computationally evaluating the effects on brain function caused by diseases
or experimental stimuli. By using Mahalanobis data whitening prior to the use
of dimensionality reduction algorithms, we are able to distill meaningful
information from fMRI signals about subjects and the experimental stimuli used
to prompt them. Furthermore, we offer an interpretation of Mahalanobis
whitening as a two-stage de-individualization of data which is motivated by
similarity as captured by the Bures distance, which is connected to quantum
mechanics. These methods have potential to aid discoveries about the mechanisms
that link brain function with cognition and behavior and may improve the
accuracy and consistency of Alzheimer's diagnosis, especially in the
preclinical stage of disease progression.","Aaron Jacobson, Tingting Dan, Martin Styner, Guorong Wu, Shahar Kovalsky, Caroline Moosmueller",arXiv,2025,2025-11-10 17:14:48+00:00,"q-bio.NC, cs.LG, q-bio.QM, 92-08, 68T10, 62H310, I.5.3; J.3"
2511.07312v1,"Superhuman AI for Stratego Using Self-Play Reinforcement Learning and
  Test-Time Search","Few classical games have been regarded as such significant benchmarks of
artificial intelligence as to have justified training costs in the millions of
dollars. Among these, Stratego -- a board wargame exemplifying the challenge of
strategic decision making under massive amounts of hidden information -- stands
apart as a case where such efforts failed to produce performance at the level
of top humans. This work establishes a step change in both performance and cost
for Stratego, showing that it is now possible not only to reach the level of
top humans, but to achieve vastly superhuman level -- and that doing so
requires not an industrial budget, but merely a few thousand dollars. We
achieved this result by developing general approaches for self-play
reinforcement learning and test-time search under imperfect information.","Samuel Sokota, Eugene Vinitsky, Hengyuan Hu, J. Zico Kolter, Gabriele Farina",arXiv,2025,2025-11-10 17:13:41+00:00,"cs.LG, cs.AI"
2511.07308v1,"Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by
  the Thermodynamics of an Ideal Gas?","Understanding the training dynamics of deep neural networks remains a major
open problem, with physics-inspired approaches offering promising insights.
Building on this perspective, we develop a thermodynamic framework to describe
the stationary distributions of stochastic gradient descent (SGD) with weight
decay for scale-invariant neural networks, a setting that both reflects
practical architectures with normalization layers and permits theoretical
analysis. We establish analogies between training hyperparameters (e.g.,
learning rate, weight decay) and thermodynamic variables such as temperature,
pressure, and volume. Starting with a simplified isotropic noise model, we
uncover a close correspondence between SGD dynamics and ideal gas behavior,
validated through theory and simulation. Extending to training of neural
networks, we show that key predictions of the framework, including the behavior
of stationary entropy, align closely with experimental observations. This
framework provides a principled foundation for interpreting training dynamics
and may guide future work on hyperparameter tuning and the design of learning
rate schedulers.","Ildus Sadrtdinov, Ekaterina Lobacheva, Ivan Klimov, Mikhail I. Katsnelson, Dmitry Vetrov",arXiv,2025,2025-11-10 17:10:01+00:00,cs.LG
2511.07304v1,"Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task
  Learning Approach for Bangla Hate Speech Identification","This paper addresses the problem of Bangla hate speech identification, a
socially impactful yet linguistically challenging task. As part of the ""Bangla
Multi-task Hate Speech Identification"" shared task at the BLP Workshop,
IJCNLP-AACL 2025, our team ""Retriv"" participated in all three subtasks: (1A)
hate type classification, (1B) target group identification, and (1C) joint
detection of type, severity, and target. For subtasks 1A and 1B, we employed a
soft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2).
For subtask 1C, we trained three multitask variants and aggregated their
predictions through a weighted voting ensemble. Our systems achieved micro-f1
scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62%
(1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7th
positions, respectively. These results highlight the promise of transformer
ensembles and weighted multitask frameworks for advancing Bangla hate speech
detection in low-resource contexts. We made experimental scripts publicly
available for the community.","Sourav Saha, K M Nafi Asib, Mohammed Moshiul Hoque",arXiv,2025,2025-11-10 17:07:09+00:00,cs.CL
2511.07301v1,"Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free
  Object Detection","Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
detector to a target domain without access to source data. However, existing
SFOD methods predominantly rely on internal knowledge from the source model,
which limits their capacity to generalize across domains and often results in
biased pseudo-labels, thereby hindering both transferability and
discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
massive and diverse data, exhibit strong perception capabilities and broad
generalization, yet their potential remains largely untapped in the SFOD
setting. In this paper, we propose a novel SFOD framework that leverages VFMs
as external knowledge sources to jointly enhance feature alignment and label
quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
Global Feature Alignment (PGFA) distills global features from VFMs using
patch-similarity-based weighting to enhance global feature transferability; (2)
Prototype-based Instance Feature Alignment (PIFA) performs instance-level
contrastive learning guided by momentum-updated VFM prototypes; and (3)
Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
detection VFMs and teacher models via an entropy-aware strategy to yield more
reliable supervision. Extensive experiments on six benchmarks demonstrate that
our method achieves state-of-the-art SFOD performance, validating the
effectiveness of integrating VFMs to simultaneously improve transferability and
discriminability.","Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu, Hui Xiong",arXiv,2025,2025-11-10 17:06:01+00:00,"cs.CV, cs.AI"
2511.07295v1,"Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender
  Systems via Large Language Models","Implicit feedback, employed in training recommender systems, unavoidably
confronts noise due to factors such as misclicks and position bias. Previous
studies have attempted to identify noisy samples through their diverged data
patterns, such as higher loss values, and mitigate their influence through
sample dropping or reweighting. However, we observed that noisy samples and
hard samples display similar patterns, leading to hard-noisy confusion issue.
Such confusion is problematic as hard samples are vital for modeling user
preferences. To solve this problem, we propose LLMHNI framework, leveraging two
auxiliary user-item relevance signals generated by Large Language Models (LLMs)
to differentiate hard and noisy samples. LLMHNI obtains user-item semantic
relevance from LLM-encoded embeddings, which is used in negative sampling to
select hard negatives while filtering out noisy false negatives. An objective
alignment strategy is proposed to project LLM-encoded embeddings, originally
for general language tasks, into a representation space optimized for user-item
relevance modeling. LLMHNI also exploits LLM-inferred logical relevance within
user-item interactions to identify hard and noisy samples. These LLM-inferred
interactions are integrated into the interaction graph and guide denoising with
cross-graph contrastive alignment. To eliminate the impact of unreliable
interactions induced by LLM hallucination, we propose a graph contrastive
learning strategy that aligns representations from randomly edge-dropped views
to suppress unreliable edges. Empirical results demonstrate that LLMHNI
significantly improves denoising and recommendation performance.","Tianrui Song, Wen-Shuo Chao, Hao Liu",arXiv,2025,2025-11-10 16:51:03+00:00,"cs.IR, cs.AI"
2511.07292v1,PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving,"Most recent work in autonomous driving has prioritized benchmark performance
and methodological innovation over in-depth analysis of model failures, biases,
and shortcut learning. This has led to incremental improvements without a deep
understanding of the current failures. While it is straightforward to look at
situations where the model fails, it is hard to understand the underlying
reason. This motivates us to conduct a systematic study, where inputs to the
model are perturbed and the predictions observed. We introduce PlanT 2.0, a
lightweight, object-centric planning transformer designed for autonomous
driving research in CARLA. The object-level representation enables controlled
analysis, as the input can be easily perturbed (e.g., by changing the location
or adding or removing certain objects), in contrast to sensor-based models. To
tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0,
we introduce multiple upgrades to PlanT, achieving state-of-the-art performance
on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis
exposes insightful failures, such as a lack of scene understanding caused by
low obstacle diversity, rigid expert behaviors leading to exploitable
shortcuts, and overfitting to a fixed set of expert trajectories. Based on
these findings, we argue for a shift toward data-centric development, with a
focus on richer, more robust, and less biased datasets. We open-source our code
and model at https://github.com/autonomousvision/plant2.","Simon Gerstenecker, Andreas Geiger, Katrin Renz",arXiv,2025,2025-11-10 16:41:47+00:00,"cs.RO, cs.CV"
2511.07419v1,"Routing Manifold Alignment Improves Generalization of Mixture-of-Experts
  LLMs","Sparse Mixture-of-Experts (MoE) have been widely adopted in recent large
language models since it can efficiently scale up the model capability without
increasing the inference cost. However, evaluations on broad downstream tasks
reveal a consistent suboptimality of the routers in existing MoE LLMs, which
results in a severe performance gap (e.g., 10-20% in accuracy) to the optimal
routing. In this paper, we show that aligning the manifold of routing weights
with that of task embedding can effectively reduce the gap and improve MoE
LLMs' generalization performance. Our method, ""Routing Manifold Alignment
(RoMA)"", introduces an additional manifold regularization term in the
post-training objective and only requires lightweight finetuning of routers
(with other parameters frozen). Specifically, the regularization encourages the
routing weights of each sample to be close to those of its successful neighbors
(whose routing weights lead to correct answers) in a task embedding space.
Consequently, samples targeting similar tasks will share similar expert choices
across layers. Building such bindings between tasks and experts over different
samples is essential to achieve better generalization. Moreover, RoMA
demonstrates the advantage of unifying the task understanding (by embedding
models) with solution generation (by MoE LLMs). In experiments, we finetune
routers in OLMoE, DeepSeekMoE, and Qwen3-MoE using RoMA. Evaluations on diverse
benchmarks and extensive comparisons with baselines show the substantial
improvement brought by RoMA.","Zhongyang Li, Ziyue Li, Tianyi Zhou",arXiv,2025,2025-11-10 18:59:53+00:00,cs.LG
2511.07417v1,Language Generation with Infinite Contamination,"We study language generation in the limit, where an algorithm observes an
adversarial enumeration of strings from an unknown target language $K$ and must
eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan
[KM24] proved that generation is achievable in surprisingly general settings.
But their generator suffers from ``mode collapse,'' producing from an
ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25]
require the generator's output to be ``dense'' in the target language. They
showed that generation with density, surprisingly, remains achievable at the
same generality.
  Both results assume perfect data: no noisy insertions and no omissions. This
raises a central question: how much contamination can generation tolerate?
Recent works made partial progress on this question by studying (non-dense)
generation with either finite amounts of noise (but no omissions) or omissions
(but no noise).
  We characterize robustness under contaminated enumerations: 1. Generation
under Contamination: Language generation in the limit is achievable for all
countable collections iff the fraction of contaminated examples converges to
zero. When this fails, we characterize which collections are generable. 2.
Dense Generation under Contamination: Dense generation is strictly less robust
to contamination than generation. As a byproduct, we resolve an open question
of Raman and Raman [ICML25] by showing that generation is possible with only
membership oracle access under finitely many contaminated examples.
  Finally, we introduce a beyond-worst-case model inspired by curriculum
learning and prove that dense generation is achievable even with infinite
contamination provided the fraction of contaminated examples converges to zero.
This suggests curriculum learning may be crucial for learning from noisy web
data.","Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou",arXiv,2025,2025-11-10 18:59:39+00:00,"stat.ML, cs.AI, cs.CL, cs.DS, cs.LG"
2511.07416v1,Robot Learning from a Physical World Model,"We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.","Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang",arXiv,2025,2025-11-10 18:59:07+00:00,"cs.RO, cs.AI, cs.CV"
2511.07414v1,Wasserstein-Cramér-Rao Theory of Unbiased Estimation,"The quantity of interest in the classical Cram\'er-Rao theory of unbiased
estimation (e.g., the Cram\'er-Rao lower bound, its exact attainment for
exponential families, and asymptotic efficiency of maximum likelihood
estimation) is the variance, which represents the instability of an estimator
when its value is compared to the value for an independently-sampled data set
from the same distribution. In this paper we are interested in a quantity which
represents the instability of an estimator when its value is compared to the
value for an infinitesimal additive perturbation of the original data set; we
refer to this as the ""sensitivity"" of an estimator. The resulting theory of
sensitivity is based on the Wasserstein geometry in the same way that the
classical theory of variance is based on the Fisher-Rao (equivalently,
Hellinger) geometry, and this insight allows us to determine a collection of
results which are analogous to the classical case: a Wasserstein-Cram\'er-Rao
lower bound for the sensitivity of any unbiased estimator, a characterization
of models in which there exist unbiased estimators achieving the lower bound
exactly, and some concrete results that show that the Wasserstein projection
estimator achieves the lower bound asymptotically. We use these results to
treat many statistical examples, sometimes revealing new optimality properties
for existing estimators and other times revealing entirely new estimators.","Nicolás García Trillos, Adam Quinn Jaffe, Bodhisattva Sen",arXiv,2025,2025-11-10 18:58:18+00:00,"math.ST, math.OC, stat.ME, stat.ML, stat.TH, 62B11, 62F10, 62F12, 35Q49, 49Q22"
2511.07413v1,DigiData: Training and Evaluating General-Purpose Mobile Control Agents,"AI agents capable of controlling user interfaces have the potential to
transform human interaction with digital devices. To accelerate this
transformation, two fundamental building blocks are essential: high-quality
datasets that enable agents to achieve complex and human-relevant goals, and
robust evaluation methods that allow researchers and practitioners to rapidly
enhance agent performance. In this paper, we introduce DigiData, a large-scale,
high-quality, diverse, multi-modal dataset designed for training mobile control
agents. Unlike existing datasets, which derive goals from unstructured
interactions, DigiData is meticulously constructed through comprehensive
exploration of app features, resulting in greater diversity and higher goal
complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating
mobile control agents on real-world complex tasks. We demonstrate that the
commonly used step-accuracy metric falls short in reliably assessing mobile
control agents and, to address this, we propose dynamic evaluation protocols
and AI-powered evaluations as rigorous alternatives for agent assessment. Our
contributions aim to significantly advance the development of mobile control
agents, paving the way for more intuitive and effective human-device
interactions.","Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan, Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, Nitin Kamra, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer, Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway, Joseph Tighe",arXiv,2025,2025-11-10 18:57:35+00:00,"cs.AI, cs.CL, cs.HC, cs.LG"
2511.07412v1,"TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for
  Embodied AI Research","Developing embodied AI for intelligent surgical systems requires safe,
controllable environments for continual learning and evaluation. However,
safety regulations and operational constraints in operating rooms (ORs) limit
embodied agents from freely perceiving and interacting in realistic settings.
Digital twins provide high-fidelity, risk-free environments for exploration and
training. How we may create photorealistic and dynamic digital representations
of ORs that capture relevant spatial, visual, and behavioral complexity remains
unclear. We introduce TwinOR, a framework for constructing photorealistic,
dynamic digital twins of ORs for embodied AI research. The system reconstructs
static geometry from pre-scan videos and continuously models human and
equipment motion through multi-view perception of OR activities. The static and
dynamic components are fused into an immersive 3D environment that supports
controllable simulation and embodied exploration. The proposed framework
reconstructs complete OR geometry with centimeter level accuracy while
preserving dynamic interaction across surgical workflows, enabling realistic
renderings and a virtual playground for embodied AI systems. In our
experiments, TwinOR simulates stereo and monocular sensor streams for geometry
understanding and visual localization tasks. Models such as FoundationStereo
and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
reported accuracy on real indoor datasets, demonstrating that TwinOR provides
sensor-level realism sufficient for perception and localization challenges. By
establishing a real-to-sim pipeline for constructing dynamic, photorealistic
digital twins of OR environments, TwinOR enables the safe, scalable, and
data-efficient development and benchmarking of embodied AI, ultimately
accelerating the deployment of embodied AI from sim-to-real.","Han Zhang, Yiqing Shen, Roger D. Soberanis-Mukul, Ankita Ghosh, Hao Ding, Lalithkumar Seenivasan, Jose L. Porras, Zhekai Mao, Chenjia Li, Wenjie Xiao, Lonny Yarmus, Angela Christine Argento, Masaru Ishii, Mathias Unberath",arXiv,2025,2025-11-10 18:57:09+00:00,"cs.CV, cs.RO"
2511.07409v1,DIMO: Diverse 3D Motion Generation for Arbitrary Objects,"We present DIMO, a generative approach capable of generating diverse 3D
motions for arbitrary objects from a single image. The core idea of our work is
to leverage the rich priors in well-trained video models to extract the common
motion patterns and then embed them into a shared low-dimensional latent space.
Specifically, we first generate multiple videos of the same object with diverse
motions. We then embed each motion into a latent vector and train a shared
motion decoder to learn the distribution of motions represented by a structured
and compact motion representation, i.e., neural key point trajectories. The
canonical 3D Gaussians are then driven by these key points and fused to model
the geometry and appearance. During inference time with learned latent space,
we can instantly sample diverse 3D motions in a single-forward pass and support
several interesting applications including 3D motion interpolation and
language-guided motion generation. Our project page is available at
https://linzhanm.github.io/dimo.","Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis",arXiv,2025,2025-11-10 18:56:49+00:00,cs.CV
2511.07407v1,Unified Humanoid Fall-Safety Policy from a Few Demonstrations,"Falling is an inherent risk of humanoid mobility. Maintaining stability is
thus a primary safety focus in robot control and learning, yet no existing
approach fully averts loss of balance. When instability does occur, prior work
addresses only isolated aspects of falling: avoiding falls, choreographing a
controlled descent, or standing up afterward. Consequently, humanoid robots
lack integrated strategies for impact mitigation and prompt recovery when real
falls defy these scripts. We aim to go beyond keeping balance to make the
entire fall-and-recovery process safe and autonomous: prevent falls when
possible, reduce impact when unavoidable, and stand up when fallen. By fusing
sparse human demonstrations with reinforcement learning and an adaptive
diffusion-based memory of safe reactions, we learn adaptive whole-body
behaviors that unify fall prevention, impact mitigation, and rapid recovery in
one policy. Experiments in simulation and on a Unitree G1 demonstrate robust
sim-to-real transfer, lower impact forces, and consistently fast recovery
across diverse disturbances, pointing towards safer, more resilient humanoids
in real environments. Videos are available at https://firm2025.github.io/.","Zhengjie Xu, Ye Li, Kwan-yee Lin, Stella X. Yu",arXiv,2025,2025-11-10 18:56:31+00:00,cs.RO
2511.07406v1,Entangled Schrödinger Bridge Matching,"Simulating trajectories of multi-particle systems on complex energy
landscapes is a central task in molecular dynamics (MD) and drug discovery, but
remains challenging at scale due to computationally expensive and long
simulations. Previous approaches leverage techniques such as flow or
Schr\""odinger bridge matching to implicitly learn joint trajectories through
data snapshots. However, many systems, including biomolecular systems and
heterogeneous cell populations, undergo dynamic interactions that evolve over
their trajectory and cannot be captured through static snapshots. To close this
gap, we introduce Entangled Schr\""odinger Bridge Matching (EntangledSBM), a
framework that learns the first- and second-order stochastic dynamics of
interacting, multi-particle systems where the direction and magnitude of each
particle's path depend dynamically on the paths of the other particles. We
define the Entangled Schr\""odinger Bridge (EntangledSB) problem as solving a
coupled system of bias forces that entangle particle velocities. We show that
our framework accurately simulates heterogeneous cell populations under
perturbations and rare transitions in high-dimensional biomolecular systems.","Sophia Tang, Yinuo Zhang, Pranam Chatterjee",arXiv,2025,2025-11-10 18:55:35+00:00,"cs.LG, q-bio.BM"
2511.07405v1,"SPOT: An Annotated French Corpus and Benchmark for Detecting Critical
  Interventions in Online Conversations","We introduce SPOT (Stopping Points in Online Threads), the first annotated
corpus translating the sociological concept of stopping point into a
reproducible NLP task. Stopping points are ordinary critical interventions that
pause or redirect online discussions through a range of forms (irony, subtle
doubt or fragmentary arguments) that frameworks like counterspeech or social
correction often overlook. We operationalize this concept as a binary
classification task and provide reliable annotation guidelines. The corpus
contains 43,305 manually annotated French Facebook comments linked to URLs
flagged as false information by social media users, enriched with contextual
metadata (article, post, parent comment, page or group, and source). We
benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs
under various prompting strategies. Results show that fine-tuned encoders
outperform prompted LLMs in F1 score by more than 10 percentage points,
confirming the importance of supervised learning for emerging non-English
social media tasks. Incorporating contextual metadata further improves encoder
models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along
with the annotation guidelines and code in our code repository, to foster
transparency and reproducible research.","Manon Berriche, Célia Nouri, Chloé Clavel, Jean-Philippe Cointet",arXiv,2025,2025-11-10 18:54:40+00:00,"cs.CL, cs.CY"
2511.07403v1,"SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial
  Rewards","Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.","Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark",arXiv,2025,2025-11-10 18:52:47+00:00,"cs.CV, cs.AI, cs.CL, cs.LG"
2511.07399v1,"StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video
  Generation","Generative models are reshaping the live-streaming industry by redefining how
content is created, styled, and delivered. Previous image-based streaming
diffusion models have powered efficient and creative live streaming products
but have hit limits on temporal consistency due to the foundation of
image-based designs. Recent advances in video diffusion have markedly improved
temporal consistency and sampling efficiency for offline generation. However,
offline generation systems primarily optimize throughput by batching large
workloads. In contrast, live online streaming operates under strict
service-level objectives (SLOs): time-to-first-frame must be minimal, and every
frame must meet a per-frame deadline with low jitter. Besides, scalable
multi-GPU serving for real-time streams remains largely unresolved so far. To
address this, we present StreamDiffusionV2, a training-free pipeline for
interactive live streaming with video diffusion models. StreamDiffusionV2
integrates an SLO-aware batching scheduler and a block scheduler, together with
a sink-token--guided rolling KV cache, a motion-aware noise controller, and
other system-level optimizations. Moreover, we introduce a scalable pipeline
orchestration that parallelizes the diffusion process across denoising steps
and network layers, achieving near-linear FPS scaling without violating latency
guarantees. The system scales seamlessly across heterogeneous GPU environments
and supports flexible denoising steps (e.g., 1--4), enabling both
ultra-low-latency and higher-quality modes. Without TensorRT or quantization,
StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS
with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four
H100 GPUs, making state-of-the-art generative live streaming practical and
accessible--from individual creators to enterprise-scale platforms.","Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li, Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt Keutzer, Akio Kodaira, Chenfeng Xu",arXiv,2025,2025-11-10 18:51:28+00:00,"cs.CV, cs.LG"
2511.07398v1,Solving bilevel optimization via sequential minimax optimization,"In this paper we propose a sequential minimax optimization (SMO) method for
solving a class of constrained bilevel optimization problems in which the
lower-level part is a possibly nonsmooth convex optimization problem, while the
upper-level part is a possibly nonconvex optimization problem. Specifically,
SMO applies a first-order method to solve a sequence of minimax subproblems,
which are obtained by employing a hybrid of modified augmented Lagrangian and
penalty schemes on the bilevel optimization problems. Under suitable
assumptions, we establish an operation complexity of
$O(\varepsilon^{-7}\log\varepsilon^{-1})$ and
$O(\varepsilon^{-6}\log\varepsilon^{-1})$, measured in terms of fundamental
operations, for SMO in finding an $\varepsilon$-KKT solution of the bilevel
optimization problems with merely convex and strongly convex lower-level
objective functions, respectively. The latter result improves the previous
best-known operation complexity by a factor of $\varepsilon^{-1}$. Preliminary
numerical results demonstrate significantly superior computational performance
compared to the recently developed first-order penalty method.","Zhaosong Lu, Sanyou Mei",arXiv,2025,2025-11-10 18:51:05+00:00,"math.OC, cs.LG, cs.NA, math.NA, stat.ML, 90C26, 90C30, 90C47, 90C99, 65K05"
2511.07397v1,ConvFill: Model Collaboration for Responsive Conversational Voice Agents,"Deploying conversational voice agents with large language models faces a
critical challenge: cloud-based foundation models provide deep reasoning and
domain knowledge but introduce latency that disrupts natural conversation,
while on-device models respond immediately but lack sophistication. We propose
conversational infill, a task where a lightweight on-device model generates
contextually appropriate dialogue while seamlessly incorporating streaming
knowledge from a powerful backend model. This approach decouples response
latency from model capability, enabling systems that feel responsive while
accessing the full power of large-scale models. We present ConvFill, a 360M
parameter model trained on synthetic multi-domain conversations. Evaluation
across multiple backend models shows that conversational infill can be
successfully learned, with ConvFill achieving accuracy improvements of 36-42%
over standalone small models of the same size while consistently retaining
sub-200ms response latencies. Our results demonstrate the promise of this
approach for building on-device conversational agents that are both immediately
responsive and knowledgeable.","Vidya Srinivas, Zachary Englhardt, Maximus Powers, Shwetak Patel, Vikram Iyer",arXiv,2025,2025-11-10 18:50:30+00:00,cs.CL
2511.07396v1,"C3PO: Optimized Large Language Model Cascades with Probabilistic Cost
  Constraints for Reasoning","Large language models (LLMs) have achieved impressive results on complex
reasoning tasks, but their high inference cost remains a major barrier to
real-world deployment. A promising solution is to use cascaded inference, where
small, cheap models handle easy queries, and only the hardest examples are
escalated to more powerful models. However, existing cascade methods typically
rely on supervised training with labeled data, offer no theoretical
generalization guarantees, and provide limited control over test-time
computational cost. We introduce C3PO (Cost Controlled Cascaded Prediction
Optimization), a self-supervised framework for optimizing LLM cascades under
probabilistic cost constraints. By focusing on minimizing regret with respect
to the most powerful model (MPM), C3PO avoids the need for labeled data by
constructing a cascade using only unlabeled model outputs. It leverages
conformal prediction to bound the probability that inference cost exceeds a
user-specified budget. We provide theoretical guarantees on both cost control
and generalization error, and show that our optimization procedure is effective
even with small calibration sets. Empirically, C3PO achieves state-of-the-art
performance across a diverse set of reasoning benchmarks including GSM8K,
MATH-500, BigBench-Hard and AIME, outperforming strong LLM cascading baselines
in both accuracy and cost-efficiency. Our results demonstrate that principled,
label-free cascade optimization can enable scalable LLM deployment.","Antonios Valkanas, Soumyasundar Pal, Pavel Rumiantsev, Yingxue Zhang, Mark Coates",arXiv,2025,2025-11-10 18:50:27+00:00,cs.LG
2511.07391v1,Extending QAOA-GPT to Higher-Order Quantum Optimization Problems,"The recently proposed QAOA-GPT framework demonstrated that generative
pre-trained transformers can learn mappings between problem graphs and
optimized quantum circuits for the Quantum Approximate Optimization Algorithm
(QAOA). In this work, we extend QAOA-GPT to Higher-Order Unconstrained Binary
Optimization (HUBO) problems, focusing on spin-glass Hamiltonians that include
cubic interaction terms. Using FEATHER graph embeddings to encode topological
information, we train the model on graph-circuit pairs generated via ADAPT-QAOA
and evaluate its performance on 8- and 16-qubit instances embedded on heavy-hex
lattices. The generative model produces adaptive QAOA-like circuits and
corresponding variational parameters in a single forward pass, bypassing the
iterative classical optimization loop. The generated circuits achieve average
approximation ratios exceeding 0.95, closely matching classically optimized
ADAPT-QAOA results, while maintaining consistent parameter distributions across
circuit depths. These results demonstrate that QAOA-GPT generalizes effectively
to higher-order cost Hamiltonians and complex energy landscapes, establishing
generative modeling as a scalable pathway toward autonomous variational circuit
design and quantum algorithm discovery in the NISQ era.","Leanto Sunny, Abhinav Rijal, George Siopsis",arXiv,2025,2025-11-10 18:46:38+00:00,quant-ph
2511.07390v1,A Diffusion Model to Shrink Proteins While Maintaining Their Function,"Many proteins useful in modern medicine or bioengineering are challenging to
make in the lab, fuse with other proteins in cells, or deliver to tissues in
the body, because their sequences are too long. Shortening these sequences
typically involves costly, time-consuming experimental campaigns. Ideally, we
could instead use modern models of massive databases of sequences from nature
to learn how to propose shrunken proteins that resemble sequences found in
nature. Unfortunately, these models struggle to efficiently search the
combinatorial space of all deletions, and are not trained with inductive biases
to learn how to delete. To address this gap, we propose SCISOR, a novel
discrete diffusion model that deletes letters from sequences to generate
protein samples that resemble those found in nature. To do so, SCISOR trains a
de-noiser to reverse a forward noising process that adds random insertions to
natural sequences. As a generative model, SCISOR fits evolutionary sequence
data competitively with previous large models. In evaluation, SCISOR achieves
state-of-the-art predictions of the functional effects of deletions on
ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein
sequences, and show that its suggested deletions result in significantly more
realistic proteins and more often preserve functional motifs than previous
models of evolutionary sequences.","Ethan Baron, Alan N. Amin, Ruben Weitzman, Debora Marks, Andrew Gordon Wilson",arXiv,2025,2025-11-10 18:46:24+00:00,"cs.LG, q-bio.QM"
2511.07388v1,Policy Learning for Perturbance-wise Linear Quadratic Control Problem,"We study finite horizon linear quadratic control with additive noise in a
perturbancewise framework that unifies the classical model, a constraint
embedded affine policy class, and a distributionally robust formulation with a
Wasserstein ambiguity set. Based on an augmented affine representation, we
model feasibility as an affine perturbation and unknown noise as distributional
perturbation from samples, thereby addressing constrained implementation and
model uncertainty in a single scheme. First, we construct an implementable
policy gradient method that accommodates nonzero noise means estimated from
data. Second, we analyze its convergence under constant stepsizes chosen as
simple polynomials of problem parameters, ensuring global decrease of the value
function. Finally, numerical studies: mean variance portfolio allocation and
dynamic benchmark tracking on real data, validating stable convergence and
illuminating sensitivity tradeoffs across horizon length, trading cost
intensity, state penalty scale, and estimation window.","Haoran Zhang, Wenhao Zhang, Xianping Wu",arXiv,2025,2025-11-10 18:45:02+00:00,math.OC
2511.07384v1,"Teaching Pretrained Language Models to Think Deeper with Retrofitted
  Recurrence","Recent advances in depth-recurrent language models show that recurrence can
decouple train-time compute and parameter count from test-time compute. In this
work, we study how to convert existing pretrained non-recurrent language models
into depth-recurrent models. We find that using a curriculum of recurrences to
increase the effective depth of the model over the course of training preserves
performance while reducing total computational cost. In our experiments, on
mathematics, we observe that converting pretrained models to recurrent ones
results in better performance at a given compute budget than simply
post-training the original non-recurrent language model.","Sean McLeish, Ang Li, John Kirchenbauer, Dayal Singh Kalra, Brian R. Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Jonas Geiping, Tom Goldstein, Micah Goldblum",arXiv,2025,2025-11-10 18:43:07+00:00,"cs.CL, cs.AI, cs.LG"
2511.07381v1,Residual Rotation Correction using Tactile Equivariance,"Visuotactile policy learning augments vision-only policies with tactile
input, facilitating contact-rich manipulation. However, the high cost of
tactile data collection makes sample efficiency the key requirement for
developing visuotactile policies. We present EquiTac, a framework that exploits
the inherent SO(2) symmetry of in-hand object rotation to improve sample
efficiency and generalization for visuotactile policy learning. EquiTac first
reconstructs surface normals from raw RGB inputs of vision-based tactile
sensors, so rotations of the normal vector field correspond to in-hand object
rotations. An SO(2)-equivariant network then predicts a residual rotation
action that augments a base visuomotor policy at test time, enabling real-time
rotation correction without additional reorientation demonstrations. On a real
robot, EquiTac accurately achieves robust zero-shot generalization to unseen
in-hand orientations with very few training samples, where baselines fail even
with more training data. To our knowledge, this is the first tactile learning
method to explicitly encode tactile equivariance for policy learning, yielding
a lightweight, symmetry-aware module that improves reliability in contact-rich
tasks.","Yizhe Zhu, Zhang Ye, Boce Hu, Haibo Zhao, Yu Qi, Dian Wang, Robert Platt",arXiv,2025,2025-11-10 18:41:34+00:00,"cs.RO, 14J60 (Primary) 14F05, 14J26 (Secondary), 14J60 (Primary) 14F05,
  14J26 (Secondary)"
2511.07379v1,"LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic
  Graphs","Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes
domains, such as financial forecasting, recommendation systems, and fraud
detection. However, their susceptibility to poisoning attacks poses a critical
security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a
novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades
TGNN performance by an average of 29.47% across 4 widely benchmark datasets and
4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage
approach: (1) sparsify the graph by removing high-impact edges using any of the
16 tested temporal importance metrics, (2) strategically replace removed edges
with adversarial negatives via LoReTTA's novel degree-preserving negative
sampling algorithm. Our plug-and-play design eliminates the need for expensive
surrogate models while adhering to realistic unnoticeability constraints.
LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8%
on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains
undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA
adversarial defense training methods, establishing its effectiveness,
unnoticeability, and robustness.","Himanshu Pal, Venkata Sai Pranav Bachina, Ankit Gangwal, Charu Sharma",arXiv,2025,2025-11-10 18:41:02+00:00,"cs.LG, cs.AI"
2511.07378v1,"Transformers Provably Learn Chain-of-Thought Reasoning with Length
  Generalization","The ability to reason lies at the core of artificial intelligence (AI), and
challenging problems usually call for deeper and longer reasoning to tackle. A
crucial question about AI reasoning is whether models can extrapolate learned
reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In
this work, we present a theoretical analysis of transformers learning on
synthetic state-tracking tasks with gradient descent. We mathematically prove
how the algebraic structure of state-tracking problems governs the degree of
extrapolation of the learned CoT. Specifically, our theory characterizes the
length generalization of transformers through the mechanism of attention
concentration, linking the retrieval robustness of the attention layer to the
state-tracking task structure of long-context reasoning. Moreover, for
transformers with limited reasoning length, we prove that a recursive
self-training scheme can progressively extend the range of solvable problem
lengths. To our knowledge, we provide the first optimization guarantee that
constant-depth transformers provably learn $\mathsf{NC}^1$-complete problems
with CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$,
unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails.
Finally, we present a broad set of experiments supporting our theoretical
results, confirming the length generalization behaviors and the mechanism of
attention concentration.","Yu Huang, Zixin Wen, Aarti Singh, Yuejie Chi, Yuxin Chen",arXiv,2025,2025-11-10 18:40:24+00:00,"cs.LG, cs.AI, math.OC, stat.ML"
2511.07377v1,Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion,"LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.","June Moh Goo, Zichao Zeng, Jan Boehm",arXiv,2025,2025-11-10 18:38:15+00:00,"cs.CV, cs.AI, cs.RO"
2511.07372v1,"Provable Benefit of Curriculum in Transformer Tree-Reasoning
  Post-Training","Recent curriculum techniques in the post-training stage of LLMs have been
widely observed to outperform non-curriculum approaches in enhancing reasoning
performance, yet a principled understanding of why and to what extent they work
remains elusive. To address this gap, we develop a theoretical framework
grounded in the intuition that progressively learning through manageable steps
is more efficient than directly tackling a hard reasoning task, provided each
stage stays within the model's effective competence. Under mild complexity
conditions linking consecutive curriculum stages, we show that curriculum
post-training avoids the exponential complexity bottleneck.
  To substantiate this result, drawing insights from the Chain-of-Thoughts
(CoTs) solving mathematical problems such as Countdown and parity, we model CoT
generation as a states-conditioned autoregressive reasoning tree, define a
uniform-branching base model to capture pretrained behavior, and formalize
curriculum stages as either depth-increasing (longer reasoning chains) or
hint-decreasing (shorter prefixes) subtasks. Our analysis shows that, under
outcome-only reward signals, reinforcement learning finetuning achieves high
accuracy with polynomial sample complexity, whereas direct learning suffers
from an exponential bottleneck. We further establish analogous guarantees for
test-time scaling, where curriculum-aware querying reduces both reward oracle
calls and sampling cost from exponential to polynomial order.","Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Hau-San Wong, Qingfu Zhang, Taiji Suzuki",arXiv,2025,2025-11-10 18:29:54+00:00,cs.LG
2511.07368v1,"Consistency Is Not Always Correct: Towards Understanding the Role of
  Exploration in Post-Training Reasoning","Foundation models exhibit broad knowledge but limited task-specific
reasoning, motivating post-training strategies such as RLVR and inference
scaling with outcome or process reward models (ORM/PRM). While recent work
highlights the role of exploration and entropy stability in improving pass@K,
empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce
existing tree-like reasoning paths rather than expanding the reasoning scope,
raising the question of why exploration helps at all if no new patterns emerge.
  To reconcile this paradox, we adopt the perspective of Kim et al. (2025),
viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a
symmetry) reasoning steps as low- versus high-probability Markov transitions,
and formalize post-training dynamics through Multi-task Tree-structured Markov
Chains (TMC). In this tractable model, pretraining corresponds to tree
expansion, while post-training corresponds to chain-of-thought reweighting. We
show that several phenomena recently observed in empirical studies arise
naturally in this setting: (1) RLVR induces a squeezing effect, reducing
reasoning entropy and forgetting some correct paths; (2) population rewards of
ORM/PRM encourage consistency rather than accuracy, thereby favoring common
patterns; and (3) certain rare, high-uncertainty reasoning paths by the base
model are responsible for solving hard problem instances.
  Together, these explain why exploration -- even when confined to the base
model's reasoning scope -- remains essential: it preserves access to rare but
crucial reasoning traces needed for difficult cases, which are squeezed out by
RLVR or unfavored by inference scaling. Building on this, we further show that
exploration strategies such as rejecting easy instances and KL regularization
help preserve rare reasoning traces. Empirical simulations corroborate our
theoretical results.","Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang, Hau-San Wong, Taiji Suzuki",arXiv,2025,2025-11-10 18:25:26+00:00,"cs.LG, cs.AI"
2511.07367v1,Machine-Learning Accelerated Calculations of Reduced Density Matrices,"$n$-particle reduced density matrices ($n$-RDMs) play a central role in
understanding correlated phases of matter. Yet the calculation of $n$-RDMs is
often computationally inefficient for strongly-correlated states, particularly
when the system sizes are large. In this work, we propose to use neural network
(NN) architectures to accelerate the calculation of, and even predict, the
$n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs are
often smooth functions over the Brillouin zone (BZ) (certainly true for gapped
states) and are thus interpolable, allowing NNs trained on small-size $n$-RDMs
to predict large-size ones. Building on this intuition, we devise two NNs: (i)
a self-attention NN that maps random RDMs to physical ones, and (ii) a
Sinusoidal Representation Network (SIREN) that directly maps momentum-space
coordinates to RDM values. We test the NNs in three 2D models: the pair-pair
correlation functions of the Richardson model of superconductivity, the
translationally-invariant 1-RDM in a four-band model with short-range
repulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model.
We find that a SIREN trained on a $6\times 6$ momentum mesh can predict the
$18\times 18$ pair-pair correlation function with a relative accuracy of
$0.839$. The NNs trained on $6\times 6 \sim 8\times 8$ meshes can provide
high-quality initial guesses for $50\times 50$ translation-invariant
Hartree-Fock (HF) and $30\times 30$ fully translation-breaking-allowed HF,
reducing the number of iterations required for convergence by up to $91.63\%$
and $92.78\%$, respectively, compared to random initializations. Our results
illustrate the potential of using NN-based methods for interpolable $n$-RDMs,
which might open a new avenue for future research on strongly correlated
phases.","Awwab A. Azam, Lexu Zhao, Jiabin Yu",arXiv,2025,2025-11-10 18:23:34+00:00,"cond-mat.str-el, cs.AI"
2511.07366v1,"UAV-Assisted Resilience in 6G and Beyond Network Energy Saving: A
  Multi-Agent DRL Approach","This paper investigates the unmanned aerial vehicle (UAV)-assisted resilience
perspective in the 6G network energy saving (NES) scenario. More specifically,
we consider multiple ground base stations (GBSs) and each GBS has three
different sectors/cells in the terrestrial networks, and multiple cells are
turned off due to NES or incidents, e.g., disasters, hardware failures, or
outages. To address this, we propose a Multi-Agent Deep Deterministic Policy
Gradient (MADDPG) framework to enable UAV-assisted communication by jointly
optimizing UAV trajectories, transmission power, and user-UAV association under
a sleeping ground base station (GBS) strategy. This framework aims to ensure
the resilience of active users in the network and the long-term operability of
UAVs. Specifically, it maximizes service coverage for users during power
outages or NES zones, while minimizing the energy consumption of UAVs.
Simulation results demonstrate that the proposed MADDPG policy consistently
achieves high coverage ratio across different testing episodes, outperforming
other baselines. Moreover, the MADDPG framework attains the lowest total energy
consumption, with a reduction of approximately 24\% compared to the
conventional all GBS ON configuration, while maintaining a comparable user
service rate. These results confirm the effectiveness of the proposed approach
in achieving a superior trade-off between energy efficiency and service
performance, supporting the development of sustainable and resilient
UAV-assisted cellular networks.","Dao Lan Vy Dinh, Anh Nguyen Thi Mai, Hung Tran, Giang Quynh Le Vu, Tu Dac Ho, Zhenni Pan, Vo Nhan Van, Symeon Chatzinotas, Dinh-Hieu Tran",arXiv,2025,2025-11-10 18:23:03+00:00,"cs.NI, cs.LG"
2511.07365v1,Private Sketches for Linear Regression,"Linear regression is frequently applied in a variety of domains. In order to
improve the efficiency of these methods, various methods have been developed
that compute summaries or \emph{sketches} of the datasets. Certain domains,
however, contain sensitive data which necessitates that the application of
these statistical methods does not reveal private information. Differentially
private (DP) linear regression methods have been developed for mitigating this
problem. These techniques typically involve estimating a noisy version of the
parameter vector. Instead, we propose releasing private sketches of the
datasets. We present differentially private sketches for the problems of least
squares regression, as well as least absolute deviations regression. The
availability of these private sketches facilitates the application of commonly
available solvers for regression, without the risk of privacy leakage.","Shrutimoy Das, Debanuj Nayak, Anirban Dasgupta",arXiv,2025,2025-11-10 18:22:40+00:00,"cs.LG, stat.ML"
2511.07364v1,"Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence
  Estimation for Failure Detection","Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.","Vaibhav Mavi, Shubh Jaroria, Weiqi Sun",arXiv,2025,2025-11-10 18:19:51+00:00,"cs.LG, cs.AI, cs.CL"
2511.07362v1,Inference-Time Scaling of Diffusion Models for Infrared Data Generation,"Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.","Kai A. Horstmann, Maxim Clouser, Kia Khezeli",arXiv,2025,2025-11-10 18:18:38+00:00,"cs.CV, cs.AI, cs.LG"
2511.07347v1,"Walsh-Hadamard Neural Operators for Solving PDEs with Discontinuous
  Coefficients","Neural operators have emerged as powerful tools for learning solution
operators of partial differential equations (PDEs). However, standard spectral
methods based on Fourier transforms struggle with problems involving
discontinuous coefficients due to the Gibbs phenomenon and poor representation
of sharp interfaces. We introduce the Walsh-Hadamard Neural Operator (WHNO),
which leverages Walsh-Hadamard transforms-a spectral basis of rectangular wave
functions naturally suited for piecewise constant fields-combined with
learnable spectral weights that transform low-sequency Walsh coefficients to
capture global dependencies efficiently. We validate WHNO on three problems:
steady-state Darcy flow (preliminary validation), heat conduction with
discontinuous thermal conductivity, and the 2D Burgers equation with
discontinuous initial conditions. In controlled comparisons with Fourier Neural
Operators (FNO) under identical conditions, WHNO demonstrates superior accuracy
with better preservation of sharp solution features at material interfaces.
Critically, we discover that weighted ensemble combinations of WHNO and FNO
achieve substantial improvements over either model alone: for both heat
conduction and Burgers equation, optimal ensembles reduce mean squared error by
35-40 percent and maximum error by up to 25 percent compared to individual
models. This demonstrates that Walsh-Hadamard and Fourier representations
capture complementary aspects of discontinuous PDE solutions, with WHNO
excelling at sharp interfaces while FNO captures smooth features effectively.","Giorrgio M. Cavallazzi, Miguel Perex Cuadrado, Alfredo Pinelli",arXiv,2025,2025-11-10 17:49:20+00:00,"physics.comp-ph, cs.LG"
2511.07343v1,TNT: Improving Chunkwise Training for Test-Time Memorization,"Recurrent neural networks (RNNs) with deep test-time memorization modules,
such as Titans and TTT, represent a promising, linearly-scaling paradigm
distinct from Transformers. While these expressive models do not yet match the
peak performance of state-of-the-art Transformers, their potential has been
largely untapped due to prohibitively slow training and low hardware
utilization. Existing parallelization methods force a fundamental conflict
governed by the chunksize hyperparameter: large chunks boost speed but degrade
performance, necessitating a fixed, suboptimal compromise. To solve this
challenge, we introduce TNT, a novel training paradigm that decouples training
efficiency from inference performance through a two-stage process. Stage one is
an efficiency-focused pre-training phase utilizing a hierarchical memory. A
global module processes large, hardware-friendly chunks for long-range context,
while multiple parallel local modules handle fine-grained details. Crucially,
by periodically resetting local memory states, we break sequential dependencies
to enable massive context parallelization. Stage two is a brief fine-tuning
phase where only the local memory modules are adapted to a smaller,
high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated
on Titans and TTT models, TNT achieves a substantial acceleration in training
speed-up to 17 times faster than the most accurate baseline configuration -
while simultaneously improving model accuracy. This improvement removes a
critical scalability barrier, establishing a practical foundation for
developing expressive RNNs and facilitating future work to close the
performance gap with Transformers.","Zeman Li, Ali Behrouz, Yuan Deng, Peilin Zhong, Praneeth Kacham, Mahdi Karami, Meisam Razaviyayn, Vahab Mirrokni",arXiv,2025,2025-11-10 17:45:09+00:00,"cs.LG, cs.AI"
2511.07339v1,GiBS: Generative Input-side Basis-driven Structures,"Designing large-scale metasurfaces with nonlocal optical effects remains
challenging due to the immense dimensionality and fabrication constraints of
conventional optimization methods. We introduce GiBS (Generative Input-side
Basis-driven Structures), an inverse-design framework that represents the
entire device using a compact set of coefficients from smooth parametric bases
such as Fourier or Chebyshev functions. This formulation compresses the design
space by more than an order of magnitude, enabling efficient optimization of
complex, broadband, and aperiodic geometries. GiBS integrates this
low-dimensional representation with an autoencoder-based manifold-learning
workflow to map the relationship between geometry and optical response,
facilitating rapid exploration, discovery of high-performance designs, and
systematic analysis of fabrication sensitivity. The inherent smoothness of the
basis functions ensures manufacturability while capturing the asymmetry
required for nonlocal optical interactions. We experimentally validated the
framework through the realization of a PEDOT:PSS broadband scattering
metasurface, whose measured response closely matched full-wave simulations
across 500-1100 nm. These results establish GiBS as a scalable, data-efficient,
and fabrication-aware platform for the inverse design of multifunctional
metasurfaces, bridging AI-guided representation learning with experimentally
realizable photonic architectures.","Reza Marzban, Ashkan Zandi, Ali Adibi",arXiv,2025,2025-11-10 17:40:12+00:00,physics.optics
2511.07338v1,DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas,"Simulating human profiles by instilling personas into large language models
(LLMs) is rapidly transforming research in agentic behavioral simulation, LLM
personalization, and human-AI alignment. However, most existing synthetic
personas remain shallow and simplistic, capturing minimal attributes and
failing to reflect the rich complexity and diversity of real human identities.
We introduce DEEPPERSONA, a scalable generative engine for synthesizing
narrative-complete synthetic personas through a two-stage, taxonomy-guided
method. First, we algorithmically construct the largest-ever human-attribute
taxonomy, comprising over hundreds of hierarchically organized attributes, by
mining thousands of real user-ChatGPT conversations. Second, we progressively
sample attributes from this taxonomy, conditionally generating coherent and
realistic personas that average hundreds of structured attributes and roughly 1
MB of narrative text, two orders of magnitude deeper than prior works.
Intrinsic evaluations confirm significant improvements in attribute diversity
(32 percent higher coverage) and profile uniqueness (44 percent greater)
compared to state-of-the-art baselines. Extrinsically, our personas enhance
GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on
average across ten metrics and substantially narrow (by 31.7 percent) the gap
between simulated LLM citizens and authentic human responses in social surveys.
Our generated national citizens reduced the performance gap on the Big Five
personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA
thus provides a rigorous, scalable, and privacy-free platform for high-fidelity
human simulation and personalized AI research.","Zhen Wang, Yufan Zhou, Zhongyan Luo, Lyumanshan Ye, Adam Wood, Man Yao, Luoshang Pan",arXiv,2025,2025-11-10 17:37:56+00:00,"cs.AI, cs.LG, 68T07, 68T20, I.2.7; I.2.6; I.2.11"
2511.07332v1,Grounding Computer Use Agents on Human Demonstrations,"Building reliable computer-use agents requires grounding: accurately
connecting natural language instructions to the correct on-screen elements.
While large datasets exist for web and mobile interactions, high-quality
resources for desktop environments are limited. To address this gap, we
introduce GroundCUA, a large-scale desktop grounding dataset built from expert
human demonstrations. It covers 87 applications across 12 categories and
includes 56K screenshots, with every on-screen element carefully annotated for
a total of over 3.56M human-verified annotations. From these demonstrations, we
generate diverse instructions that capture a wide range of real-world tasks,
providing high-quality data for model training. Using GroundCUA, we develop the
GroundNext family of models that map instructions to their target UI elements.
At both 3B and 7B scales, GroundNext achieves state-of-the-art results across
five benchmarks using supervised fine-tuning, while requiring less than
one-tenth the training data of prior work. Reinforcement learning post-training
further improves performance, and when evaluated in an agentic setting on the
OSWorld benchmark using o3 as planner, GroundNext attains comparable or
superior results to models trained with substantially more data,. These results
demonstrate the critical role of high-quality, expert-driven datasets in
advancing general-purpose computer-use agents.","Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar",arXiv,2025,2025-11-10 17:35:21+00:00,"cs.LG, cs.AI"
2511.07329v1,"Preparation of Fractal-Inspired Computational Architectures for Advanced
  Large Language Model Analysis","It introduces FractalNet, a fractal-inspired computational architectures for
advanced large language model analysis that mainly challenges model diversity
on a large scale in an efficient manner. The new set-up involves a
template-driven generator, runner, and evaluation framework that, through
systematic permutations of convolutional, normalization, activation, and
dropout layers, can create more than 1,200 variants of neural networks. Fractal
templates allow for structural recursion and multi-column pathways, thus,
models become deeper and wider in a balanced way. Training utilizes PyTorch,
Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out
on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based
architectures are capable of strong performance and are computationally
efficient. The paper positions fractal design as a feasible and
resource-efficient method of automated architecture exploration.","Yash Mittal, Dmitry Ignatov, Radu Timofte",arXiv,2025,2025-11-10 17:31:39+00:00,"cs.LG, cs.CV"
2511.07328v1,"Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder
  Training","Retrieval-Augmented Generation (RAG) methods enhance LLM performance by
efficiently filtering relevant context for LLMs, reducing hallucinations and
inference cost. However, most existing RAG methods focus on single-step
retrieval, which is often insufficient for answering complex questions that
require multi-step search. Recently, multi-step retrieval approaches have
emerged, typically involving the fine-tuning of small LLMs to perform
multi-step retrieval. This type of fine-tuning is highly resource-intensive and
does not enable the use of larger LLMs. In this work, we propose Q-RAG, a novel
approach that fine-tunes the Embedder model for multi-step retrieval using
reinforcement learning (RL). Q-RAG offers a competitive, resource-efficient
alternative to existing multi-step retrieval methods for open-domain question
answering and achieves state-of-the-art results on the popular long-context
benchmarks Babilong and RULER for contexts up to 10M tokens.","Artyom Sorokin, Nazar Buzun, Alexander Anokhin, Oleg Inozemcev, Egor Vedernikov, Petr Anokhin, Mikhail Burtsev, Trushkov Alexey, Yin Wenshuai, Evgeny Burnaev",arXiv,2025,2025-11-10 17:31:02+00:00,"cs.LG, cs.IR"
2511.07327v1,"IterResearch: Rethinking Long-Horizon Agents via Markovian State
  Reconstruction","Recent advances in deep-research agents have shown promise for autonomous
knowledge construction through dynamic reasoning over external sources.
However, existing approaches rely on a mono-contextual paradigm that
accumulates all information in a single, expanding context window, leading to
context suffocation and noise contamination that limit their effectiveness on
long-horizon tasks. We introduce IterResearch, a novel iterative deep-research
paradigm that reformulates long-horizon research as a Markov Decision Process
with strategic workspace reconstruction. By maintaining an evolving report as
memory and periodically synthesizing insights, our approach preserves
consistent reasoning capacity across arbitrary exploration depths. We further
develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning
framework that incentivizes efficient exploration through geometric reward
discounting and enables stable distributed training via adaptive downsampling.
Extensive experiments demonstrate that IterResearch achieves substantial
improvements over existing open-source agents with average +14.5pp across six
benchmarks and narrows the gap with frontier proprietary systems. Remarkably,
our paradigm exhibits unprecedented interaction scaling, extending to 2048
interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves
as an effective prompting strategy, improving frontier models by up to 19.2pp
over ReAct on long-horizon tasks. These findings position IterResearch as a
versatile solution for long-horizon reasoning, effective both as a trained
agent and as a prompting paradigm for frontier models.","Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",arXiv,2025,2025-11-10 17:30:08+00:00,"cs.AI, cs.CL"
2511.07325v1,Garbage Vulnerable Point Monitoring using IoT and Computer Vision,"This paper proposes a smart way to manage municipal solid waste by using the
Internet of Things (IoT) and computer vision (CV) to monitor illegal waste
dumping at garbage vulnerable points (GVPs) in urban areas. The system can
quickly detect and monitor dumped waste using a street-level camera and object
detection algorithm. Data was collected from the Sangareddy district in
Telangana, India. A series of comprehensive experiments was carried out using
the proposed dataset to assess the accuracy and overall performance of various
object detection models. Specifically, we performed an in-depth evaluation of
YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models,
YOLO11m achieved the highest accuracy of 92.39\% in waste detection,
demonstrating its effectiveness in detecting waste. Additionally, it attains an
mAP@50 of 0.91, highlighting its high precision. These findings confirm that
the object detection model is well-suited for monitoring and tracking waste
dumping events at GVP locations. Furthermore, the system effectively captures
waste disposal patterns, including hourly, daily, and weekly dumping trends,
ensuring comprehensive daily and nightly monitoring.","R. Kumar, A. Lall, S. Chaudhari, M. Kale, A. Vattem",arXiv,2025,2025-11-10 17:27:51+00:00,"cs.CV, cs.LG"
2511.07322v1,"FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework
  for Equity Research Report Generation","While LLMs have shown great success in financial tasks like stock prediction
and question answering, their application in fully automating Equity Research
Report generation remains uncharted territory. In this paper, we formulate the
Equity Research Report (ERR) Generation task for the first time. To address the
data scarcity and the evaluation metrics absence, we present an open-source
evaluation benchmark for ERR generation - FinRpt. We frame a Dataset
Construction Pipeline that integrates 7 financial data types and produces a
high-quality ERR dataset automatically, which could be used for model training
and evaluation. We also introduce a comprehensive evaluation system including
11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent
framework specifically tailored to address this task, named FinRpt-Gen, and
train several LLM-based agents on the proposed datasets using Supervised
Fine-Tuning and Reinforcement Learning. Experimental results indicate the data
quality and metrics effectiveness of the benchmark FinRpt and the strong
performance of FinRpt-Gen, showcasing their potential to drive innovation in
the ERR generation field. All code and datasets are publicly available.","Song Jin, Shuqi Li, Shukun Zhang, Rui Yan",arXiv,2025,2025-11-10 17:22:32+00:00,"cs.CL, cs.AI"
2511.07321v1,YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting,"Fast and flexible 3D scene reconstruction from unstructured image collections
remains a significant challenge. We present YoNoSplat, a feedforward model that
reconstructs high-quality 3D Gaussian Splatting representations from an
arbitrary number of images. Our model is highly versatile, operating
effectively with both posed and unposed, calibrated and uncalibrated inputs.
YoNoSplat predicts local Gaussians and camera poses for each view, which are
aggregated into a global representation using either predicted or provided
poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and
camera parameters, we introduce a novel mixing training strategy. This approach
mitigates the entanglement between the two tasks by initially using
ground-truth poses to aggregate local Gaussians and gradually transitioning to
a mix of predicted and ground-truth poses, which prevents both training
instability and exposure bias. We further resolve the scale ambiguity problem
by a novel pairwise camera-distance normalization scheme and by embedding
camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic
parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates
exceptional efficiency, reconstructing a scene from 100 views (at 280x518
resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves
state-of-the-art performance on standard benchmarks in both pose-free and
pose-dependent settings. Our project page is at
https://botaoye.github.io/yonosplat/.","Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, Marc Pollefeys",arXiv,2025,2025-11-10 17:21:54+00:00,cs.CV
2511.07318v1,"When Bias Pretends to Be Truth: How Spurious Correlations Undermine
  Hallucination Detection in LLMs","Despite substantial advances, large language models (LLMs) continue to
exhibit hallucinations, generating plausible yet incorrect responses. In this
paper, we highlight a critical yet previously underexplored class of
hallucinations driven by spurious correlations -- superficial but statistically
prominent associations between features (e.g., surnames) and attributes (e.g.,
nationality) present in the training data. We demonstrate that these spurious
correlations induce hallucinations that are confidently generated, immune to
model scaling, evade current detection methods, and persist even after refusal
fine-tuning. Through systematically controlled synthetic experiments and
empirical evaluations on state-of-the-art open-source and proprietary LLMs
(including GPT-5), we show that existing hallucination detection methods, such
as confidence-based filtering and inner-state probing, fundamentally fail in
the presence of spurious correlations. Our theoretical analysis further
elucidates why these statistical biases intrinsically undermine
confidence-based detection techniques. Our findings thus emphasize the urgent
need for new approaches explicitly designed to address hallucinations caused by
spurious correlations.","Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun, Kaifeng Lyu, Jian Li",arXiv,2025,2025-11-10 17:19:27+00:00,"cs.CL, cs.AI, cs.LG"
2511.07317v1,"RLVE: Scaling Up Reinforcement Learning for Language Models with
  Adaptive Verifiable Environments","We introduce Reinforcement Learning (RL) with Adaptive Verifiable
Environments (RLVE), an approach using verifiable environments that
procedurally generate problems and provide algorithmically verifiable rewards,
to scale up RL for language models (LMs). RLVE enables each verifiable
environment to dynamically adapt its problem difficulty distribution to the
policy model's capabilities as training progresses. In contrast, static data
distributions often lead to vanishing learning signals when problems are either
too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a
large-scale suite of 400 verifiable environments carefully developed through
manual environment engineering. Using RLVE-Gym, we show that environment
scaling, i.e., expanding the collection of training environments, consistently
improves generalizable reasoning capabilities. RLVE with joint training across
all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement
across six reasoning benchmarks, starting from one of the strongest 1.5B
reasoning LMs. By comparison, continuing this LM's original RL training yields
only a 0.49% average absolute gain despite using over 3x more compute. We
release our code publicly.","Zhiyuan Zeng, Hamish Ivison, Yiping Wang, Lifan Yuan, Shuyue Stella Li, Zhuorui Ye, Siting Li, Jacqueline He, Runlong Zhou, Tong Chen, Chenyang Zhao, Yulia Tsvetkov, Simon Shaolei Du, Natasha Jaques, Hao Peng, Pang Wei Koh, Hannaneh Hajishirzi",arXiv,2025,2025-11-10 17:18:35+00:00,"cs.CL, cs.LG"
2511.07313v1,"De-Individualizing fMRI Signals via Mahalanobis Whitening and Bures
  Geometry","Functional connectivity has been widely investigated to understand brain
disease in clinical studies and imaging-based neuroscience, and analyzing
changes in functional connectivity has proven to be valuable for understanding
and computationally evaluating the effects on brain function caused by diseases
or experimental stimuli. By using Mahalanobis data whitening prior to the use
of dimensionality reduction algorithms, we are able to distill meaningful
information from fMRI signals about subjects and the experimental stimuli used
to prompt them. Furthermore, we offer an interpretation of Mahalanobis
whitening as a two-stage de-individualization of data which is motivated by
similarity as captured by the Bures distance, which is connected to quantum
mechanics. These methods have potential to aid discoveries about the mechanisms
that link brain function with cognition and behavior and may improve the
accuracy and consistency of Alzheimer's diagnosis, especially in the
preclinical stage of disease progression.","Aaron Jacobson, Tingting Dan, Martin Styner, Guorong Wu, Shahar Kovalsky, Caroline Moosmueller",arXiv,2025,2025-11-10 17:14:48+00:00,"q-bio.NC, cs.LG, q-bio.QM, 92-08, 68T10, 62H310, I.5.3; J.3"
2511.07312v1,"Superhuman AI for Stratego Using Self-Play Reinforcement Learning and
  Test-Time Search","Few classical games have been regarded as such significant benchmarks of
artificial intelligence as to have justified training costs in the millions of
dollars. Among these, Stratego -- a board wargame exemplifying the challenge of
strategic decision making under massive amounts of hidden information -- stands
apart as a case where such efforts failed to produce performance at the level
of top humans. This work establishes a step change in both performance and cost
for Stratego, showing that it is now possible not only to reach the level of
top humans, but to achieve vastly superhuman level -- and that doing so
requires not an industrial budget, but merely a few thousand dollars. We
achieved this result by developing general approaches for self-play
reinforcement learning and test-time search under imperfect information.","Samuel Sokota, Eugene Vinitsky, Hengyuan Hu, J. Zico Kolter, Gabriele Farina",arXiv,2025,2025-11-10 17:13:41+00:00,"cs.LG, cs.AI"
2511.07308v1,"Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by
  the Thermodynamics of an Ideal Gas?","Understanding the training dynamics of deep neural networks remains a major
open problem, with physics-inspired approaches offering promising insights.
Building on this perspective, we develop a thermodynamic framework to describe
the stationary distributions of stochastic gradient descent (SGD) with weight
decay for scale-invariant neural networks, a setting that both reflects
practical architectures with normalization layers and permits theoretical
analysis. We establish analogies between training hyperparameters (e.g.,
learning rate, weight decay) and thermodynamic variables such as temperature,
pressure, and volume. Starting with a simplified isotropic noise model, we
uncover a close correspondence between SGD dynamics and ideal gas behavior,
validated through theory and simulation. Extending to training of neural
networks, we show that key predictions of the framework, including the behavior
of stationary entropy, align closely with experimental observations. This
framework provides a principled foundation for interpreting training dynamics
and may guide future work on hyperparameter tuning and the design of learning
rate schedulers.","Ildus Sadrtdinov, Ekaterina Lobacheva, Ivan Klimov, Mikhail I. Katsnelson, Dmitry Vetrov",arXiv,2025,2025-11-10 17:10:01+00:00,cs.LG
2511.07304v1,"Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task
  Learning Approach for Bangla Hate Speech Identification","This paper addresses the problem of Bangla hate speech identification, a
socially impactful yet linguistically challenging task. As part of the ""Bangla
Multi-task Hate Speech Identification"" shared task at the BLP Workshop,
IJCNLP-AACL 2025, our team ""Retriv"" participated in all three subtasks: (1A)
hate type classification, (1B) target group identification, and (1C) joint
detection of type, severity, and target. For subtasks 1A and 1B, we employed a
soft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2).
For subtask 1C, we trained three multitask variants and aggregated their
predictions through a weighted voting ensemble. Our systems achieved micro-f1
scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62%
(1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7th
positions, respectively. These results highlight the promise of transformer
ensembles and weighted multitask frameworks for advancing Bangla hate speech
detection in low-resource contexts. We made experimental scripts publicly
available for the community.","Sourav Saha, K M Nafi Asib, Mohammed Moshiul Hoque",arXiv,2025,2025-11-10 17:07:09+00:00,cs.CL
2511.07301v1,"Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free
  Object Detection","Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
detector to a target domain without access to source data. However, existing
SFOD methods predominantly rely on internal knowledge from the source model,
which limits their capacity to generalize across domains and often results in
biased pseudo-labels, thereby hindering both transferability and
discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
massive and diverse data, exhibit strong perception capabilities and broad
generalization, yet their potential remains largely untapped in the SFOD
setting. In this paper, we propose a novel SFOD framework that leverages VFMs
as external knowledge sources to jointly enhance feature alignment and label
quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
Global Feature Alignment (PGFA) distills global features from VFMs using
patch-similarity-based weighting to enhance global feature transferability; (2)
Prototype-based Instance Feature Alignment (PIFA) performs instance-level
contrastive learning guided by momentum-updated VFM prototypes; and (3)
Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
detection VFMs and teacher models via an entropy-aware strategy to yield more
reliable supervision. Extensive experiments on six benchmarks demonstrate that
our method achieves state-of-the-art SFOD performance, validating the
effectiveness of integrating VFMs to simultaneously improve transferability and
discriminability.","Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu, Hui Xiong",arXiv,2025,2025-11-10 17:06:01+00:00,"cs.CV, cs.AI"
2511.07295v1,"Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender
  Systems via Large Language Models","Implicit feedback, employed in training recommender systems, unavoidably
confronts noise due to factors such as misclicks and position bias. Previous
studies have attempted to identify noisy samples through their diverged data
patterns, such as higher loss values, and mitigate their influence through
sample dropping or reweighting. However, we observed that noisy samples and
hard samples display similar patterns, leading to hard-noisy confusion issue.
Such confusion is problematic as hard samples are vital for modeling user
preferences. To solve this problem, we propose LLMHNI framework, leveraging two
auxiliary user-item relevance signals generated by Large Language Models (LLMs)
to differentiate hard and noisy samples. LLMHNI obtains user-item semantic
relevance from LLM-encoded embeddings, which is used in negative sampling to
select hard negatives while filtering out noisy false negatives. An objective
alignment strategy is proposed to project LLM-encoded embeddings, originally
for general language tasks, into a representation space optimized for user-item
relevance modeling. LLMHNI also exploits LLM-inferred logical relevance within
user-item interactions to identify hard and noisy samples. These LLM-inferred
interactions are integrated into the interaction graph and guide denoising with
cross-graph contrastive alignment. To eliminate the impact of unreliable
interactions induced by LLM hallucination, we propose a graph contrastive
learning strategy that aligns representations from randomly edge-dropped views
to suppress unreliable edges. Empirical results demonstrate that LLMHNI
significantly improves denoising and recommendation performance.","Tianrui Song, Wen-Shuo Chao, Hao Liu",arXiv,2025,2025-11-10 16:51:03+00:00,"cs.IR, cs.AI"
2511.07292v1,PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving,"Most recent work in autonomous driving has prioritized benchmark performance
and methodological innovation over in-depth analysis of model failures, biases,
and shortcut learning. This has led to incremental improvements without a deep
understanding of the current failures. While it is straightforward to look at
situations where the model fails, it is hard to understand the underlying
reason. This motivates us to conduct a systematic study, where inputs to the
model are perturbed and the predictions observed. We introduce PlanT 2.0, a
lightweight, object-centric planning transformer designed for autonomous
driving research in CARLA. The object-level representation enables controlled
analysis, as the input can be easily perturbed (e.g., by changing the location
or adding or removing certain objects), in contrast to sensor-based models. To
tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0,
we introduce multiple upgrades to PlanT, achieving state-of-the-art performance
on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis
exposes insightful failures, such as a lack of scene understanding caused by
low obstacle diversity, rigid expert behaviors leading to exploitable
shortcuts, and overfitting to a fixed set of expert trajectories. Based on
these findings, we argue for a shift toward data-centric development, with a
focus on richer, more robust, and less biased datasets. We open-source our code
and model at https://github.com/autonomousvision/plant2.","Simon Gerstenecker, Andreas Geiger, Katrin Renz",arXiv,2025,2025-11-10 16:41:47+00:00,"cs.RO, cs.CV"
2511.07418v1,"Lightning Grasp: High Performance Procedural Grasp Synthesis with
  Contact Fields","Despite years of research, real-time diverse grasp synthesis for dexterous
hands remains an unsolved core challenge in robotics and computer graphics. We
present Lightning Grasp, a novel high-performance procedural grasp synthesis
algorithm that achieves orders-of-magnitude speedups over state-of-the-art
approaches, while enabling unsupervised grasp generation for irregular,
tool-like objects. The method avoids many limitations of prior approaches, such
as the need for carefully tuned energy functions and sensitive initialization.
This breakthrough is driven by a key insight: decoupling complex geometric
computation from the search process via a simple, efficient data structure -
the Contact Field. This abstraction collapses the problem complexity, enabling
a procedural search at unprecedented speeds. We open-source our system to
propel further innovation in robotic manipulation.","Zhao-Heng Yin, Pieter Abbeel",arXiv,2025,2025-11-10 18:59:44+00:00,"cs.RO, cs.AI, cs.CV, cs.DC, cs.GR"
2511.07417v1,Language Generation with Infinite Contamination,"We study language generation in the limit, where an algorithm observes an
adversarial enumeration of strings from an unknown target language $K$ and must
eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan
[KM24] proved that generation is achievable in surprisingly general settings.
But their generator suffers from ``mode collapse,'' producing from an
ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25]
require the generator's output to be ``dense'' in the target language. They
showed that generation with density, surprisingly, remains achievable at the
same generality.
  Both results assume perfect data: no noisy insertions and no omissions. This
raises a central question: how much contamination can generation tolerate?
Recent works made partial progress on this question by studying (non-dense)
generation with either finite amounts of noise (but no omissions) or omissions
(but no noise).
  We characterize robustness under contaminated enumerations: 1. Generation
under Contamination: Language generation in the limit is achievable for all
countable collections iff the fraction of contaminated examples converges to
zero. When this fails, we characterize which collections are generable. 2.
Dense Generation under Contamination: Dense generation is strictly less robust
to contamination than generation. As a byproduct, we resolve an open question
of Raman and Raman [ICML25] by showing that generation is possible with only
membership oracle access under finitely many contaminated examples.
  Finally, we introduce a beyond-worst-case model inspired by curriculum
learning and prove that dense generation is achievable even with infinite
contamination provided the fraction of contaminated examples converges to zero.
This suggests curriculum learning may be crucial for learning from noisy web
data.","Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou",arXiv,2025,2025-11-10 18:59:39+00:00,"stat.ML, cs.AI, cs.CL, cs.DS, cs.LG"
2511.07416v1,Robot Learning from a Physical World Model,"We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.","Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang",arXiv,2025,2025-11-10 18:59:07+00:00,"cs.RO, cs.AI, cs.CV"
2511.07413v1,DigiData: Training and Evaluating General-Purpose Mobile Control Agents,"AI agents capable of controlling user interfaces have the potential to
transform human interaction with digital devices. To accelerate this
transformation, two fundamental building blocks are essential: high-quality
datasets that enable agents to achieve complex and human-relevant goals, and
robust evaluation methods that allow researchers and practitioners to rapidly
enhance agent performance. In this paper, we introduce DigiData, a large-scale,
high-quality, diverse, multi-modal dataset designed for training mobile control
agents. Unlike existing datasets, which derive goals from unstructured
interactions, DigiData is meticulously constructed through comprehensive
exploration of app features, resulting in greater diversity and higher goal
complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating
mobile control agents on real-world complex tasks. We demonstrate that the
commonly used step-accuracy metric falls short in reliably assessing mobile
control agents and, to address this, we propose dynamic evaluation protocols
and AI-powered evaluations as rigorous alternatives for agent assessment. Our
contributions aim to significantly advance the development of mobile control
agents, paving the way for more intuitive and effective human-device
interactions.","Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan, Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, Nitin Kamra, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer, Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway, Joseph Tighe",arXiv,2025,2025-11-10 18:57:35+00:00,"cs.AI, cs.CL, cs.HC, cs.LG"
2511.07412v1,"TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for
  Embodied AI Research","Developing embodied AI for intelligent surgical systems requires safe,
controllable environments for continual learning and evaluation. However,
safety regulations and operational constraints in operating rooms (ORs) limit
embodied agents from freely perceiving and interacting in realistic settings.
Digital twins provide high-fidelity, risk-free environments for exploration and
training. How we may create photorealistic and dynamic digital representations
of ORs that capture relevant spatial, visual, and behavioral complexity remains
unclear. We introduce TwinOR, a framework for constructing photorealistic,
dynamic digital twins of ORs for embodied AI research. The system reconstructs
static geometry from pre-scan videos and continuously models human and
equipment motion through multi-view perception of OR activities. The static and
dynamic components are fused into an immersive 3D environment that supports
controllable simulation and embodied exploration. The proposed framework
reconstructs complete OR geometry with centimeter level accuracy while
preserving dynamic interaction across surgical workflows, enabling realistic
renderings and a virtual playground for embodied AI systems. In our
experiments, TwinOR simulates stereo and monocular sensor streams for geometry
understanding and visual localization tasks. Models such as FoundationStereo
and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
reported accuracy on real indoor datasets, demonstrating that TwinOR provides
sensor-level realism sufficient for perception and localization challenges. By
establishing a real-to-sim pipeline for constructing dynamic, photorealistic
digital twins of OR environments, TwinOR enables the safe, scalable, and
data-efficient development and benchmarking of embodied AI, ultimately
accelerating the deployment of embodied AI from sim-to-real.","Han Zhang, Yiqing Shen, Roger D. Soberanis-Mukul, Ankita Ghosh, Hao Ding, Lalithkumar Seenivasan, Jose L. Porras, Zhekai Mao, Chenjia Li, Wenjie Xiao, Lonny Yarmus, Angela Christine Argento, Masaru Ishii, Mathias Unberath",arXiv,2025,2025-11-10 18:57:09+00:00,"cs.CV, cs.RO"
2511.07410v1,"Using Vision Language Models as Closed-Loop Symbolic Planners for
  Robotic Applications: A Control-Theoretic Perspective","Large Language Models (LLMs) and Vision Language Models (VLMs) have been
widely used for embodied symbolic planning. Yet, how to effectively use these
models for closed-loop symbolic planning remains largely unexplored. Because
they operate as black boxes, LLMs and VLMs can produce unpredictable or costly
errors, making their use in high-level robotic planning especially challenging.
In this work, we investigate how to use VLMs as closed-loop symbolic planners
for robotic applications from a control-theoretic perspective. Concretely, we
study how the control horizon and warm-starting impact the performance of VLM
symbolic planners. We design and conduct controlled experiments to gain
insights that are broadly applicable to utilizing VLMs as closed-loop symbolic
planners, and we discuss recommendations that can help improve the performance
of VLM symbolic planners.","Hao Wang, Sathwik Karnik, Bea Lim, Somil Bansal",arXiv,2025,2025-11-10 18:56:56+00:00,"cs.RO, cs.AI"
2511.07403v1,"SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial
  Rewards","Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.","Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark",arXiv,2025,2025-11-10 18:52:47+00:00,"cs.CV, cs.AI, cs.CL, cs.LG"
2511.07392v1,"Surgical Agent Orchestration Platform for Voice-directed Patient Data
  Interaction","In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in
the procedure, making it difficult to access and manipulate multimodal patient
data without interruption. We propose a voice-directed Surgical Agent
Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework,
consisting of an orchestration agent and three task-specific agents driven by
Large Language Models (LLMs). These LLM-based agents autonomously plan, refine,
validate, and reason to map voice commands into specific tasks such as
retrieving clinical information, manipulating CT scans, or navigating 3D
anatomical models on the surgical video. We also introduce a Multi-level
Orchestration Evaluation Metric (MOEM) to comprehensively assess the
performance and robustness from command-level and category-level perspectives.
The SAOP achieves high accuracy and success rates across 240 voice commands,
while LLM-based agents improve robustness against speech recognition errors and
diverse or ambiguous free-form commands, demonstrating strong potential to
support minimally invasive da Vinci robotic surgery.","Hyeryun Park, Byung Mo Gu, Jun Hee Lee, Byeong Hyeon Choi, Sekeun Kim, Hyun Koo Kim, Kyungsang Kim",arXiv,2025,2025-11-10 18:47:24+00:00,"cs.CL, cs.AI"
2511.07384v1,"Teaching Pretrained Language Models to Think Deeper with Retrofitted
  Recurrence","Recent advances in depth-recurrent language models show that recurrence can
decouple train-time compute and parameter count from test-time compute. In this
work, we study how to convert existing pretrained non-recurrent language models
into depth-recurrent models. We find that using a curriculum of recurrences to
increase the effective depth of the model over the course of training preserves
performance while reducing total computational cost. In our experiments, on
mathematics, we observe that converting pretrained models to recurrent ones
results in better performance at a given compute budget than simply
post-training the original non-recurrent language model.","Sean McLeish, Ang Li, John Kirchenbauer, Dayal Singh Kalra, Brian R. Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Jonas Geiping, Tom Goldstein, Micah Goldblum",arXiv,2025,2025-11-10 18:43:07+00:00,"cs.CL, cs.AI, cs.LG"
2511.07379v1,"LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic
  Graphs","Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes
domains, such as financial forecasting, recommendation systems, and fraud
detection. However, their susceptibility to poisoning attacks poses a critical
security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a
novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades
TGNN performance by an average of 29.47% across 4 widely benchmark datasets and
4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage
approach: (1) sparsify the graph by removing high-impact edges using any of the
16 tested temporal importance metrics, (2) strategically replace removed edges
with adversarial negatives via LoReTTA's novel degree-preserving negative
sampling algorithm. Our plug-and-play design eliminates the need for expensive
surrogate models while adhering to realistic unnoticeability constraints.
LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8%
on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains
undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA
adversarial defense training methods, establishing its effectiveness,
unnoticeability, and robustness.","Himanshu Pal, Venkata Sai Pranav Bachina, Ankit Gangwal, Charu Sharma",arXiv,2025,2025-11-10 18:41:02+00:00,"cs.LG, cs.AI"
2511.07378v1,"Transformers Provably Learn Chain-of-Thought Reasoning with Length
  Generalization","The ability to reason lies at the core of artificial intelligence (AI), and
challenging problems usually call for deeper and longer reasoning to tackle. A
crucial question about AI reasoning is whether models can extrapolate learned
reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In
this work, we present a theoretical analysis of transformers learning on
synthetic state-tracking tasks with gradient descent. We mathematically prove
how the algebraic structure of state-tracking problems governs the degree of
extrapolation of the learned CoT. Specifically, our theory characterizes the
length generalization of transformers through the mechanism of attention
concentration, linking the retrieval robustness of the attention layer to the
state-tracking task structure of long-context reasoning. Moreover, for
transformers with limited reasoning length, we prove that a recursive
self-training scheme can progressively extend the range of solvable problem
lengths. To our knowledge, we provide the first optimization guarantee that
constant-depth transformers provably learn $\mathsf{NC}^1$-complete problems
with CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$,
unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails.
Finally, we present a broad set of experiments supporting our theoretical
results, confirming the length generalization behaviors and the mechanism of
attention concentration.","Yu Huang, Zixin Wen, Aarti Singh, Yuejie Chi, Yuxin Chen",arXiv,2025,2025-11-10 18:40:24+00:00,"cs.LG, cs.AI, math.OC, stat.ML"
2511.07377v1,Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion,"LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.","June Moh Goo, Zichao Zeng, Jan Boehm",arXiv,2025,2025-11-10 18:38:15+00:00,"cs.CV, cs.AI, cs.RO"
2511.07368v1,"Consistency Is Not Always Correct: Towards Understanding the Role of
  Exploration in Post-Training Reasoning","Foundation models exhibit broad knowledge but limited task-specific
reasoning, motivating post-training strategies such as RLVR and inference
scaling with outcome or process reward models (ORM/PRM). While recent work
highlights the role of exploration and entropy stability in improving pass@K,
empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce
existing tree-like reasoning paths rather than expanding the reasoning scope,
raising the question of why exploration helps at all if no new patterns emerge.
  To reconcile this paradox, we adopt the perspective of Kim et al. (2025),
viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a
symmetry) reasoning steps as low- versus high-probability Markov transitions,
and formalize post-training dynamics through Multi-task Tree-structured Markov
Chains (TMC). In this tractable model, pretraining corresponds to tree
expansion, while post-training corresponds to chain-of-thought reweighting. We
show that several phenomena recently observed in empirical studies arise
naturally in this setting: (1) RLVR induces a squeezing effect, reducing
reasoning entropy and forgetting some correct paths; (2) population rewards of
ORM/PRM encourage consistency rather than accuracy, thereby favoring common
patterns; and (3) certain rare, high-uncertainty reasoning paths by the base
model are responsible for solving hard problem instances.
  Together, these explain why exploration -- even when confined to the base
model's reasoning scope -- remains essential: it preserves access to rare but
crucial reasoning traces needed for difficult cases, which are squeezed out by
RLVR or unfavored by inference scaling. Building on this, we further show that
exploration strategies such as rejecting easy instances and KL regularization
help preserve rare reasoning traces. Empirical simulations corroborate our
theoretical results.","Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang, Hau-San Wong, Taiji Suzuki",arXiv,2025,2025-11-10 18:25:26+00:00,"cs.LG, cs.AI"
2511.07367v1,Machine-Learning Accelerated Calculations of Reduced Density Matrices,"$n$-particle reduced density matrices ($n$-RDMs) play a central role in
understanding correlated phases of matter. Yet the calculation of $n$-RDMs is
often computationally inefficient for strongly-correlated states, particularly
when the system sizes are large. In this work, we propose to use neural network
(NN) architectures to accelerate the calculation of, and even predict, the
$n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs are
often smooth functions over the Brillouin zone (BZ) (certainly true for gapped
states) and are thus interpolable, allowing NNs trained on small-size $n$-RDMs
to predict large-size ones. Building on this intuition, we devise two NNs: (i)
a self-attention NN that maps random RDMs to physical ones, and (ii) a
Sinusoidal Representation Network (SIREN) that directly maps momentum-space
coordinates to RDM values. We test the NNs in three 2D models: the pair-pair
correlation functions of the Richardson model of superconductivity, the
translationally-invariant 1-RDM in a four-band model with short-range
repulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model.
We find that a SIREN trained on a $6\times 6$ momentum mesh can predict the
$18\times 18$ pair-pair correlation function with a relative accuracy of
$0.839$. The NNs trained on $6\times 6 \sim 8\times 8$ meshes can provide
high-quality initial guesses for $50\times 50$ translation-invariant
Hartree-Fock (HF) and $30\times 30$ fully translation-breaking-allowed HF,
reducing the number of iterations required for convergence by up to $91.63\%$
and $92.78\%$, respectively, compared to random initializations. Our results
illustrate the potential of using NN-based methods for interpolable $n$-RDMs,
which might open a new avenue for future research on strongly correlated
phases.","Awwab A. Azam, Lexu Zhao, Jiabin Yu",arXiv,2025,2025-11-10 18:23:34+00:00,"cond-mat.str-el, cs.AI"
2511.07364v1,"Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence
  Estimation for Failure Detection","Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.","Vaibhav Mavi, Shubh Jaroria, Weiqi Sun",arXiv,2025,2025-11-10 18:19:51+00:00,"cs.LG, cs.AI, cs.CL"
2511.07362v1,Inference-Time Scaling of Diffusion Models for Infrared Data Generation,"Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.","Kai A. Horstmann, Maxim Clouser, Kia Khezeli",arXiv,2025,2025-11-10 18:18:38+00:00,"cs.CV, cs.AI, cs.LG"
2511.07343v1,TNT: Improving Chunkwise Training for Test-Time Memorization,"Recurrent neural networks (RNNs) with deep test-time memorization modules,
such as Titans and TTT, represent a promising, linearly-scaling paradigm
distinct from Transformers. While these expressive models do not yet match the
peak performance of state-of-the-art Transformers, their potential has been
largely untapped due to prohibitively slow training and low hardware
utilization. Existing parallelization methods force a fundamental conflict
governed by the chunksize hyperparameter: large chunks boost speed but degrade
performance, necessitating a fixed, suboptimal compromise. To solve this
challenge, we introduce TNT, a novel training paradigm that decouples training
efficiency from inference performance through a two-stage process. Stage one is
an efficiency-focused pre-training phase utilizing a hierarchical memory. A
global module processes large, hardware-friendly chunks for long-range context,
while multiple parallel local modules handle fine-grained details. Crucially,
by periodically resetting local memory states, we break sequential dependencies
to enable massive context parallelization. Stage two is a brief fine-tuning
phase where only the local memory modules are adapted to a smaller,
high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated
on Titans and TTT models, TNT achieves a substantial acceleration in training
speed-up to 17 times faster than the most accurate baseline configuration -
while simultaneously improving model accuracy. This improvement removes a
critical scalability barrier, establishing a practical foundation for
developing expressive RNNs and facilitating future work to close the
performance gap with Transformers.","Zeman Li, Ali Behrouz, Yuan Deng, Peilin Zhong, Praneeth Kacham, Mahdi Karami, Meisam Razaviyayn, Vahab Mirrokni",arXiv,2025,2025-11-10 17:45:09+00:00,"cs.LG, cs.AI"
2511.07338v1,DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas,"Simulating human profiles by instilling personas into large language models
(LLMs) is rapidly transforming research in agentic behavioral simulation, LLM
personalization, and human-AI alignment. However, most existing synthetic
personas remain shallow and simplistic, capturing minimal attributes and
failing to reflect the rich complexity and diversity of real human identities.
We introduce DEEPPERSONA, a scalable generative engine for synthesizing
narrative-complete synthetic personas through a two-stage, taxonomy-guided
method. First, we algorithmically construct the largest-ever human-attribute
taxonomy, comprising over hundreds of hierarchically organized attributes, by
mining thousands of real user-ChatGPT conversations. Second, we progressively
sample attributes from this taxonomy, conditionally generating coherent and
realistic personas that average hundreds of structured attributes and roughly 1
MB of narrative text, two orders of magnitude deeper than prior works.
Intrinsic evaluations confirm significant improvements in attribute diversity
(32 percent higher coverage) and profile uniqueness (44 percent greater)
compared to state-of-the-art baselines. Extrinsically, our personas enhance
GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on
average across ten metrics and substantially narrow (by 31.7 percent) the gap
between simulated LLM citizens and authentic human responses in social surveys.
Our generated national citizens reduced the performance gap on the Big Five
personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA
thus provides a rigorous, scalable, and privacy-free platform for high-fidelity
human simulation and personalized AI research.","Zhen Wang, Yufan Zhou, Zhongyan Luo, Lyumanshan Ye, Adam Wood, Man Yao, Luoshang Pan",arXiv,2025,2025-11-10 17:37:56+00:00,"cs.AI, cs.LG, 68T07, 68T20, I.2.7; I.2.6; I.2.11"
2511.07332v1,Grounding Computer Use Agents on Human Demonstrations,"Building reliable computer-use agents requires grounding: accurately
connecting natural language instructions to the correct on-screen elements.
While large datasets exist for web and mobile interactions, high-quality
resources for desktop environments are limited. To address this gap, we
introduce GroundCUA, a large-scale desktop grounding dataset built from expert
human demonstrations. It covers 87 applications across 12 categories and
includes 56K screenshots, with every on-screen element carefully annotated for
a total of over 3.56M human-verified annotations. From these demonstrations, we
generate diverse instructions that capture a wide range of real-world tasks,
providing high-quality data for model training. Using GroundCUA, we develop the
GroundNext family of models that map instructions to their target UI elements.
At both 3B and 7B scales, GroundNext achieves state-of-the-art results across
five benchmarks using supervised fine-tuning, while requiring less than
one-tenth the training data of prior work. Reinforcement learning post-training
further improves performance, and when evaluated in an agentic setting on the
OSWorld benchmark using o3 as planner, GroundNext attains comparable or
superior results to models trained with substantially more data,. These results
demonstrate the critical role of high-quality, expert-driven datasets in
advancing general-purpose computer-use agents.","Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar",arXiv,2025,2025-11-10 17:35:21+00:00,"cs.LG, cs.AI"
2511.07327v1,"IterResearch: Rethinking Long-Horizon Agents via Markovian State
  Reconstruction","Recent advances in deep-research agents have shown promise for autonomous
knowledge construction through dynamic reasoning over external sources.
However, existing approaches rely on a mono-contextual paradigm that
accumulates all information in a single, expanding context window, leading to
context suffocation and noise contamination that limit their effectiveness on
long-horizon tasks. We introduce IterResearch, a novel iterative deep-research
paradigm that reformulates long-horizon research as a Markov Decision Process
with strategic workspace reconstruction. By maintaining an evolving report as
memory and periodically synthesizing insights, our approach preserves
consistent reasoning capacity across arbitrary exploration depths. We further
develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning
framework that incentivizes efficient exploration through geometric reward
discounting and enables stable distributed training via adaptive downsampling.
Extensive experiments demonstrate that IterResearch achieves substantial
improvements over existing open-source agents with average +14.5pp across six
benchmarks and narrows the gap with frontier proprietary systems. Remarkably,
our paradigm exhibits unprecedented interaction scaling, extending to 2048
interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves
as an effective prompting strategy, improving frontier models by up to 19.2pp
over ReAct on long-horizon tasks. These findings position IterResearch as a
versatile solution for long-horizon reasoning, effective both as a trained
agent and as a prompting paradigm for frontier models.","Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",arXiv,2025,2025-11-10 17:30:08+00:00,"cs.AI, cs.CL"
2511.07322v1,"FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework
  for Equity Research Report Generation","While LLMs have shown great success in financial tasks like stock prediction
and question answering, their application in fully automating Equity Research
Report generation remains uncharted territory. In this paper, we formulate the
Equity Research Report (ERR) Generation task for the first time. To address the
data scarcity and the evaluation metrics absence, we present an open-source
evaluation benchmark for ERR generation - FinRpt. We frame a Dataset
Construction Pipeline that integrates 7 financial data types and produces a
high-quality ERR dataset automatically, which could be used for model training
and evaluation. We also introduce a comprehensive evaluation system including
11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent
framework specifically tailored to address this task, named FinRpt-Gen, and
train several LLM-based agents on the proposed datasets using Supervised
Fine-Tuning and Reinforcement Learning. Experimental results indicate the data
quality and metrics effectiveness of the benchmark FinRpt and the strong
performance of FinRpt-Gen, showcasing their potential to drive innovation in
the ERR generation field. All code and datasets are publicly available.","Song Jin, Shuqi Li, Shukun Zhang, Rui Yan",arXiv,2025,2025-11-10 17:22:32+00:00,"cs.CL, cs.AI"
2511.07318v1,"When Bias Pretends to Be Truth: How Spurious Correlations Undermine
  Hallucination Detection in LLMs","Despite substantial advances, large language models (LLMs) continue to
exhibit hallucinations, generating plausible yet incorrect responses. In this
paper, we highlight a critical yet previously underexplored class of
hallucinations driven by spurious correlations -- superficial but statistically
prominent associations between features (e.g., surnames) and attributes (e.g.,
nationality) present in the training data. We demonstrate that these spurious
correlations induce hallucinations that are confidently generated, immune to
model scaling, evade current detection methods, and persist even after refusal
fine-tuning. Through systematically controlled synthetic experiments and
empirical evaluations on state-of-the-art open-source and proprietary LLMs
(including GPT-5), we show that existing hallucination detection methods, such
as confidence-based filtering and inner-state probing, fundamentally fail in
the presence of spurious correlations. Our theoretical analysis further
elucidates why these statistical biases intrinsically undermine
confidence-based detection techniques. Our findings thus emphasize the urgent
need for new approaches explicitly designed to address hallucinations caused by
spurious correlations.","Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun, Kaifeng Lyu, Jian Li",arXiv,2025,2025-11-10 17:19:27+00:00,"cs.CL, cs.AI, cs.LG"
2511.07312v1,"Superhuman AI for Stratego Using Self-Play Reinforcement Learning and
  Test-Time Search","Few classical games have been regarded as such significant benchmarks of
artificial intelligence as to have justified training costs in the millions of
dollars. Among these, Stratego -- a board wargame exemplifying the challenge of
strategic decision making under massive amounts of hidden information -- stands
apart as a case where such efforts failed to produce performance at the level
of top humans. This work establishes a step change in both performance and cost
for Stratego, showing that it is now possible not only to reach the level of
top humans, but to achieve vastly superhuman level -- and that doing so
requires not an industrial budget, but merely a few thousand dollars. We
achieved this result by developing general approaches for self-play
reinforcement learning and test-time search under imperfect information.","Samuel Sokota, Eugene Vinitsky, Hengyuan Hu, J. Zico Kolter, Gabriele Farina",arXiv,2025,2025-11-10 17:13:41+00:00,"cs.LG, cs.AI"
2511.07309v1,"Frequency Diverse (FD)-RIS-Enhanced Covert Communications: Defense
  Against Wiretapping via Joint Distance-Angle Beamforming","In response to the security blind zone challenges faced by traditional
reconfigurable intelligent surface (RIS)-aided covert communication (CC)
systems, the joint distance-angle beamforming capability of frequency diverse
RIS (FD-RIS) shows significant potential for addressing these limitations.
Therefore, this paper initially incorporates the FD-RIS into the CC systems and
proposes the corresponding CC transmission scheme. Specifically, we first
develop the signal processing model of the FD-RIS, which considers effective
control of harmonic signals by leveraging the time-delay techniques. The joint
distance-angle beamforming capability is then validated through its normalized
beampattern. Based on this model, we then construct an FD-RIS-assisted CC
system under a multi-warden scenario and derive an approximate closed-form
expression for the covert constraints by considering the worst-case
eavesdropping conditions and utilizing the logarithmic moment-generating
function. An optimization problem is formulated which aims at maximizing the
covert user's achievable rate under covert constrains by jointly designing the
time delays and modulation frequencies. To tackle this non-convex problem, an
iterative algorithm with assured convergence is proposed to effectively solve
the time-delay and modulation frequency variables. To evaluate the performance
of the proposed scheme, we consider three communication scenarios with varying
spatial correlations between the covert user and wardens. Simulation results
demonstrate that FD-RIS can significantly improve covert performance,
particularly in angular-overlap scenarios where traditional RIS experiences
severe degradation. These findings further highlight the effectiveness of
FD-RIS in enhancing CC robustness under challenging spatial environments.","Han Xiao, Xiaoyan Hu, Wenjie Wang, Kai-Kit Wong, Kun Yang, Chan-Byoung Chae",arXiv,2025,2025-11-10 17:10:06+00:00,"cs.IT, math.IT"
2511.07301v1,"Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free
  Object Detection","Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
detector to a target domain without access to source data. However, existing
SFOD methods predominantly rely on internal knowledge from the source model,
which limits their capacity to generalize across domains and often results in
biased pseudo-labels, thereby hindering both transferability and
discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
massive and diverse data, exhibit strong perception capabilities and broad
generalization, yet their potential remains largely untapped in the SFOD
setting. In this paper, we propose a novel SFOD framework that leverages VFMs
as external knowledge sources to jointly enhance feature alignment and label
quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
Global Feature Alignment (PGFA) distills global features from VFMs using
patch-similarity-based weighting to enhance global feature transferability; (2)
Prototype-based Instance Feature Alignment (PIFA) performs instance-level
contrastive learning guided by momentum-updated VFM prototypes; and (3)
Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
detection VFMs and teacher models via an entropy-aware strategy to yield more
reliable supervision. Extensive experiments on six benchmarks demonstrate that
our method achieves state-of-the-art SFOD performance, validating the
effectiveness of integrating VFMs to simultaneously improve transferability and
discriminability.","Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu, Hui Xiong",arXiv,2025,2025-11-10 17:06:01+00:00,"cs.CV, cs.AI"
2511.07298v1,LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging,"Low-dose computed tomography (CT) represents a significant improvement in
patient safety through lower radiation doses, but increased noise, blur, and
contrast loss can diminish diagnostic quality. Therefore, consistency and
robustness in image quality assessment become essential for clinical
applications. In this study, we propose an LLM-based quality assessment system
that generates both numerical scores and textual descriptions of degradations
such as noise, blur, and contrast loss. Furthermore, various inference
strategies - from the zero-shot approach to metadata integration and error
feedback - are systematically examined, demonstrating the progressive
contribution of each method to overall performance. The resultant assessments
yield not only highly correlated scores but also interpretable output, thereby
adding value to clinical workflows. The source codes of our study are available
at https://github.com/itu-biai/lmms_ldct_iqa.","Kagan Celik, Mehmet Ozan Unal, Metin Ertas, Isa Yildirim",arXiv,2025,2025-11-10 16:56:11+00:00,"cs.CV, cs.AI"
2511.07295v1,"Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender
  Systems via Large Language Models","Implicit feedback, employed in training recommender systems, unavoidably
confronts noise due to factors such as misclicks and position bias. Previous
studies have attempted to identify noisy samples through their diverged data
patterns, such as higher loss values, and mitigate their influence through
sample dropping or reweighting. However, we observed that noisy samples and
hard samples display similar patterns, leading to hard-noisy confusion issue.
Such confusion is problematic as hard samples are vital for modeling user
preferences. To solve this problem, we propose LLMHNI framework, leveraging two
auxiliary user-item relevance signals generated by Large Language Models (LLMs)
to differentiate hard and noisy samples. LLMHNI obtains user-item semantic
relevance from LLM-encoded embeddings, which is used in negative sampling to
select hard negatives while filtering out noisy false negatives. An objective
alignment strategy is proposed to project LLM-encoded embeddings, originally
for general language tasks, into a representation space optimized for user-item
relevance modeling. LLMHNI also exploits LLM-inferred logical relevance within
user-item interactions to identify hard and noisy samples. These LLM-inferred
interactions are integrated into the interaction graph and guide denoising with
cross-graph contrastive alignment. To eliminate the impact of unreliable
interactions induced by LLM hallucination, we propose a graph contrastive
learning strategy that aligns representations from randomly edge-dropped views
to suppress unreliable edges. Empirical results demonstrate that LLMHNI
significantly improves denoising and recommendation performance.","Tianrui Song, Wen-Shuo Chao, Hao Liu",arXiv,2025,2025-11-10 16:51:03+00:00,"cs.IR, cs.AI"
2511.07293v1,Verifying rich robustness properties for neural networks,"Robustness is a important problem in AI alignment and safety, with models
such as neural networks being increasingly used in safety-critical systems. In
the last decade, a large body of work has emerged on local robustness, i.e.,
checking if the decision of a neural network remains unchanged when the input
is slightly perturbed. However, many of these approaches require specialized
encoding and often ignore the confidence of a neural network on its output. In
this paper, our goal is to build a generalized framework to specify and verify
variants of robustness in neural network verification. We propose a
specification framework using a simple grammar, which is flexible enough to
capture most existing variants. This allows us to introduce new variants of
robustness that take into account the confidence of the neural network in its
outputs. Next, we develop a novel and powerful unified technique to verify all
such variants in a homogeneous way, viz., by adding a few additional layers to
the neural network. This enables us to use any state-of-the-art neural network
verification tool, without having to tinker with the encoding within, while
incurring an approximation error that we show is bounded. We perform an
extensive experimental evaluation over a large suite of 8870 benchmarks having
138M parameters in a largest network, and show that we are able to capture a
wide set of robustness variants and outperform direct encoding approaches by a
significant margin.","Mohammad Afzal, S. Akshay, Ashutosh Gupta",arXiv,2025,2025-11-10 16:43:02+00:00,"cs.LO, cs.AI, cs.CV"
2511.07288v1,"Enabling Off-Policy Imitation Learning with Deep Actor Critic
  Stabilization","Learning complex policies with Reinforcement Learning (RL) is often hindered
by instability and slow convergence, a problem exacerbated by the difficulty of
reward engineering. Imitation Learning (IL) from expert demonstrations bypasses
this reliance on rewards. However, state-of-the-art IL methods, exemplified by
Generative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severe
sample inefficiency. This is a direct consequence of their foundational
on-policy algorithms, such as TRPO Schulman et.al. In this work, we introduce
an adversarial imitation learning algorithm that incorporates off-policy
learning to improve sample efficiency. By combining an off-policy framework
with auxiliary techniques specifically, double Q network based stabilization
and value learning without reward function inference we demonstrate a reduction
in the samples required to robustly match expert behavior.","Sayambhu Sen, Shalabh Bhatnagar",arXiv,2025,2025-11-10 16:35:50+00:00,"cs.LG, cs.AI"
2511.07286v1,"Glioma C6: A Novel Dataset for Training and Benchmarking Cell
  Segmentation","We present Glioma C6, a new open dataset for instance segmentation of glioma
C6 cells, designed as both a benchmark and a training resource for deep
learning models. The dataset comprises 75 high-resolution phase-contrast
microscopy images with over 12,000 annotated cells, providing a realistic
testbed for biomedical image analysis. It includes soma annotations and
morphological cell categorization provided by biologists. Additional
categorization of cells, based on morphology, aims to enhance the utilization
of image data for cancer cell research. Glioma C6 consists of two parts: the
first is curated with controlled parameters for benchmarking, while the second
supports generalization testing under varying conditions. We evaluate the
performance of several generalist segmentation models, highlighting their
limitations on our dataset. Our experiments demonstrate that training on Glioma
C6 significantly enhances segmentation performance, reinforcing its value for
developing robust and generalizable models. The dataset is publicly available
for researchers.","Roman Malashin, Svetlana Pashkevich, Daniil Ilyukhin, Arseniy Volkov, Valeria Yachnaya, Andrey Denisov, Maria Mikhalkova",arXiv,2025,2025-11-10 16:33:34+00:00,"cs.CV, cs.AI"
2511.07277v1,"Designing Beyond Language: Sociotechnical Barriers in AI Health
  Technologies for Limited English Proficiency","Limited English proficiency (LEP) patients in the U.S. face systemic barriers
to healthcare beyond language and interpreter access, encompassing procedural
and institutional constraints. AI advances may support communication and care
through on-demand translation and visit preparation, but also risk exacerbating
existing inequalities. We conducted storyboard-driven interviews with 14
patient navigators to explore how AI could shape care experiences for
Spanish-speaking LEP individuals. We identified tensions around linguistic and
cultural misunderstandings, privacy concerns, and opportunities and risks for
AI to augment care workflows. Participants highlighted structural factors that
can undermine trust in AI systems, including sensitive information disclosure,
unstable technology access, and low digital literacy. While AI tools can
potentially alleviate social barriers and institutional constraints, there are
risks of misinformation and uprooting human camaraderie. Our findings
contribute design considerations for AI that support LEP patients and care
teams via rapport-building, education, and language support, and minimizing
disruptions to existing practices.","Michelle Huang, Violeta J. Rodriguez, Koustuv Saha, Tal August",arXiv,2025,2025-11-10 16:23:06+00:00,"cs.HC, cs.AI, cs.CY"
2511.07267v1,"Beyond Detection: Exploring Evidence-based Multi-Agent Debate for
  Misinformation Intervention and Persuasion","Multi-agent debate (MAD) frameworks have emerged as promising approaches for
misinformation detection by simulating adversarial reasoning. While prior work
has focused on detection accuracy, it overlooks the importance of helping users
understand the reasoning behind factual judgments and develop future
resilience. The debate transcripts generated during MAD offer a rich but
underutilized resource for transparent reasoning. In this study, we introduce
ED2D, an evidence-based MAD framework that extends previous approach by
incorporating factual evidence retrieval. More importantly, ED2D is designed
not only as a detection framework but also as a persuasive multi-agent system
aimed at correcting user beliefs and discouraging misinformation sharing. We
compare the persuasive effects of ED2D-generated debunking transcripts with
those authored by human experts. Results demonstrate that ED2D outperforms
existing baselines across three misinformation detection benchmarks. When ED2D
generates correct predictions, its debunking transcripts exhibit persuasive
effects comparable to those of human experts; However, when ED2D misclassifies,
its accompanying explanations may inadvertently reinforce users'misconceptions,
even when presented alongside accurate human explanations. Our findings
highlight both the promise and the potential risks of deploying MAD systems for
misinformation intervention. We further develop a public community website to
help users explore ED2D, fostering transparency, critical thinking, and
collaborative fact-checking.","Chen Han, Yijia Ma, Jin Tan, Wenzhen Zheng, Xijin Tang",arXiv,2025,2025-11-10 16:15:53+00:00,cs.AI
2511.07265v1,"When Intelligence Overloads Infrastructure: A Forecast Model for
  AI-Driven Bottlenecks","The exponential growth of AI agents and connected devices fundamentally
transforms the structure and capacity demands of global digital infrastructure.
This paper introduces a unified forecasting model that projects AI agent
populations to increase by more than 100 times between 2026 and 2036+, reaching
trillions of instances globally. In parallel, bandwidth demand is expected to
surge from 1 EB/day in 2026 to over 8,000 EB/day by 2036, which is an increase
of 8000 times in a single decade. Through this growth model, we identify
critical bottleneck domains across access networks, edge gateways,
interconnection exchanges, and cloud infrastructures. Simulations reveal that
edge and peering systems will experience saturation as early as 2030, with more
than 70% utilization of projected maximum capacity by 2033. To address these
constraints, we propose a coevolutionary shift in compute-network design,
emphasizing distributed inference, AI-native traffic engineering, and
intent-aware orchestration. Security, scalability, and coordination challenges
are examined with a focus on sustaining intelligent connectivity throughout the
next digital decade.","Gamal Refai-Ahmed, Mallik Tatipamula, Victor Zhirnov, Ahmed Refaey Hussein, Abdallah Shami",arXiv,2025,2025-11-10 16:09:49+00:00,cs.NI
2511.07262v1,"AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery
  in Scientific Machine Learning","Scientific Machine Learning (SciML) integrates data-driven inference with
physical modeling to solve complex problems in science and engineering.
However, the design of SciML architectures, loss formulations, and training
strategies remains an expert-driven research process, requiring extensive
experimentation and problem-specific insights. Here we introduce AgenticSciML,
a collaborative multi-agent system in which over 10 specialized AI agents
collaborate to propose, critique, and refine SciML solutions through structured
reasoning and iterative evolution. The framework integrates structured debate,
retrieval-augmented method memory, and ensemble-guided evolutionary search,
enabling the agents to generate and assess new hypotheses about architectures
and optimization procedures. Across physics-informed learning and operator
learning tasks, the framework discovers solution methods that outperform
single-agent and human-designed baselines by up to four orders of magnitude in
error reduction. The agents produce novel strategies -- including adaptive
mixture-of-expert architectures, decomposition-based PINNs, and
physics-informed operator learning models -- that do not appear explicitly in
the curated knowledge base. These results show that collaborative reasoning
among AI agents can yield emergent methodological innovation, suggesting a path
toward scalable, transparent, and autonomous discovery in scientific computing.","Qile Jiang, George Karniadakis",arXiv,2025,2025-11-10 16:06:33+00:00,"cs.AI, cs.CE, cs.LG"
2511.07260v1,PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork,"Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen
teammates, which is crucial for many real-world applications. The core
challenge of AHT is to develop an ego agent that can predict and adapt to
unknown teammates on the fly. Conventional RL-based approaches optimize a
single expected return, which often causes policies to collapse into a single
dominant behavior, thus failing to capture the multimodal cooperation patterns
inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach
that captures agent's multimodal behaviors, unlocking its diverse cooperation
modes with teammates. However, standard diffusion models lack the ability to
predict and adapt in highly non-stationary AHT scenarios. To address this
limitation, we propose a novel diffusion-based policy that integrates critical
predictive information about teammates into the denoising process. Extensive
experiments across three cooperation environments demonstrate that PADiff
outperforms existing AHT methods significantly.","Hohei Chan, Xinzhi Zhang, Antao Xiang, Weinan Zhang, Mengchen Zhao",arXiv,2025,2025-11-10 16:05:40+00:00,"cs.AI, cs.LG"
2511.07250v1,"MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal
  LLMs","The advent of Multimodal Large Language Models (MLLMs) has expanded AI
capabilities to visual modalities, yet existing evaluation benchmarks remain
limited to single-video understanding, overlooking the critical need for
multi-video understanding in real-world scenarios (e.g., sports analytics and
autonomous driving). To address this significant gap, we introduce MVU-Eval,
the first comprehensive benchmark for evaluating Multi-Video Understanding for
MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies
through 1,824 meticulously curated question-answer pairs spanning 4,959 videos
from diverse domains, addressing both fundamental perception tasks and
high-order reasoning tasks. These capabilities are rigorously aligned with
real-world applications such as multi-sensor synthesis in autonomous systems
and cross-angle sports analytics. Through extensive evaluation of
state-of-the-art open-source and closed-source models, we reveal significant
performance discrepancies and limitations in current MLLMs' ability to perform
understanding across multiple videos. The benchmark will be made publicly
available to foster future research.","Tianhao Peng, Haochen Wang, Yuanxing Zhang, Zekun Wang, Zili Wang, Ge Zhang, Jian Yang, Shihao Li, Yanghai Wang, Xintao Wang, Houyi Li, Wei Ji, Pengfei Wan, Wenhao Huang, Zhaoxiang Zhang, Jiaheng Liu",arXiv,2025,2025-11-10 16:02:33+00:00,"cs.CV, cs.AI"
2511.07238v1,Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation,"In autonomous driving and robotics, ensuring road safety and reliable
decision-making critically depends on out-of-distribution (OOD) segmentation.
While numerous methods have been proposed to detect anomalous objects on the
road, leveraging the vision-language space-which provides rich linguistic
knowledge-remains an underexplored field. We hypothesize that incorporating
these linguistic cues can be especially beneficial in the complex contexts
found in real-world autonomous driving scenarios.
  To this end, we present a novel approach that trains a Text-Driven OOD
Segmentation model to learn a semantically diverse set of objects in the
vision-language space. Concretely, our approach combines a vision-language
model's encoder with a transformer decoder, employs Distance-Based OOD prompts
located at varying semantic distances from in-distribution (ID) classes, and
utilizes OOD Semantic Augmentation for OOD representations. By aligning visual
and textual information, our approach effectively generalizes to unseen objects
and provides robust OOD segmentation in diverse driving environments.
  We conduct extensive experiments on publicly available OOD segmentation
datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets,
demonstrating that our approach achieves state-of-the-art performance across
both pixel-level and object-level evaluations. This result underscores the
potential of vision-language-based OOD segmentation to bolster the safety and
reliability of future autonomous driving systems.","Seungheon Song, Jaekoo Lee",arXiv,2025,2025-11-10 15:54:23+00:00,"cs.CV, cs.AI"
2511.07233v1,"Noise & pattern: identity-anchored Tikhonov regularization for robust
  structural anomaly detection","Anomaly detection plays a pivotal role in automated industrial inspection,
aiming to identify subtle or rare defects in otherwise uniform visual patterns.
As collecting representative examples of all possible anomalies is infeasible,
we tackle structural anomaly detection using a self-supervised autoencoder that
learns to repair corrupted inputs. To this end, we introduce a corruption model
that injects artificial disruptions into training images to mimic structural
defects. While reminiscent of denoising autoencoders, our approach differs in
two key aspects. First, instead of unstructured i.i.d.\ noise, we apply
structured, spatially coherent perturbations that make the task a hybrid of
segmentation and inpainting. Second, and counterintuitively, we add and
preserve Gaussian noise on top of the occlusions, which acts as a Tikhonov
regularizer anchoring the Jacobian of the reconstruction function toward
identity. This identity-anchored regularization stabilizes reconstruction and
further improves both detection and segmentation accuracy. On the MVTec AD
benchmark, our method achieves state-of-the-art results (I/P-AUROC: 99.9/99.4),
supporting our theoretical framework and demonstrating its practical relevance
for automatic inspection.","Alexander Bauer, Klaus-Robert Müller",arXiv,2025,2025-11-10 15:48:50+00:00,"cs.CV, cs.LG"
2511.07230v1,Discourse Graph Guided Document Translation with Large Language Models,"Adapting large language models to full document translation remains
challenging due to the difficulty of capturing long-range dependencies and
preserving discourse coherence throughout extended texts. While recent agentic
machine translation systems mitigate context window constraints through
multi-agent orchestration and persistent memory, they require substantial
computational resources and are sensitive to memory retrieval strategies. We
introduce TransGraph, a discourse-guided framework that explicitly models
inter-chunk relationships through structured discourse graphs and selectively
conditions each translation segment on relevant graph neighbourhoods rather
than relying on sequential or exhaustive context. Across three document-level
MT benchmarks spanning six languages and diverse domains, TransGraph
consistently surpasses strong baselines in translation quality and terminology
consistency while incurring significantly lower token overhead.","Viet-Thanh Pham, Minghan Wang, Hao-Han Liao, Thuy-Trang Vu",arXiv,2025,2025-11-10 15:48:01+00:00,"cs.CL, cs.AI"
2511.07229v1,"LLMServingSim2.0: A Unified Simulator for Heterogeneous Hardware and
  Serving Techniques in LLM Infrastructure","This paper introduces LLMServingSim2.0, a system simulator designed for
exploring heterogeneous hardware in large-scale LLM serving systems.
LLMServingSim2.0 addresses two key limitations of its predecessor: (1)
integrating hardware models into system-level simulators is non-trivial due to
the lack of a clear abstraction, and (2) existing simulators support only a
narrow subset of serving techniques, leaving no infrastructure that captures
the breadth of approaches in modern LLM serving. To overcome these issues,
LLMServingSim2.0 adopts trace-driven performance modeling, accompanied by an
operator-level latency profiler, enabling the integration of new accelerators
with a single command. It further embeds up-to-date serving techniques while
exposing flexible interfaces for request routing, cache management, and
scheduling policies. In a TPU case study, our profiler requires 18.5x fewer LoC
and outperforms the predecessor's hardware-simulator integration, demonstrating
LLMServingSim2.0's low-effort hardware extensibility. Our experiments further
show that LLMServingSim2.0 reproduces GPU-based LLM serving with 1.9% error,
while maintaining practical simulation time, making it a comprehensive platform
for both hardware developers and LLM service providers.","Jaehong Cho, Hyunmin Choi, Jongse Park",arXiv,2025,2025-11-10 15:47:53+00:00,"cs.DC, cs.AI"
2511.07223v1,"NoteEx: Interactive Visual Context Manipulation for LLM-Assisted
  Exploratory Data Analysis in Computational Notebooks","Computational notebooks have become popular for Exploratory Data Analysis
(EDA), augmented by LLM-based code generation and result interpretation.
Effective LLM assistance hinges on selecting informative context -- the minimal
set of cells whose code, data, or outputs suffice to answer a prompt. As
notebooks grow long and messy, users can lose track of the mental model of
their analysis. They thus fail to curate appropriate contexts for LLM tasks,
causing frustration and tedious prompt engineering. We conducted a formative
study (n=6) that surfaced challenges in LLM context selection and mental model
maintenance. Therefore, we introduce NoteEx, a JupyterLab extension that
provides a semantic visualization of the EDA workflow, allowing analysts to
externalize their mental model, specify analysis dependencies, and enable
interactive selection of task-relevant contexts for LLMs. A user study (n=12)
against a baseline shows that NoteEx improved mental model retention and
context selection, leading to more accurate and relevant LLM responses.","Mohammad Hasan Payandeh, Lin-Ping Yuan, Jian Zhao",arXiv,2025,2025-11-10 15:44:55+00:00,"cs.HC, cs.AI"
2511.07208v1,"SMiLE: Provably Enforcing Global Relational Properties in Neural
  Networks","Artificial Intelligence systems are increasingly deployed in settings where
ensuring robustness, fairness, or domain-specific properties is essential for
regulation compliance and alignment with human values. However, especially on
Neural Networks, property enforcement is very challenging, and existing methods
are limited to specific constraints or local properties (defined around
datapoints), or fail to provide full guarantees. We tackle these limitations by
extending SMiLE, a recently proposed enforcement framework for NNs, to support
global relational properties (defined over the entire input space). The
proposed approach scales well with model complexity, accommodates general
properties and backbones, and provides full satisfaction guarantees. We
evaluate SMiLE on monotonicity, global robustness, and individual fairness, on
synthetic and real data, for regression and classification tasks. Our approach
is competitive with property-specific baselines in terms of accuracy and
runtime, and strictly superior in terms of generality and level of guarantees.
Overall, our results emphasize the potential of the SMiLE framework as a
platform for future research and applications.","Matteo Francobaldi, Michele Lombardi, Andrea Lodi",arXiv,2025,2025-11-10 15:33:32+00:00,"cs.LG, cs.AI, math.OC"
2511.07205v1,"Twenty-Five Years of MIR Research: Achievements, Practices, Evaluations,
  and Future Challenges","In this paper, we trace the evolution of Music Information Retrieval (MIR)
over the past 25 years. While MIR gathers all kinds of research related to
music informatics, a large part of it focuses on signal processing techniques
for music data, fostering a close relationship with the IEEE Audio and Acoustic
Signal Processing Technical Commitee. In this paper, we reflect the main
research achievements of MIR along the three EDICS related to music analysis,
processing and generation. We then review a set of successful practices that
fuel the rapid development of MIR research. One practice is the annual research
benchmark, the Music Information Retrieval Evaluation eXchange, where
participants compete on a set of research tasks. Another practice is the
pursuit of reproducible and open research. The active engagement with industry
research and products is another key factor for achieving large societal
impacts and motivating younger generations of students to join the field. Last
but not the least, the commitment to diversity, equity and inclusion ensures
MIR to be a vibrant and open community where various ideas, methodologies, and
career pathways collide. We finish by providing future challenges MIR will have
to face.","Geoffroy Peeters, Zafar Rafii, Magdalena Fuentes, Zhiyao Duan, Emmanouil Benetos, Juhan Nam, Yuki Mitsufuji",arXiv,2025,2025-11-10 15:32:23+00:00,"cs.SD, cs.AI"
2511.07204v1,Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations,"Online Social Networks (OSNs) widely adopt content moderation to mitigate the
spread of abusive and toxic discourse. Nonetheless, the real effectiveness of
moderation interventions remains unclear due to the high cost of data
collection and limited experimental control. The latest developments in Natural
Language Processing pave the way for a new evaluation approach. Large Language
Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and
simulate human-like social behavior with unprecedented degree of believability.
Yet, existing tools do not support simulation-based evaluation of moderation
strategies. We fill this gap by designing a LLM-powered simulator of OSN
conversations enabling a parallel, counterfactual simulation where toxic
behavior is influenced by moderation interventions, keeping all else equal. We
conduct extensive experiments, unveiling the psychological realism of OSN
agents, the emergence of social contagion phenomena and the superior
effectiveness of personalized moderation strategies.","Giacomo Fidone, Lucia Passaro, Riccardo Guidotti",arXiv,2025,2025-11-10 15:31:59+00:00,"cs.AI, cs.CY, cs.MA"
2511.07202v1,"Resilient by Design - Active Inference for Distributed Continuum
  Intelligence","Failures are the norm in highly complex and heterogeneous devices spanning
the distributed computing continuum (DCC), from resource-constrained IoT and
edge nodes to high-performance computing systems. Ensuring reliability and
global consistency across these layers remains a major challenge, especially
for AI-driven workloads requiring real-time, adaptive coordination. This paper
introduces a Probabilistic Active Inference Resilience Agent (PAIR-Agent) to
achieve resilience in DCC systems. PAIR-Agent performs three core operations:
(i) constructing a causal fault graph from device logs, (ii) identifying faults
while managing certainties and uncertainties using Markov blankets and the
free-energy principle, and (iii) autonomously healing issues through active
inference. Through continuous monitoring and adaptive reconfiguration, the
agent maintains service continuity and stability under diverse failure
conditions. Theoretical validations confirm the reliability and effectiveness
of the proposed framework.","Praveen Kumar Donta, Alfreds Lapkovskis, Enzo Mingozzi, Schahram Dustdar",arXiv,2025,2025-11-10 15:30:44+00:00,"cs.DC, cs.AI, cs.MA, cs.NI"
2511.07171v1,"Federated Learning for Video Violence Detection: Complementary Roles of
  Lightweight CNNs and Vision-Language Models for Energy-Efficient Use","Deep learning-based video surveillance increasingly demands
privacy-preserving architectures with low computational and environmental
overhead. Federated learning preserves privacy but deploying large
vision-language models (VLMs) introduces major energy and sustainability
challenges. We compare three strategies for federated violence detection under
realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference
with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and
personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed
90% accuracy in binary violence detection. The 3D CNN achieves superior
calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570
Wh) of federated LoRA, while VLMs provide richer multimodal reasoning.
Hierarchical category grouping (based on semantic similarity and class
exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime
dataset. To our knowledge, this is the first comparative simulation study of
LoRA-tuned VLMs and personalized CNNs for federated violence detection, with
explicit energy and CO2e quantification. Our results inform hybrid deployment
strategies that default to efficient CNNs for routine inference and selectively
engage VLMs for complex contextual reasoning.","Sébastien Thuau, Siba Haidar, Rachid Chelouah",arXiv,2025,2025-11-10 15:01:51+00:00,"cs.CV, cs.AI, cs.LG"
2511.07166v1,"AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and
  Dual-Channel Reasoning","We propose AdaRec, a few-shot in-context learning framework that leverages
large language models for an adaptive personalized recommendation. AdaRec
introduces narrative profiling, transforming user-item interactions into
natural language representations to enable unified task handling and enhance
human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a
dual-channel architecture that integrates horizontal behavioral alignment,
discovering peer-driven patterns, with vertical causal attribution,
highlighting decisive factors behind user preferences. Unlike existing
LLM-based approaches, AdaRec eliminates manual feature engineering through
semantic representations and supports rapid cross-task adaptation with minimal
supervision. Experiments on real ecommerce datasets demonstrate that AdaRec
outperforms both machine learning models and LLM-based baselines by up to eight
percent in few-shot settings. In zero-shot scenarios, it achieves up to a
nineteen percent improvement over expert-crafted profiling, showing
effectiveness for long-tail personalization with minimal interaction data.
Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec
matches the performance of fully fine-tuned models, highlighting its efficiency
and generalization across diverse tasks.","Meiyun Wang, Charin Polpanumas",arXiv,2025,2025-11-10 14:59:27+00:00,"cs.CL, cs.AI, cs.CE"
2511.07165v1,Fuzzy Label: From Concept to Its Application in Label Learning,"Label learning is a fundamental task in machine learning that aims to
construct intelligent models using labeled data, encompassing traditional
single-label and multi-label classification models. Traditional methods
typically rely on logical labels, such as binary indicators (e.g., ""yes/no"")
that specify whether an instance belongs to a given category. However, in
practical applications, label annotations often involve significant uncertainty
due to factors such as data noise, inherent ambiguity in the observed entities,
and the subjectivity of human annotators. Therefore, representing labels using
simplistic binary logic can obscure valuable information and limit the
expressiveness of label learning models. To overcome this limitation, this
paper introduces the concept of fuzzy labels, grounded in fuzzy set theory, to
better capture and represent label uncertainty. We further propose an efficient
fuzzy labeling method that mines and generates fuzzy labels from the original
data, thereby enriching the label space with more informative and nuanced
representations. Based on this foundation, we present fuzzy-label-enhanced
algorithms for both single-label and multi-label learning, using the classical
K-Nearest Neighbors (KNN) and multi-label KNN algorithms as illustrative
examples. Experimental results indicate that fuzzy labels can more effectively
characterize the real-world labeling information and significantly enhance the
performance of label learning models.","Chenxi Luoa, Zhuangzhuang Zhaoa, Zhaohong Denga, Te Zhangb",arXiv,2025,2025-11-10 14:58:19+00:00,"cs.LG, cs.AI"
2511.07161v1,LLMscape,"LLMscape is an interactive installation that investigates how humans and AI
construct meaning under shared conditions of uncertainty. Within a mutable,
projection-mapped landscape, human participants reshape the world and engage
with multiple AI agents, each developing incomplete and provisional accounts of
their environment. Exhibited in Shanghai and continually evolving, the work
positions AI not as deterministic tools but as embodied co-witnesses to an
unstable world, examining the parallels between human and artificial
meaning-making and inviting reflection on our shared epistemic limits.","Gottfried Haider, Jie Zhang",arXiv,2025,2025-11-10 14:52:20+00:00,cs.LG
2511.07158v1,"Guiding Generative Models to Uncover Diverse and Novel Crystals via
  Reinforcement Learning","Discovering functional crystalline materials entails navigating an immense
combinatorial design space. While recent advances in generative artificial
intelligence have enabled the sampling of chemically plausible compositions and
structures, a fundamental challenge remains: the objective misalignment between
likelihood-based sampling in generative modelling and targeted focus on
underexplored regions where novel compounds reside. Here, we introduce a
reinforcement learning framework that guides latent denoising diffusion models
toward diverse and novel, yet thermodynamically viable crystalline compounds.
Our approach integrates group relative policy optimisation with verifiable,
multi-objective rewards that jointly balance creativity, stability, and
diversity. Beyond de novo generation, we demonstrate enhanced property-guided
design that preserves chemical validity, while targeting desired functional
properties. This approach establishes a modular foundation for controllable
AI-driven inverse design that addresses the novelty-validity trade-off across
scientific discovery applications of generative models.","Hyunsoo Park, Aron Walsh",arXiv,2025,2025-11-10 14:48:49+00:00,"cs.LG, physics.comp-ph"
2511.07418v1,"Lightning Grasp: High Performance Procedural Grasp Synthesis with
  Contact Fields","Despite years of research, real-time diverse grasp synthesis for dexterous
hands remains an unsolved core challenge in robotics and computer graphics. We
present Lightning Grasp, a novel high-performance procedural grasp synthesis
algorithm that achieves orders-of-magnitude speedups over state-of-the-art
approaches, while enabling unsupervised grasp generation for irregular,
tool-like objects. The method avoids many limitations of prior approaches, such
as the need for carefully tuned energy functions and sensitive initialization.
This breakthrough is driven by a key insight: decoupling complex geometric
computation from the search process via a simple, efficient data structure -
the Contact Field. This abstraction collapses the problem complexity, enabling
a procedural search at unprecedented speeds. We open-source our system to
propel further innovation in robotic manipulation.","Zhao-Heng Yin, Pieter Abbeel",arXiv,2025,2025-11-10 18:59:44+00:00,"cs.RO, cs.AI, cs.CV, cs.DC, cs.GR"
2511.07417v1,Language Generation with Infinite Contamination,"We study language generation in the limit, where an algorithm observes an
adversarial enumeration of strings from an unknown target language $K$ and must
eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan
[KM24] proved that generation is achievable in surprisingly general settings.
But their generator suffers from ``mode collapse,'' producing from an
ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25]
require the generator's output to be ``dense'' in the target language. They
showed that generation with density, surprisingly, remains achievable at the
same generality.
  Both results assume perfect data: no noisy insertions and no omissions. This
raises a central question: how much contamination can generation tolerate?
Recent works made partial progress on this question by studying (non-dense)
generation with either finite amounts of noise (but no omissions) or omissions
(but no noise).
  We characterize robustness under contaminated enumerations: 1. Generation
under Contamination: Language generation in the limit is achievable for all
countable collections iff the fraction of contaminated examples converges to
zero. When this fails, we characterize which collections are generable. 2.
Dense Generation under Contamination: Dense generation is strictly less robust
to contamination than generation. As a byproduct, we resolve an open question
of Raman and Raman [ICML25] by showing that generation is possible with only
membership oracle access under finitely many contaminated examples.
  Finally, we introduce a beyond-worst-case model inspired by curriculum
learning and prove that dense generation is achievable even with infinite
contamination provided the fraction of contaminated examples converges to zero.
This suggests curriculum learning may be crucial for learning from noisy web
data.","Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou",arXiv,2025,2025-11-10 18:59:39+00:00,"stat.ML, cs.AI, cs.CL, cs.DS, cs.LG"
2511.07416v1,Robot Learning from a Physical World Model,"We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.","Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang",arXiv,2025,2025-11-10 18:59:07+00:00,"cs.RO, cs.AI, cs.CV"
2511.07413v1,DigiData: Training and Evaluating General-Purpose Mobile Control Agents,"AI agents capable of controlling user interfaces have the potential to
transform human interaction with digital devices. To accelerate this
transformation, two fundamental building blocks are essential: high-quality
datasets that enable agents to achieve complex and human-relevant goals, and
robust evaluation methods that allow researchers and practitioners to rapidly
enhance agent performance. In this paper, we introduce DigiData, a large-scale,
high-quality, diverse, multi-modal dataset designed for training mobile control
agents. Unlike existing datasets, which derive goals from unstructured
interactions, DigiData is meticulously constructed through comprehensive
exploration of app features, resulting in greater diversity and higher goal
complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating
mobile control agents on real-world complex tasks. We demonstrate that the
commonly used step-accuracy metric falls short in reliably assessing mobile
control agents and, to address this, we propose dynamic evaluation protocols
and AI-powered evaluations as rigorous alternatives for agent assessment. Our
contributions aim to significantly advance the development of mobile control
agents, paving the way for more intuitive and effective human-device
interactions.","Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan, Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, Nitin Kamra, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer, Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway, Joseph Tighe",arXiv,2025,2025-11-10 18:57:35+00:00,"cs.AI, cs.CL, cs.HC, cs.LG"
2511.07412v1,"TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for
  Embodied AI Research","Developing embodied AI for intelligent surgical systems requires safe,
controllable environments for continual learning and evaluation. However,
safety regulations and operational constraints in operating rooms (ORs) limit
embodied agents from freely perceiving and interacting in realistic settings.
Digital twins provide high-fidelity, risk-free environments for exploration and
training. How we may create photorealistic and dynamic digital representations
of ORs that capture relevant spatial, visual, and behavioral complexity remains
unclear. We introduce TwinOR, a framework for constructing photorealistic,
dynamic digital twins of ORs for embodied AI research. The system reconstructs
static geometry from pre-scan videos and continuously models human and
equipment motion through multi-view perception of OR activities. The static and
dynamic components are fused into an immersive 3D environment that supports
controllable simulation and embodied exploration. The proposed framework
reconstructs complete OR geometry with centimeter level accuracy while
preserving dynamic interaction across surgical workflows, enabling realistic
renderings and a virtual playground for embodied AI systems. In our
experiments, TwinOR simulates stereo and monocular sensor streams for geometry
understanding and visual localization tasks. Models such as FoundationStereo
and ORB-SLAM3 on TwinOR-synthesized data achieve performance within their
reported accuracy on real indoor datasets, demonstrating that TwinOR provides
sensor-level realism sufficient for perception and localization challenges. By
establishing a real-to-sim pipeline for constructing dynamic, photorealistic
digital twins of OR environments, TwinOR enables the safe, scalable, and
data-efficient development and benchmarking of embodied AI, ultimately
accelerating the deployment of embodied AI from sim-to-real.","Han Zhang, Yiqing Shen, Roger D. Soberanis-Mukul, Ankita Ghosh, Hao Ding, Lalithkumar Seenivasan, Jose L. Porras, Zhekai Mao, Chenjia Li, Wenjie Xiao, Lonny Yarmus, Angela Christine Argento, Masaru Ishii, Mathias Unberath",arXiv,2025,2025-11-10 18:57:09+00:00,"cs.CV, cs.RO"
2511.07410v1,"Using Vision Language Models as Closed-Loop Symbolic Planners for
  Robotic Applications: A Control-Theoretic Perspective","Large Language Models (LLMs) and Vision Language Models (VLMs) have been
widely used for embodied symbolic planning. Yet, how to effectively use these
models for closed-loop symbolic planning remains largely unexplored. Because
they operate as black boxes, LLMs and VLMs can produce unpredictable or costly
errors, making their use in high-level robotic planning especially challenging.
In this work, we investigate how to use VLMs as closed-loop symbolic planners
for robotic applications from a control-theoretic perspective. Concretely, we
study how the control horizon and warm-starting impact the performance of VLM
symbolic planners. We design and conduct controlled experiments to gain
insights that are broadly applicable to utilizing VLMs as closed-loop symbolic
planners, and we discuss recommendations that can help improve the performance
of VLM symbolic planners.","Hao Wang, Sathwik Karnik, Bea Lim, Somil Bansal",arXiv,2025,2025-11-10 18:56:56+00:00,"cs.RO, cs.AI"
2511.07409v1,DIMO: Diverse 3D Motion Generation for Arbitrary Objects,"We present DIMO, a generative approach capable of generating diverse 3D
motions for arbitrary objects from a single image. The core idea of our work is
to leverage the rich priors in well-trained video models to extract the common
motion patterns and then embed them into a shared low-dimensional latent space.
Specifically, we first generate multiple videos of the same object with diverse
motions. We then embed each motion into a latent vector and train a shared
motion decoder to learn the distribution of motions represented by a structured
and compact motion representation, i.e., neural key point trajectories. The
canonical 3D Gaussians are then driven by these key points and fused to model
the geometry and appearance. During inference time with learned latent space,
we can instantly sample diverse 3D motions in a single-forward pass and support
several interesting applications including 3D motion interpolation and
language-guided motion generation. Our project page is available at
https://linzhanm.github.io/dimo.","Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis",arXiv,2025,2025-11-10 18:56:49+00:00,cs.CV
2511.07405v1,"SPOT: An Annotated French Corpus and Benchmark for Detecting Critical
  Interventions in Online Conversations","We introduce SPOT (Stopping Points in Online Threads), the first annotated
corpus translating the sociological concept of stopping point into a
reproducible NLP task. Stopping points are ordinary critical interventions that
pause or redirect online discussions through a range of forms (irony, subtle
doubt or fragmentary arguments) that frameworks like counterspeech or social
correction often overlook. We operationalize this concept as a binary
classification task and provide reliable annotation guidelines. The corpus
contains 43,305 manually annotated French Facebook comments linked to URLs
flagged as false information by social media users, enriched with contextual
metadata (article, post, parent comment, page or group, and source). We
benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs
under various prompting strategies. Results show that fine-tuned encoders
outperform prompted LLMs in F1 score by more than 10 percentage points,
confirming the importance of supervised learning for emerging non-English
social media tasks. Incorporating contextual metadata further improves encoder
models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along
with the annotation guidelines and code in our code repository, to foster
transparency and reproducible research.","Manon Berriche, Célia Nouri, Chloé Clavel, Jean-Philippe Cointet",arXiv,2025,2025-11-10 18:54:40+00:00,"cs.CL, cs.CY"
2511.07403v1,"SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial
  Rewards","Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.","Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark",arXiv,2025,2025-11-10 18:52:47+00:00,"cs.CV, cs.AI, cs.CL, cs.LG"
2511.07399v1,"StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video
  Generation","Generative models are reshaping the live-streaming industry by redefining how
content is created, styled, and delivered. Previous image-based streaming
diffusion models have powered efficient and creative live streaming products
but have hit limits on temporal consistency due to the foundation of
image-based designs. Recent advances in video diffusion have markedly improved
temporal consistency and sampling efficiency for offline generation. However,
offline generation systems primarily optimize throughput by batching large
workloads. In contrast, live online streaming operates under strict
service-level objectives (SLOs): time-to-first-frame must be minimal, and every
frame must meet a per-frame deadline with low jitter. Besides, scalable
multi-GPU serving for real-time streams remains largely unresolved so far. To
address this, we present StreamDiffusionV2, a training-free pipeline for
interactive live streaming with video diffusion models. StreamDiffusionV2
integrates an SLO-aware batching scheduler and a block scheduler, together with
a sink-token--guided rolling KV cache, a motion-aware noise controller, and
other system-level optimizations. Moreover, we introduce a scalable pipeline
orchestration that parallelizes the diffusion process across denoising steps
and network layers, achieving near-linear FPS scaling without violating latency
guarantees. The system scales seamlessly across heterogeneous GPU environments
and supports flexible denoising steps (e.g., 1--4), enabling both
ultra-low-latency and higher-quality modes. Without TensorRT or quantization,
StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS
with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four
H100 GPUs, making state-of-the-art generative live streaming practical and
accessible--from individual creators to enterprise-scale platforms.","Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li, Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt Keutzer, Akio Kodaira, Chenfeng Xu",arXiv,2025,2025-11-10 18:51:28+00:00,"cs.CV, cs.LG"
2511.07398v1,Solving bilevel optimization via sequential minimax optimization,"In this paper we propose a sequential minimax optimization (SMO) method for
solving a class of constrained bilevel optimization problems in which the
lower-level part is a possibly nonsmooth convex optimization problem, while the
upper-level part is a possibly nonconvex optimization problem. Specifically,
SMO applies a first-order method to solve a sequence of minimax subproblems,
which are obtained by employing a hybrid of modified augmented Lagrangian and
penalty schemes on the bilevel optimization problems. Under suitable
assumptions, we establish an operation complexity of
$O(\varepsilon^{-7}\log\varepsilon^{-1})$ and
$O(\varepsilon^{-6}\log\varepsilon^{-1})$, measured in terms of fundamental
operations, for SMO in finding an $\varepsilon$-KKT solution of the bilevel
optimization problems with merely convex and strongly convex lower-level
objective functions, respectively. The latter result improves the previous
best-known operation complexity by a factor of $\varepsilon^{-1}$. Preliminary
numerical results demonstrate significantly superior computational performance
compared to the recently developed first-order penalty method.","Zhaosong Lu, Sanyou Mei",arXiv,2025,2025-11-10 18:51:05+00:00,"math.OC, cs.LG, cs.NA, math.NA, stat.ML, 90C26, 90C30, 90C47, 90C99, 65K05"
2511.07397v1,ConvFill: Model Collaboration for Responsive Conversational Voice Agents,"Deploying conversational voice agents with large language models faces a
critical challenge: cloud-based foundation models provide deep reasoning and
domain knowledge but introduce latency that disrupts natural conversation,
while on-device models respond immediately but lack sophistication. We propose
conversational infill, a task where a lightweight on-device model generates
contextually appropriate dialogue while seamlessly incorporating streaming
knowledge from a powerful backend model. This approach decouples response
latency from model capability, enabling systems that feel responsive while
accessing the full power of large-scale models. We present ConvFill, a 360M
parameter model trained on synthetic multi-domain conversations. Evaluation
across multiple backend models shows that conversational infill can be
successfully learned, with ConvFill achieving accuracy improvements of 36-42%
over standalone small models of the same size while consistently retaining
sub-200ms response latencies. Our results demonstrate the promise of this
approach for building on-device conversational agents that are both immediately
responsive and knowledgeable.","Vidya Srinivas, Zachary Englhardt, Maximus Powers, Shwetak Patel, Vikram Iyer",arXiv,2025,2025-11-10 18:50:30+00:00,cs.CL
2511.07396v1,"C3PO: Optimized Large Language Model Cascades with Probabilistic Cost
  Constraints for Reasoning","Large language models (LLMs) have achieved impressive results on complex
reasoning tasks, but their high inference cost remains a major barrier to
real-world deployment. A promising solution is to use cascaded inference, where
small, cheap models handle easy queries, and only the hardest examples are
escalated to more powerful models. However, existing cascade methods typically
rely on supervised training with labeled data, offer no theoretical
generalization guarantees, and provide limited control over test-time
computational cost. We introduce C3PO (Cost Controlled Cascaded Prediction
Optimization), a self-supervised framework for optimizing LLM cascades under
probabilistic cost constraints. By focusing on minimizing regret with respect
to the most powerful model (MPM), C3PO avoids the need for labeled data by
constructing a cascade using only unlabeled model outputs. It leverages
conformal prediction to bound the probability that inference cost exceeds a
user-specified budget. We provide theoretical guarantees on both cost control
and generalization error, and show that our optimization procedure is effective
even with small calibration sets. Empirically, C3PO achieves state-of-the-art
performance across a diverse set of reasoning benchmarks including GSM8K,
MATH-500, BigBench-Hard and AIME, outperforming strong LLM cascading baselines
in both accuracy and cost-efficiency. Our results demonstrate that principled,
label-free cascade optimization can enable scalable LLM deployment.","Antonios Valkanas, Soumyasundar Pal, Pavel Rumiantsev, Yingxue Zhang, Mark Coates",arXiv,2025,2025-11-10 18:50:27+00:00,cs.LG
2511.07395v1,The Landscape of Almost Equitable Allocations,"Equitability is a fundamental notion in fair division which requires that all
agents derive equal value from their allocated bundles. We study, for general
(possibly non-monotone) valuations, a popular relaxation of equitability known
as equitability up to one item (EQ1). An EQ1 allocation may fail to exist even
with additive non-monotone valuations; for instance, when there are two agents,
one valuing every item positively and the other negatively. This motivates a
mild and natural assumption: all agents agree on the sign of their value for
the grand bundle. Under this assumption, we prove the existence and provide an
efficient algorithm for computing EQ1 allocations for two agents with general
valuations. When there are more than two agents, we show the existence and
polynomial-time computability of EQ1 allocations for valuation classes beyond
additivity and monotonicity, in particular for (1) doubly monotone valuations
and (2) submodular (resp. supermodular) valuations where the value for the
grand bundle is nonnegative (resp. nonpositive) for all agents. Furthermore, we
settle an open question of Bil`o et al. by showing that an EQ1 allocation
always exists for nonnegative(resp. nonpositive) valuations, i.e., when every
agent values each subset of items nonnegatively (resp. nonpositively). Finally,
we complete the picture by showing that for general valuations with more than
two agents, EQ1 allocations may not exist even when agents agree on the sign of
the grand bundle, and that deciding the existence of an EQ1 allocation is
computationally intractable.","Hadi Hosseini, Vishwa Prakash HV, Aditi Sethia, Jatin Yadav",arXiv,2025,2025-11-10 18:50:07+00:00,"cs.GT, cs.DS"
2511.07392v1,"Surgical Agent Orchestration Platform for Voice-directed Patient Data
  Interaction","In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in
the procedure, making it difficult to access and manipulate multimodal patient
data without interruption. We propose a voice-directed Surgical Agent
Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework,
consisting of an orchestration agent and three task-specific agents driven by
Large Language Models (LLMs). These LLM-based agents autonomously plan, refine,
validate, and reason to map voice commands into specific tasks such as
retrieving clinical information, manipulating CT scans, or navigating 3D
anatomical models on the surgical video. We also introduce a Multi-level
Orchestration Evaluation Metric (MOEM) to comprehensively assess the
performance and robustness from command-level and category-level perspectives.
The SAOP achieves high accuracy and success rates across 240 voice commands,
while LLM-based agents improve robustness against speech recognition errors and
diverse or ambiguous free-form commands, demonstrating strong potential to
support minimally invasive da Vinci robotic surgery.","Hyeryun Park, Byung Mo Gu, Jun Hee Lee, Byeong Hyeon Choi, Sekeun Kim, Hyun Koo Kim, Kyungsang Kim",arXiv,2025,2025-11-10 18:47:24+00:00,"cs.CL, cs.AI"
2511.07385v1,"samsara: A Continuous-Time Markov Chain Monte Carlo Sampler for
  Trans-Dimensional Bayesian Analysis","Bayesian inference requires determining the posterior distribution, a task
that becomes particularly challenging when the dimension of the parameter space
is large and unknown. This limitation arises in many physics problems, such as
Mixture Models (MM) with an unknown number of components or the inference of
overlapping signals in noisy data, as in the Laser Interferometer Space Antenna
(LISA) Global Fit problem. Traditional approaches, such as product-space
methods or Reversible-Jump Markov Chain Monte Carlo (RJMCMC), often face
efficiency and convergence limitations. This paper presents samsara, a
Continuous-Time Markov Chain Monte Carlo (CTMCMC) framework that models
parameter evolution through Poisson-driven birth, death, and mutation
processes. samsara is designed to sample models of unknown dimensionality. By
requiring detailed balance through adaptive rate definitions, CTMCMC achieves
automatic acceptance of trans-dimensional moves and high sampling efficiency.
The code features waiting time weighted estimators, optimized memory storage,
and a modular design for easy customization. We validate samsara on three
benchmark problems: an analytic trans-dimensional distribution, joint inference
of sine waves and Lorentzians in time series, and a Gaussian MM with an unknown
number of components. In all cases, the code shows excellent agreement with
analytical and Nested Sampling results. All these features push samsara as a
powerful alternative to RJMCMC for large- and variable-dimensional Bayesian
inference problems.","Gabriele Astorino, Lorenzo Valbusa Dall'Armi, Riccardo Buscicchio, Joachim Pomper, Angelo Ricciardone, Walter Del Pozzo",arXiv,2025,2025-11-10 18:44:14+00:00,"stat.CO, astro-ph.IM, gr-qc"
2511.07384v1,"Teaching Pretrained Language Models to Think Deeper with Retrofitted
  Recurrence","Recent advances in depth-recurrent language models show that recurrence can
decouple train-time compute and parameter count from test-time compute. In this
work, we study how to convert existing pretrained non-recurrent language models
into depth-recurrent models. We find that using a curriculum of recurrences to
increase the effective depth of the model over the course of training preserves
performance while reducing total computational cost. In our experiments, on
mathematics, we observe that converting pretrained models to recurrent ones
results in better performance at a given compute budget than simply
post-training the original non-recurrent language model.","Sean McLeish, Ang Li, John Kirchenbauer, Dayal Singh Kalra, Brian R. Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Jonas Geiping, Tom Goldstein, Micah Goldblum",arXiv,2025,2025-11-10 18:43:07+00:00,"cs.CL, cs.AI, cs.LG"
2511.07382v1,"Retriv at BLP-2025 Task 2: Test-Driven Feedback-Guided Framework for
  Bangla-to-Python Code Generation","Large Language Models (LLMs) have advanced the automated generation of code
from natural language prompts. However, low-resource languages (LRLs) like
Bangla remain underrepresented due to the limited availability of
instruction-to-code datasets and evaluation benchmarks. To address this, the
BLP Workshop at IJCNLP-AACL 2025 introduced a shared task on ""Code Generation
in Bangla"". In this work, we propose a method that combines instruction
prompting with a test-driven, feedback-guided iterative refinement process
using a fine-tuned Qwen2.5-14B model. The model generates code from Bangla
instructions, tests it against unit tests, and iteratively refines any failing
outputs through three evaluation passes, using test feedback to guide each
step. This approach helped our team ""Retriv"" to secure 2nd place in the shared
task with a Pass@1 score of 0.934. The analysis highlights challenges in Bangla
instruction understanding and Python code generation, emphasizing the need for
targeted methods in LRLs. We made experimental scripts publicly available for
the community.","K M Nafi Asib, Sourav Saha, Mohammed Moshiul Hoque",arXiv,2025,2025-11-10 18:41:44+00:00,cs.CL
2511.07381v1,Residual Rotation Correction using Tactile Equivariance,"Visuotactile policy learning augments vision-only policies with tactile
input, facilitating contact-rich manipulation. However, the high cost of
tactile data collection makes sample efficiency the key requirement for
developing visuotactile policies. We present EquiTac, a framework that exploits
the inherent SO(2) symmetry of in-hand object rotation to improve sample
efficiency and generalization for visuotactile policy learning. EquiTac first
reconstructs surface normals from raw RGB inputs of vision-based tactile
sensors, so rotations of the normal vector field correspond to in-hand object
rotations. An SO(2)-equivariant network then predicts a residual rotation
action that augments a base visuomotor policy at test time, enabling real-time
rotation correction without additional reorientation demonstrations. On a real
robot, EquiTac accurately achieves robust zero-shot generalization to unseen
in-hand orientations with very few training samples, where baselines fail even
with more training data. To our knowledge, this is the first tactile learning
method to explicitly encode tactile equivariance for policy learning, yielding
a lightweight, symmetry-aware module that improves reliability in contact-rich
tasks.","Yizhe Zhu, Zhang Ye, Boce Hu, Haibo Zhao, Yu Qi, Dian Wang, Robert Platt",arXiv,2025,2025-11-10 18:41:34+00:00,"cs.RO, 14J60 (Primary) 14F05, 14J26 (Secondary), 14J60 (Primary) 14F05,
  14J26 (Secondary)"
2511.07380v1,"Selecting Auxiliary Data via Neural Tangent Kernels for Low-Resource
  Domains","Large language models (LLMs) have achieved remarkable success across
widespread tasks, yet their application in low-resource domains remains a
significant challenge due to data scarcity and the high risk of overfitting.
While in-domain data is limited, there exist vast amounts of similar
general-domain data, and our initial findings reveal that they could
potentially serve as auxiliary supervision for domain enhancement. This
observation leads us to our central research question: \textbf{\textit{how to
effectively select the most valuable auxiliary data to maximize domain-specific
performance}}, particularly when traditional methods are inapplicable due to a
lack of large in-domain data pools or validation sets. To address this, we
propose \textbf{NTK-Selector}, a principled and efficient framework for
selecting general-domain auxiliary data to enhance domain-specific performance
via neural tangent kernels (NTK). Our method tackles two challenges of directly
applying NTK to LLMs, theoretical assumptions and prohibitive computational
cost, by empirically demonstrating a stable NTK-like behavior in LLMs during
LoRA fine-tuning and proposing a Jacobian-free approximation method. Extensive
experiments across four low-resource domains (medical, financial, legal, and
psychological) demonstrate that NTK-Selector consistently improves downstream
performance. Specifically, fine-tuning on 1,000 in-domain samples alone only
yielded +0.8 points for Llama3-8B-Instruct and +0.9 points for Qwen3-8B. In
contrast, enriching with 9,000 auxiliary samples selected by NTK-Selector led
to substantial \textbf{gains of +8.7 and +5.1 points}, which corresponds to a
\textbf{10.9x and 5.7x improvement} over the domain-only setting.","Pingjie Wang, Hongcheng Liu, Yusheng Liao, Ziqing Fan, Yaxin Du, Shuo Tang, Yanfeng Wang, Yu Wang",arXiv,2025,2025-11-10 18:41:23+00:00,cs.CL
2511.07377v1,Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion,"LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.","June Moh Goo, Zichao Zeng, Jan Boehm",arXiv,2025,2025-11-10 18:38:15+00:00,"cs.CV, cs.AI, cs.RO"
2511.07365v1,Private Sketches for Linear Regression,"Linear regression is frequently applied in a variety of domains. In order to
improve the efficiency of these methods, various methods have been developed
that compute summaries or \emph{sketches} of the datasets. Certain domains,
however, contain sensitive data which necessitates that the application of
these statistical methods does not reveal private information. Differentially
private (DP) linear regression methods have been developed for mitigating this
problem. These techniques typically involve estimating a noisy version of the
parameter vector. Instead, we propose releasing private sketches of the
datasets. We present differentially private sketches for the problems of least
squares regression, as well as least absolute deviations regression. The
availability of these private sketches facilitates the application of commonly
available solvers for regression, without the risk of privacy leakage.","Shrutimoy Das, Debanuj Nayak, Anirban Dasgupta",arXiv,2025,2025-11-10 18:22:40+00:00,"cs.LG, stat.ML"
2511.07364v1,"Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence
  Estimation for Failure Detection","Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.","Vaibhav Mavi, Shubh Jaroria, Weiqi Sun",arXiv,2025,2025-11-10 18:19:51+00:00,"cs.LG, cs.AI, cs.CL"
2511.07363v1,"When the Correct Model Fails: The Optimality of Stackelberg Equilibria
  with Follower Intention Updates","We study a two-player dynamic Stackelberg game between a leader and a
follower. Classical formulations of the Stackelberg equilibrium (SE) assume
that the follower's best response (BR) mapping is known to the leader. However,
this is not always true in practice. In those cases the leader needs to
simultaneously infer this BR function while fulfilling an internal objective.
We study a setting in which the leader selects a control strategy that
optimizes an objective given an initial belief about the follower's best
response. This belief is updated during the finite decision horizon, prompting
the leader to reoptimize its control. We characterize the optimality guarantees
of the SE solutions under this belief update for both open loop (OL) and
feedback (FB) information structures. In particular, we show that it is
possible that assuming an incorrect follower BR map obtains a lower cost over
the game horizon than knowing the true BR. We support these claims with
numerical examples in a linear quadratic (LQ) Stackelberg game.","Cayetana Salinas Rodriguez, Jonathan Rogers, Sarah H. Q. Li",arXiv,2025,2025-11-10 18:19:23+00:00,"eess.SY, cs.GT, cs.SY"
2511.07362v1,Inference-Time Scaling of Diffusion Models for Infrared Data Generation,"Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.","Kai A. Horstmann, Maxim Clouser, Kia Khezeli",arXiv,2025,2025-11-10 18:18:38+00:00,"cs.CV, cs.AI, cs.LG"
2511.07355v1,"Scale setting of SU($N$) Yang--Mills theory, topology and large-$N$
  volume independence","We set the scale of SU($N$) Yang--Mills theories for $N=3,5,8$ and in the
large-$N$ limit via gradient flow, as a first step towards the computation of
the large-$N$ $\Lambda$-parameter using step scaling. We adopt twisted boundary
conditions to achieve large-$N$ volume reduction and the Parallel Tempering on
Boundary Conditions algorithm to tame topological freezing. This setup allows
accurate determinations of the gradient-flow scales even on extremely fine
lattices for all the explored values of $N$. Moreover, we are able to precisely
estimate the finite-size systematics related to topological freezing, and to
show the suppression of finite-volume effects expected by virtue of large-$N$
twisted volume reduction.","Claudio Bonanno, Jorge Luis Dasilva Golán, Margarita García Pérez, Massimo D'Elia, Andrea Giorgieri",arXiv,2025,2025-11-10 18:01:33+00:00,hep-lat
2511.07349v1,"Modeling Unsteady Aircraft Aerodynamics Using Lorenz Attractor: A
  Reduced-Order Approach for Wing Rock","This paper presents a novel modeling approach for unsteady aircraft airflow,
leveraging the Lorenz attractor framework. The proposed model is based on the
force distribution exerted by a lift-generating wing on the surrounding fluid.
It distinguishes between turbulent and nominal components of the force
distribution, with the nominal force distribution modeled to peak at the wing
and decay linearly into the free stream. This separation allows the turbulent
component to be represented by a transport equation that is influenced by
flight conditions, specifically dynamic pressure and angle of attack.
Consequently, the Navier-Stokes equations, along with the turbulence transport
equation, can be transformed into a reduced-order model characterized by three
scalar ordinary differential equations - similar to the Lorenz attractor. This
resulting system effectively captures chaotic behavior, facilitating the
exploration of complex dynamics without the computational demands of solving
the full Navier-Stokes equations. A simulation trade study is conducted that
models wing rock phenomena at high angles of attack, demonstrating the
effectiveness of the proposed approach in capturing the intricate dynamics of
unsteady aircraft aerodynamics.","Marcel Menner, Eugene Lavretsky",arXiv,2025,2025-11-10 17:52:04+00:00,"physics.flu-dyn, cs.SY, eess.SY, nlin.CD"
2511.07347v1,"Walsh-Hadamard Neural Operators for Solving PDEs with Discontinuous
  Coefficients","Neural operators have emerged as powerful tools for learning solution
operators of partial differential equations (PDEs). However, standard spectral
methods based on Fourier transforms struggle with problems involving
discontinuous coefficients due to the Gibbs phenomenon and poor representation
of sharp interfaces. We introduce the Walsh-Hadamard Neural Operator (WHNO),
which leverages Walsh-Hadamard transforms-a spectral basis of rectangular wave
functions naturally suited for piecewise constant fields-combined with
learnable spectral weights that transform low-sequency Walsh coefficients to
capture global dependencies efficiently. We validate WHNO on three problems:
steady-state Darcy flow (preliminary validation), heat conduction with
discontinuous thermal conductivity, and the 2D Burgers equation with
discontinuous initial conditions. In controlled comparisons with Fourier Neural
Operators (FNO) under identical conditions, WHNO demonstrates superior accuracy
with better preservation of sharp solution features at material interfaces.
Critically, we discover that weighted ensemble combinations of WHNO and FNO
achieve substantial improvements over either model alone: for both heat
conduction and Burgers equation, optimal ensembles reduce mean squared error by
35-40 percent and maximum error by up to 25 percent compared to individual
models. This demonstrates that Walsh-Hadamard and Fourier representations
capture complementary aspects of discontinuous PDE solutions, with WHNO
excelling at sharp interfaces while FNO captures smooth features effectively.","Giorrgio M. Cavallazzi, Miguel Perex Cuadrado, Alfredo Pinelli",arXiv,2025,2025-11-10 17:49:20+00:00,"physics.comp-ph, cs.LG"
2511.07346v1,"On Subexponential Parameterized Algorithms for Steiner Tree on
  Intersection Graphs of Geometric Objects","We study the Steiner Tree problem on the intersection graph of most natural
families of geometric objects, e.g., disks, squares, polygons, etc. Given a set
of $n$ objects in the plane and a subset $T$ of $t$ terminal objects, the task
is to find a subset $S$ of $k$ objects such that the intersection graph of
$S\cup T$ is connected. Given how typical parameterized problems behave on
planar graphs and geometric intersection graphs, we would expect that exact
algorithms with some form of subexponential dependence on the solution size or
the number of terminals exist. Contrary to this expectation, we show that,
assuming the Exponential-Time Hypothesis (ETH), there is no $2^{o(k+t)}\cdot
n^{O(1)}$ time algorithm even for unit disks or unit squares, that is, there is
no FPT algorithm subexponential in the size of the Steiner tree. However,
subexponential dependence can appear in a different form: we show that Steiner
Tree can be solved in time $n^{O(\sqrt{t})}$ for many natural classes of
objects, including: Disks of arbitrary size. Axis-parallel squares of arbitrary
size. Similarly-sized fat polygons.
  This in particular significantly improves and generalizes two recent results:
(1) Steiner Tree on unit disks can be solved in time $n^{\Oh(\sqrt{k + t})}$
(Bhore, Carmi, Kolay, and Zehavi, Algorithmica 2023) and (2) Steiner Tree on
planar graphs can be solved in time $n^{O(\sqrt{t})}$ (Marx, Pilipczuk, and
Pilipczuk, FOCS 2018). We complement our algorithms with lower bounds that
demonstrate that the class of objects cannot be significantly extended, even if
we allow the running time to be $n^{o(k+t)/\log(k+t)}$.","Sujoy Bhore, Baris Can Esmer, Daniel Marx, Karol Wegrzycki",arXiv,2025,2025-11-10 17:49:14+00:00,"cs.CG, cs.DS"
2511.07344v1,"Higher-Order Interactions in Brain Connectomics: Implicit versus
  Explicit Modeling Approaches","The human brain is a complex system defined by multi-way, higher-order
interactions invisible to traditional pairwise network models. Although a
diverse array of analytical methods has been developed to address this
shortcoming, the field remains fragmented, lacking a unifying conceptual
framework that integrates and organizes the rapidly expanding methodological
landscape of higher-order brain connectivity. This review provides a synthesis
of the methodologies for studying higher-order brain connectivity. We propose a
fundamental distinction between implicit paradigms, which quantify the
statistical strength of group interactions, and explicit paradigms, which
construct higher-order structural representations like hypergraphs and
topological data analysis. We trace the evolution of each approach, from early
Correlation-of-Correlations and information-theoretic concepts of
synergy/redundancy, to the edge-centric paradigm and advanced topological
methods. Through a critical analysis of conceptual, statistical, and
computational challenges, we argue that the future of the field lies not in a
single best method, but in a principled integration of these complementary
approaches. This manuscript aims to provide a unified map and a critical
perspective to guide researchers toward a robust and insightful understanding
of the brain's complex, multi-level architecture.","Mohamma Reza Salehi, Ali BashirGonbadi, Hamid Soltanian-Zadeh",arXiv,2025,2025-11-10 17:45:30+00:00,q-bio.QM
2511.07341v1,Universal Reduced-Operator Method and High-Order Global Curvature Bounds,"In this paper, we develop a new concept of Global Curvature Bound for an
arbitrary nonlinear operator between abstract metric spaces. We use this notion
to characterize the global complexity of high-order algorithms solving
composite variational problems, which include convex minimization and min-max
problems. We develop the new universal Reduced-Operator Method, which
automatically achieves the fastest universal rate within our class, while our
analysis does not need any specific assumptions about smoothness of the target
nonlinear operator. Every step of our universal method of order $p \geq 1$
requires access to the $p$-th order derivative of the operator and the solution
of a strictly monotone doubly regularized subproblem. For $p = 1$, this
corresponds to computing the standard Jacobian matrix of the operator and
solving a simple monotone subproblem, which can be handled using different
methods of Convex Optimization.","Nikita Doikov, Yurii Nesterov",arXiv,2025,2025-11-10 17:42:46+00:00,math.OC
2511.07340v1,"Smoothing Out Sticking Points: Sampling from Discrete-Continuous
  Mixtures with Dynamical Monte Carlo by Mapping Discrete Mass into a Latent
  Universe","Combining a continuous ""slab"" density with discrete ""spike"" mass at zero,
spike-and-slab priors provide important tools for inducing sparsity and
carrying out variable selection in Bayesian models. However, the presence of
discrete mass makes posterior inference challenging. ""Sticky"" extensions to
piecewise-deterministic Markov process samplers have shown promising
performance, where sampling from the spike is achieved by the process sticking
there for an exponentially distributed duration. As it turns out, the sampler
remains valid when the exponential sticking time is replaced with its
expectation. We justify this by mapping the spike to a continuous density over
a latent universe, allowing the sampler to be reinterpreted as traversing this
universe while being stuck in the original space. This perspective opens up an
array of possibilities to carry out posterior computation under spike-and-slab
type priors. Notably, it enables us to construct sticky samplers using other
dynamics-based paradigms such as Hamiltonian Monte Carlo, and, in fact,
original sticky process can be established as a partial position-momentum
refreshment limit of our Hamiltonian sticky sampler. Further, our theoretical
and empirical findings suggest these alternatives to be at least as efficient
as the original sticky approach.","Andrew Chin, Akihiko Nishimura",arXiv,2025,2025-11-10 17:40:12+00:00,"stat.CO, stat.ME"
2511.07337v1,Model Counting for Dependency Quantified Boolean Formulas,"Dependency Quantified Boolean Formulas (DQBF) generalize QBF by explicitly
specifying which universal variables each existential variable depends on,
instead of relying on a linear quantifier order. The satisfiability problem of
DQBF is NEXP-complete, and many hard problems can be succinctly encoded as
DQBF. Recent work has revealed a strong analogy between DQBF and SAT: k-DQBF
(with k existential variables) is a succinct form of k-SAT, and satisfiability
is NEXP-complete for 3-DQBF but PSPACE-complete for 2-DQBF, mirroring the
complexity gap between 3-SAT (NP-complete) and 2-SAT (NL-complete).
  Motivated by this analogy, we study the model counting problem for DQBF,
denoted #DQBF. Our main theoretical result is that #2-DQBF is #EXP-complete,
where #EXP is the exponential-time analogue of #P. This parallels Valiant's
classical theorem stating that #2-SAT is #P-complete. As a direct application,
we show that first-order model counting (FOMC) remains #EXP-complete even when
restricted to a PSPACE-decidable fragment of first-order logic and domain size
two.
  Building on recent successes in reducing 2-DQBF satisfiability to symbolic
model checking, we develop a dedicated 2-DQBF model counter. Using a diverse
set of crafted instances, we experimentally evaluated it against a baseline
that expands 2-DQBF formulas into propositional formulas and applies
propositional model counting. While the baseline worked well when each
existential variable depends on few variables, our implementation scaled
significantly better to larger dependency sets.","Long-Hin Fung, Che Cheng, Jie-Hong Roland Jiang, Friedrich Slivovsky, Tony Tan",arXiv,2025,2025-11-10 17:37:44+00:00,"cs.LO, cs.CC"
2511.07336v1,"AcousTools: A `Full-Stack', Python-Based, Acoustic Holography Library","Acoustic Holography is an emerging field where mid-air ultrasound is
controlled and manipulated for novel and exciting applications. These range
from mid-air haptics, volumetric displays, contactless fabrication, and even
chemical and biomedical applications such as drug delivery. To develop these
applications, a software framework to predict acoustic behaviour and simulating
resulting effects, such as applied forces or scattering patterns is desirable.
There have been various software libraries and platforms that attempt to fill
this role, but there is yet to be a single piece of software that acts as a
'full-stack' solution. We define this full-stack as the process from
abstraction to physicalisation starting with setup, modelling acoustic
propagation, transducer phase retrieval, sound field analysis, and control of
the acoustic holographic hardware itself. Existing methods fail to fulfil one
or more of these categories. To address this, we present AcousTools, a
Python-based acoustic holography library, designed to support the full suite of
acoustic holographic applications and we show AcousTools's ability to meet each
step of the full-stack's requirements. AcousTools has the potential to become
the standard code library for acoustic holography, with the uniquely complete
suite of features wrapped in a language that is known to be easy to use,
AcousTools will increase the ability for researchers to develop novel
applications as well as accurately review other's work. The full-stack, aside
from software, will also be useful for researchers - providing a way to view
and compare methodologies by understanding where they fit into the stack.","Joshua Mukherjee, Giorgos Christopoulos, Zhouyang Shen, Sriram Subramanian, Ryuji Hirayama",arXiv,2025,2025-11-10 17:36:33+00:00,"cs.SD, cs.ET"
2511.07332v1,Grounding Computer Use Agents on Human Demonstrations,"Building reliable computer-use agents requires grounding: accurately
connecting natural language instructions to the correct on-screen elements.
While large datasets exist for web and mobile interactions, high-quality
resources for desktop environments are limited. To address this gap, we
introduce GroundCUA, a large-scale desktop grounding dataset built from expert
human demonstrations. It covers 87 applications across 12 categories and
includes 56K screenshots, with every on-screen element carefully annotated for
a total of over 3.56M human-verified annotations. From these demonstrations, we
generate diverse instructions that capture a wide range of real-world tasks,
providing high-quality data for model training. Using GroundCUA, we develop the
GroundNext family of models that map instructions to their target UI elements.
At both 3B and 7B scales, GroundNext achieves state-of-the-art results across
five benchmarks using supervised fine-tuning, while requiring less than
one-tenth the training data of prior work. Reinforcement learning post-training
further improves performance, and when evaluated in an agentic setting on the
OSWorld benchmark using o3 as planner, GroundNext attains comparable or
superior results to models trained with substantially more data,. These results
demonstrate the critical role of high-quality, expert-driven datasets in
advancing general-purpose computer-use agents.","Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar",arXiv,2025,2025-11-10 17:35:21+00:00,"cs.LG, cs.AI"
2511.07330v1,"Roundabout Constrained Convex Generators: A Unified Framework for
  Multiply-Connected Reachable Sets","This paper introduces Roundabout Constrained Convex Generators (RCGs), a set
representation framework for modeling multiply connected regions in control and
verification applications. The RCG representation extends the constrained
convex generators framework by incorporating an inner exclusion zone, creating
sets with topological holes that naturally arise in collision avoidance and
safety-critical control problems. We present two equivalent formulations: a set
difference representation that provides geometric intuition and a unified
parametric representation that facilitates computational implementation. The
paper establishes closure properties under fundamental operations, including
linear transformations, Minkowski sums, and intersections with convex generator
sets. We derive special cases, including roundabout zonotopes and roundabout
ellipsotopes, which offer computational advantages for specific norm
selections. The framework maintains compatibility with existing optimization
solvers while enabling the representation of non-convex feasible regions that
were previously challenging to model efficiently.","Peng Xie, Sabin Diaconescu, Florin Stoican, Amr Alanwar",arXiv,2025,2025-11-10 17:32:24+00:00,"math.OC, cs.SY, eess.SY"
2511.07329v1,"Preparation of Fractal-Inspired Computational Architectures for Advanced
  Large Language Model Analysis","It introduces FractalNet, a fractal-inspired computational architectures for
advanced large language model analysis that mainly challenges model diversity
on a large scale in an efficient manner. The new set-up involves a
template-driven generator, runner, and evaluation framework that, through
systematic permutations of convolutional, normalization, activation, and
dropout layers, can create more than 1,200 variants of neural networks. Fractal
templates allow for structural recursion and multi-column pathways, thus,
models become deeper and wider in a balanced way. Training utilizes PyTorch,
Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out
on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based
architectures are capable of strong performance and are computationally
efficient. The paper positions fractal design as a feasible and
resource-efficient method of automated architecture exploration.","Yash Mittal, Dmitry Ignatov, Radu Timofte",arXiv,2025,2025-11-10 17:31:39+00:00,"cs.LG, cs.CV"
2511.07327v1,"IterResearch: Rethinking Long-Horizon Agents via Markovian State
  Reconstruction","Recent advances in deep-research agents have shown promise for autonomous
knowledge construction through dynamic reasoning over external sources.
However, existing approaches rely on a mono-contextual paradigm that
accumulates all information in a single, expanding context window, leading to
context suffocation and noise contamination that limit their effectiveness on
long-horizon tasks. We introduce IterResearch, a novel iterative deep-research
paradigm that reformulates long-horizon research as a Markov Decision Process
with strategic workspace reconstruction. By maintaining an evolving report as
memory and periodically synthesizing insights, our approach preserves
consistent reasoning capacity across arbitrary exploration depths. We further
develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning
framework that incentivizes efficient exploration through geometric reward
discounting and enables stable distributed training via adaptive downsampling.
Extensive experiments demonstrate that IterResearch achieves substantial
improvements over existing open-source agents with average +14.5pp across six
benchmarks and narrows the gap with frontier proprietary systems. Remarkably,
our paradigm exhibits unprecedented interaction scaling, extending to 2048
interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves
as an effective prompting strategy, improving frontier models by up to 19.2pp
over ReAct on long-horizon tasks. These findings position IterResearch as a
versatile solution for long-horizon reasoning, effective both as a trained
agent and as a prompting paradigm for frontier models.","Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",arXiv,2025,2025-11-10 17:30:08+00:00,"cs.AI, cs.CL"
2511.07325v1,Garbage Vulnerable Point Monitoring using IoT and Computer Vision,"This paper proposes a smart way to manage municipal solid waste by using the
Internet of Things (IoT) and computer vision (CV) to monitor illegal waste
dumping at garbage vulnerable points (GVPs) in urban areas. The system can
quickly detect and monitor dumped waste using a street-level camera and object
detection algorithm. Data was collected from the Sangareddy district in
Telangana, India. A series of comprehensive experiments was carried out using
the proposed dataset to assess the accuracy and overall performance of various
object detection models. Specifically, we performed an in-depth evaluation of
YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models,
YOLO11m achieved the highest accuracy of 92.39\% in waste detection,
demonstrating its effectiveness in detecting waste. Additionally, it attains an
mAP@50 of 0.91, highlighting its high precision. These findings confirm that
the object detection model is well-suited for monitoring and tracking waste
dumping events at GVP locations. Furthermore, the system effectively captures
waste disposal patterns, including hourly, daily, and weekly dumping trends,
ensuring comprehensive daily and nightly monitoring.","R. Kumar, A. Lall, S. Chaudhari, M. Kale, A. Vattem",arXiv,2025,2025-11-10 17:27:51+00:00,"cs.CV, cs.LG"
2511.07322v1,"FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework
  for Equity Research Report Generation","While LLMs have shown great success in financial tasks like stock prediction
and question answering, their application in fully automating Equity Research
Report generation remains uncharted territory. In this paper, we formulate the
Equity Research Report (ERR) Generation task for the first time. To address the
data scarcity and the evaluation metrics absence, we present an open-source
evaluation benchmark for ERR generation - FinRpt. We frame a Dataset
Construction Pipeline that integrates 7 financial data types and produces a
high-quality ERR dataset automatically, which could be used for model training
and evaluation. We also introduce a comprehensive evaluation system including
11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent
framework specifically tailored to address this task, named FinRpt-Gen, and
train several LLM-based agents on the proposed datasets using Supervised
Fine-Tuning and Reinforcement Learning. Experimental results indicate the data
quality and metrics effectiveness of the benchmark FinRpt and the strong
performance of FinRpt-Gen, showcasing their potential to drive innovation in
the ERR generation field. All code and datasets are publicly available.","Song Jin, Shuqi Li, Shukun Zhang, Rui Yan",arXiv,2025,2025-11-10 17:22:32+00:00,"cs.CL, cs.AI"
2511.07321v1,YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting,"Fast and flexible 3D scene reconstruction from unstructured image collections
remains a significant challenge. We present YoNoSplat, a feedforward model that
reconstructs high-quality 3D Gaussian Splatting representations from an
arbitrary number of images. Our model is highly versatile, operating
effectively with both posed and unposed, calibrated and uncalibrated inputs.
YoNoSplat predicts local Gaussians and camera poses for each view, which are
aggregated into a global representation using either predicted or provided
poses. To overcome the inherent difficulty of jointly learning 3D Gaussians and
camera parameters, we introduce a novel mixing training strategy. This approach
mitigates the entanglement between the two tasks by initially using
ground-truth poses to aggregate local Gaussians and gradually transitioning to
a mix of predicted and ground-truth poses, which prevents both training
instability and exposure bias. We further resolve the scale ambiguity problem
by a novel pairwise camera-distance normalization scheme and by embedding
camera intrinsics into the network. Moreover, YoNoSplat also predicts intrinsic
parameters, making it feasible for uncalibrated inputs. YoNoSplat demonstrates
exceptional efficiency, reconstructing a scene from 100 views (at 280x518
resolution) in just 2.69 seconds on an NVIDIA GH200 GPU. It achieves
state-of-the-art performance on standard benchmarks in both pose-free and
pose-dependent settings. Our project page is at
https://botaoye.github.io/yonosplat/.","Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, Marc Pollefeys",arXiv,2025,2025-11-10 17:21:54+00:00,cs.CV
2511.07318v1,"When Bias Pretends to Be Truth: How Spurious Correlations Undermine
  Hallucination Detection in LLMs","Despite substantial advances, large language models (LLMs) continue to
exhibit hallucinations, generating plausible yet incorrect responses. In this
paper, we highlight a critical yet previously underexplored class of
hallucinations driven by spurious correlations -- superficial but statistically
prominent associations between features (e.g., surnames) and attributes (e.g.,
nationality) present in the training data. We demonstrate that these spurious
correlations induce hallucinations that are confidently generated, immune to
model scaling, evade current detection methods, and persist even after refusal
fine-tuning. Through systematically controlled synthetic experiments and
empirical evaluations on state-of-the-art open-source and proprietary LLMs
(including GPT-5), we show that existing hallucination detection methods, such
as confidence-based filtering and inner-state probing, fundamentally fail in
the presence of spurious correlations. Our theoretical analysis further
elucidates why these statistical biases intrinsically undermine
confidence-based detection techniques. Our findings thus emphasize the urgent
need for new approaches explicitly designed to address hallucinations caused by
spurious correlations.","Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun, Kaifeng Lyu, Jian Li",arXiv,2025,2025-11-10 17:19:27+00:00,"cs.CL, cs.AI, cs.LG"
2511.07317v1,"RLVE: Scaling Up Reinforcement Learning for Language Models with
  Adaptive Verifiable Environments","We introduce Reinforcement Learning (RL) with Adaptive Verifiable
Environments (RLVE), an approach using verifiable environments that
procedurally generate problems and provide algorithmically verifiable rewards,
to scale up RL for language models (LMs). RLVE enables each verifiable
environment to dynamically adapt its problem difficulty distribution to the
policy model's capabilities as training progresses. In contrast, static data
distributions often lead to vanishing learning signals when problems are either
too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a
large-scale suite of 400 verifiable environments carefully developed through
manual environment engineering. Using RLVE-Gym, we show that environment
scaling, i.e., expanding the collection of training environments, consistently
improves generalizable reasoning capabilities. RLVE with joint training across
all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement
across six reasoning benchmarks, starting from one of the strongest 1.5B
reasoning LMs. By comparison, continuing this LM's original RL training yields
only a 0.49% average absolute gain despite using over 3x more compute. We
release our code publicly.","Zhiyuan Zeng, Hamish Ivison, Yiping Wang, Lifan Yuan, Shuyue Stella Li, Zhuorui Ye, Siting Li, Jacqueline He, Runlong Zhou, Tong Chen, Chenyang Zhao, Yulia Tsvetkov, Simon Shaolei Du, Natasha Jaques, Hao Peng, Pang Wei Koh, Hannaneh Hajishirzi",arXiv,2025,2025-11-10 17:18:35+00:00,"cs.CL, cs.LG"
2511.07314v1,The free bifibration on a functor,"We consider the problem of constructing the free bifibration generated by a
functor of categories $p : D \to C$. This problem was previously considered by
Lamarche, and is closely related to the problem, considered by Dawson, Par\'e,
and Pronk, of ""freely adjoining adjoints"" to a category. We develop a
proof-theoretic approach to the problem, beginning with a construction of the
free bifibration $\Lambda_p : \mathcal{B}\mathrm{if}(p)\to C$ in which objects
of $\mathcal{B}\mathrm{if}(p)$ are formulas of a primitive ""bifibrational
logic"", and arrows are derivations in a cut-free sequent calculus modulo a
notion of permutation equivalence. We show that instantiating the construction
to the identity functor generates a _zigzag double category_ $\mathbb{Z}(C)$,
which is also the free double category with companions and conjoints (or
fibrant double category) on $C$. The approach adapts smoothly to the more
general task of building $(P,N)$-fibrations, where one only asks for
pushforwards along arrows in $P$ and pullbacks along arrows in $N$ for some
subsets of arrows, which encompasses Kock and Joyal's notion of _ambifibration_
when $(P,N)$ form a factorization system. We establish a series of
progressively stronger normal forms, guided by ideas of _focusing_ from proof
theory, and obtain a canonicity result under assumption that the base category
is factorization preordered relative to $P$ and $N$. This canonicity result
allows us to decide the word problem and to enumerate relative homsets without
duplicates. Finally, we describe several examples of a combinatorial nature,
including a category of plane trees generated as a free bifibration over
$\omega$, and a category of increasing forests generated as a free
ambifibration over $\Delta$, which contains the lattices of noncrossing
partitions as quotients of its fibers by the Beck-Chevalley condition.","Bryce Clarke, Gabriel Scherer, Noam Zeilberger",arXiv,2025,2025-11-10 17:16:20+00:00,"math.CT, cs.LO, 18N10, 18D30, 03B47, 03F05"
2511.07311v1,ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding,"Automatic ICD coding, the task of assigning disease and procedure codes to
electronic medical records, is crucial for clinical documentation and billing.
While existing methods primarily enhance model understanding of code
hierarchies and synonyms, they often overlook the pervasive use of medical
acronyms in clinical notes, a key factor in ICD code inference. To address this
gap, we propose a novel effective data augmentation technique that leverages
large language models to expand medical acronyms, allowing models to be trained
on their full form representations. Moreover, we incorporate consistency
training to regularize predictions by enforcing agreement between the original
and augmented documents. Extensive experiments on the MIMIC-III dataset
demonstrate that our approach, ACE-ICD establishes new state-of-the-art
performance across multiple settings, including common codes, rare codes, and
full-code assignments. Our code is publicly available.","Tuan-Dung Le, Shohreh Haddadan, Thanh Q. Thieu",arXiv,2025,2025-11-10 17:11:20+00:00,cs.CL
2511.07310v1,"Low-Complexity ADMM-Based Multicast Beamforming in Cell-Free Massive
  MIMO Systems","The growing demand for efficient delivery of common content to multiple user
equipments (UEs) has motivated significant research in physical-layer
multicasting. By exploiting the beamforming capabilities of massive MIMO,
multicasting provides a spectrum-efficient solution that avoids unnecessary
intra-group interference. A key challenge, however, is solving the max-min fair
(MMF) and quality-of-service (QoS) multicast beamforming optimization problems,
which are NP-hard due to the non-convex structure and the requirement for
rank-1 solutions. Traditional approaches based on semidefinite relaxation (SDR)
followed by randomization exhibit poor scalability with system size, while
state-of-the-art successive convex approximation (SCA) methods only guarantee
convergence to stationary points. In this paper, we propose an alternating
direction method of multipliers (ADMM)-based framework for MMF and QoS
multicast beamforming in cell-free massive MIMO networks. The algorithm
leverages SDR but incorporates a novel iterative elimination strategy within
the ADMM updates to efficiently obtain near-global optimal rank-1 beamforming
solutions with reduced computational complexity compared to standard SDP
solvers and randomization methods. Numerical evaluations demonstrate that the
proposed ADMM-based procedure not only achieves superior spectral efficiency
but also scales favorably with the number of antennas and UEs compared to
state-of-the-art SCA-based algorithms, making it a practical tool for
next-generation multicast systems.","Mahmoud Zaher, Emil Björnson",arXiv,2025,2025-11-10 17:11:09+00:00,eess.SP
2511.07307v1,"Singling out people without knowing their names - Behavioural targeting,
  pseudonymous data, and the New Data Protection Regulation","Information about millions of people is collected for behavioural targeting,
a type of marketing that involves tracking people's online behaviour for
targeted advertising. It is hotly debated whether data protection law applies
to behavioural targeting. Many behavioural targeting companies say that, as
long as they do not tie names to data they hold about individuals, they do not
process any personal data, and that, therefore, data protection law does not
apply to them. European Data Protection Authorities, however, take the view
that a company processes personal data if it uses data to single out a person,
even if it cannot tie a name to these data. This paper argues that data
protection law should indeed apply to behavioural targeting. Companies can
often tie a name to nameless data about individuals. Furthermore, behavioural
targeting relies on collecting information about individuals, singling out
individuals, and targeting ads to individuals. Many privacy risks remain,
regardless of whether companies tie a name to the information they hold about a
person. A name is merely one of the identifiers that can be tied to data about
a person, and it is not even the most practical identifier for behavioural
targeting. Seeing data used to single out a person as personal data fits the
rationale for data protection law: protecting fairness and privacy.",Frederik J. Zuiderveen Borgesius,arXiv,2025,2025-11-10 17:09:31+00:00,cs.CY
2511.07306v1,"Het 'right to be forgotten' en bijzondere persoonsgegevens: geen ruimte
  meer voor een belangenafweging? [The 'Right to Be Forgotten' and Sensitive
  Personal Data: No Room for Balancing?]","An attorney submitted a 'right to be forgotten' delisting request to Google,
regarding a blog post about a criminal conviction of the attorney in another
country. The Rotterdam District Court ruled that Google may no longer link to
the blog post when people search for the attorney's name. The court granted the
attorney's request because the blog post concerns a criminal conviction.
Personal data regarding criminal convictions are, under Dutch law, special
categories of data (sometimes called sensitive data). The reasoning of the
court on special categories of data creates problems for freedom of expression.
This paper, in Dutch, explores how these problems can be reduced. Google has
appealed the decision; the judgment of the Court of Appeals is expected in
March 2017.",Frederik Zuiderveen Borgesius,arXiv,2025,2025-11-10 17:09:29+00:00,cs.CY
2511.07304v1,"Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task
  Learning Approach for Bangla Hate Speech Identification","This paper addresses the problem of Bangla hate speech identification, a
socially impactful yet linguistically challenging task. As part of the ""Bangla
Multi-task Hate Speech Identification"" shared task at the BLP Workshop,
IJCNLP-AACL 2025, our team ""Retriv"" participated in all three subtasks: (1A)
hate type classification, (1B) target group identification, and (1C) joint
detection of type, severity, and target. For subtasks 1A and 1B, we employed a
soft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2).
For subtask 1C, we trained three multitask variants and aggregated their
predictions through a weighted voting ensemble. Our systems achieved micro-f1
scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62%
(1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7th
positions, respectively. These results highlight the promise of transformer
ensembles and weighted multitask frameworks for advancing Bangla hate speech
detection in low-resource contexts. We made experimental scripts publicly
available for the community.","Sourav Saha, K M Nafi Asib, Mohammed Moshiul Hoque",arXiv,2025,2025-11-10 17:07:09+00:00,cs.CL
2511.07301v1,"Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free
  Object Detection","Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object
detector to a target domain without access to source data. However, existing
SFOD methods predominantly rely on internal knowledge from the source model,
which limits their capacity to generalize across domains and often results in
biased pseudo-labels, thereby hindering both transferability and
discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on
massive and diverse data, exhibit strong perception capabilities and broad
generalization, yet their potential remains largely untapped in the SFOD
setting. In this paper, we propose a novel SFOD framework that leverages VFMs
as external knowledge sources to jointly enhance feature alignment and label
quality. Specifically, we design three VFM-based modules: (1) Patch-weighted
Global Feature Alignment (PGFA) distills global features from VFMs using
patch-similarity-based weighting to enhance global feature transferability; (2)
Prototype-based Instance Feature Alignment (PIFA) performs instance-level
contrastive learning guided by momentum-updated VFM prototypes; and (3)
Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from
detection VFMs and teacher models via an entropy-aware strategy to yield more
reliable supervision. Extensive experiments on six benchmarks demonstrate that
our method achieves state-of-the-art SFOD performance, validating the
effectiveness of integrating VFMs to simultaneously improve transferability and
discriminability.","Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu, Hui Xiong",arXiv,2025,2025-11-10 17:06:01+00:00,"cs.CV, cs.AI"
2511.07419v1,"Routing Manifold Alignment Improves Generalization of Mixture-of-Experts
  LLMs","Sparse Mixture-of-Experts (MoE) have been widely adopted in recent large
language models since it can efficiently scale up the model capability without
increasing the inference cost. However, evaluations on broad downstream tasks
reveal a consistent suboptimality of the routers in existing MoE LLMs, which
results in a severe performance gap (e.g., 10-20% in accuracy) to the optimal
routing. In this paper, we show that aligning the manifold of routing weights
with that of task embedding can effectively reduce the gap and improve MoE
LLMs' generalization performance. Our method, ""Routing Manifold Alignment
(RoMA)"", introduces an additional manifold regularization term in the
post-training objective and only requires lightweight finetuning of routers
(with other parameters frozen). Specifically, the regularization encourages the
routing weights of each sample to be close to those of its successful neighbors
(whose routing weights lead to correct answers) in a task embedding space.
Consequently, samples targeting similar tasks will share similar expert choices
across layers. Building such bindings between tasks and experts over different
samples is essential to achieve better generalization. Moreover, RoMA
demonstrates the advantage of unifying the task understanding (by embedding
models) with solution generation (by MoE LLMs). In experiments, we finetune
routers in OLMoE, DeepSeekMoE, and Qwen3-MoE using RoMA. Evaluations on diverse
benchmarks and extensive comparisons with baselines show the substantial
improvement brought by RoMA.","Zhongyang Li, Ziyue Li, Tianyi Zhou",arXiv,2025,2025-11-10 18:59:53+00:00,cs.LG
2511.07418v1,"Lightning Grasp: High Performance Procedural Grasp Synthesis with
  Contact Fields","Despite years of research, real-time diverse grasp synthesis for dexterous
hands remains an unsolved core challenge in robotics and computer graphics. We
present Lightning Grasp, a novel high-performance procedural grasp synthesis
algorithm that achieves orders-of-magnitude speedups over state-of-the-art
approaches, while enabling unsupervised grasp generation for irregular,
tool-like objects. The method avoids many limitations of prior approaches, such
as the need for carefully tuned energy functions and sensitive initialization.
This breakthrough is driven by a key insight: decoupling complex geometric
computation from the search process via a simple, efficient data structure -
the Contact Field. This abstraction collapses the problem complexity, enabling
a procedural search at unprecedented speeds. We open-source our system to
propel further innovation in robotic manipulation.","Zhao-Heng Yin, Pieter Abbeel",arXiv,2025,2025-11-10 18:59:44+00:00,"cs.RO, cs.AI, cs.CV, cs.DC, cs.GR"
2511.07417v1,Language Generation with Infinite Contamination,"We study language generation in the limit, where an algorithm observes an
adversarial enumeration of strings from an unknown target language $K$ and must
eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan
[KM24] proved that generation is achievable in surprisingly general settings.
But their generator suffers from ``mode collapse,'' producing from an
ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25]
require the generator's output to be ``dense'' in the target language. They
showed that generation with density, surprisingly, remains achievable at the
same generality.
  Both results assume perfect data: no noisy insertions and no omissions. This
raises a central question: how much contamination can generation tolerate?
Recent works made partial progress on this question by studying (non-dense)
generation with either finite amounts of noise (but no omissions) or omissions
(but no noise).
  We characterize robustness under contaminated enumerations: 1. Generation
under Contamination: Language generation in the limit is achievable for all
countable collections iff the fraction of contaminated examples converges to
zero. When this fails, we characterize which collections are generable. 2.
Dense Generation under Contamination: Dense generation is strictly less robust
to contamination than generation. As a byproduct, we resolve an open question
of Raman and Raman [ICML25] by showing that generation is possible with only
membership oracle access under finitely many contaminated examples.
  Finally, we introduce a beyond-worst-case model inspired by curriculum
learning and prove that dense generation is achievable even with infinite
contamination provided the fraction of contaminated examples converges to zero.
This suggests curriculum learning may be crucial for learning from noisy web
data.","Anay Mehrotra, Grigoris Velegkas, Xifan Yu, Felix Zhou",arXiv,2025,2025-11-10 18:59:39+00:00,"stat.ML, cs.AI, cs.CL, cs.DS, cs.LG"
2511.07416v1,Robot Learning from a Physical World Model,"We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.","Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang",arXiv,2025,2025-11-10 18:59:07+00:00,"cs.RO, cs.AI, cs.CV"
2511.07413v1,DigiData: Training and Evaluating General-Purpose Mobile Control Agents,"AI agents capable of controlling user interfaces have the potential to
transform human interaction with digital devices. To accelerate this
transformation, two fundamental building blocks are essential: high-quality
datasets that enable agents to achieve complex and human-relevant goals, and
robust evaluation methods that allow researchers and practitioners to rapidly
enhance agent performance. In this paper, we introduce DigiData, a large-scale,
high-quality, diverse, multi-modal dataset designed for training mobile control
agents. Unlike existing datasets, which derive goals from unstructured
interactions, DigiData is meticulously constructed through comprehensive
exploration of app features, resulting in greater diversity and higher goal
complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating
mobile control agents on real-world complex tasks. We demonstrate that the
commonly used step-accuracy metric falls short in reliably assessing mobile
control agents and, to address this, we propose dynamic evaluation protocols
and AI-powered evaluations as rigorous alternatives for agent assessment. Our
contributions aim to significantly advance the development of mobile control
agents, paving the way for more intuitive and effective human-device
interactions.","Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan, Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, Nitin Kamra, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer, Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway, Joseph Tighe",arXiv,2025,2025-11-10 18:57:35+00:00,"cs.AI, cs.CL, cs.HC, cs.LG"
2511.07410v1,"Using Vision Language Models as Closed-Loop Symbolic Planners for
  Robotic Applications: A Control-Theoretic Perspective","Large Language Models (LLMs) and Vision Language Models (VLMs) have been
widely used for embodied symbolic planning. Yet, how to effectively use these
models for closed-loop symbolic planning remains largely unexplored. Because
they operate as black boxes, LLMs and VLMs can produce unpredictable or costly
errors, making their use in high-level robotic planning especially challenging.
In this work, we investigate how to use VLMs as closed-loop symbolic planners
for robotic applications from a control-theoretic perspective. Concretely, we
study how the control horizon and warm-starting impact the performance of VLM
symbolic planners. We design and conduct controlled experiments to gain
insights that are broadly applicable to utilizing VLMs as closed-loop symbolic
planners, and we discuss recommendations that can help improve the performance
of VLM symbolic planners.","Hao Wang, Sathwik Karnik, Bea Lim, Somil Bansal",arXiv,2025,2025-11-10 18:56:56+00:00,"cs.RO, cs.AI"
2511.07409v1,DIMO: Diverse 3D Motion Generation for Arbitrary Objects,"We present DIMO, a generative approach capable of generating diverse 3D
motions for arbitrary objects from a single image. The core idea of our work is
to leverage the rich priors in well-trained video models to extract the common
motion patterns and then embed them into a shared low-dimensional latent space.
Specifically, we first generate multiple videos of the same object with diverse
motions. We then embed each motion into a latent vector and train a shared
motion decoder to learn the distribution of motions represented by a structured
and compact motion representation, i.e., neural key point trajectories. The
canonical 3D Gaussians are then driven by these key points and fused to model
the geometry and appearance. During inference time with learned latent space,
we can instantly sample diverse 3D motions in a single-forward pass and support
several interesting applications including 3D motion interpolation and
language-guided motion generation. Our project page is available at
https://linzhanm.github.io/dimo.","Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis",arXiv,2025,2025-11-10 18:56:49+00:00,cs.CV
2511.07407v1,Unified Humanoid Fall-Safety Policy from a Few Demonstrations,"Falling is an inherent risk of humanoid mobility. Maintaining stability is
thus a primary safety focus in robot control and learning, yet no existing
approach fully averts loss of balance. When instability does occur, prior work
addresses only isolated aspects of falling: avoiding falls, choreographing a
controlled descent, or standing up afterward. Consequently, humanoid robots
lack integrated strategies for impact mitigation and prompt recovery when real
falls defy these scripts. We aim to go beyond keeping balance to make the
entire fall-and-recovery process safe and autonomous: prevent falls when
possible, reduce impact when unavoidable, and stand up when fallen. By fusing
sparse human demonstrations with reinforcement learning and an adaptive
diffusion-based memory of safe reactions, we learn adaptive whole-body
behaviors that unify fall prevention, impact mitigation, and rapid recovery in
one policy. Experiments in simulation and on a Unitree G1 demonstrate robust
sim-to-real transfer, lower impact forces, and consistently fast recovery
across diverse disturbances, pointing towards safer, more resilient humanoids
in real environments. Videos are available at https://firm2025.github.io/.","Zhengjie Xu, Ye Li, Kwan-yee Lin, Stella X. Yu",arXiv,2025,2025-11-10 18:56:31+00:00,cs.RO
2511.07405v1,"SPOT: An Annotated French Corpus and Benchmark for Detecting Critical
  Interventions in Online Conversations","We introduce SPOT (Stopping Points in Online Threads), the first annotated
corpus translating the sociological concept of stopping point into a
reproducible NLP task. Stopping points are ordinary critical interventions that
pause or redirect online discussions through a range of forms (irony, subtle
doubt or fragmentary arguments) that frameworks like counterspeech or social
correction often overlook. We operationalize this concept as a binary
classification task and provide reliable annotation guidelines. The corpus
contains 43,305 manually annotated French Facebook comments linked to URLs
flagged as false information by social media users, enriched with contextual
metadata (article, post, parent comment, page or group, and source). We
benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs
under various prompting strategies. Results show that fine-tuned encoders
outperform prompted LLMs in F1 score by more than 10 percentage points,
confirming the importance of supervised learning for emerging non-English
social media tasks. Incorporating contextual metadata further improves encoder
models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along
with the annotation guidelines and code in our code repository, to foster
transparency and reproducible research.","Manon Berriche, Célia Nouri, Chloé Clavel, Jean-Philippe Cointet",arXiv,2025,2025-11-10 18:54:40+00:00,"cs.CL, cs.CY"
2511.07404v1,Entanglement-driven responses through multiscale 3D-printed knits,"For their resilience and toughness, filamentous entanglements are ubiquitous
in both natural and engineered systems across length scales, from
polymer-chain- to collagen-networks and from cable-net structures to forest
canopies. Textiles are an everyday manifestation of filamentous entanglement:
the remarkable resilience and toughness in knitted fabrics arise predominately
from the topology of interlooped yarns. Yet most architected materials do not
exploit entanglement as a design primitive, and industrial knitting fixes a
narrow set of patterns for manufacturability. Additive manufacturing has
recently enabled interlocking structures such as chainmail, knot and woven
assemblies, hinting at broader possibilities for entangled architectures. The
general challenge is to treat knitting itself as a three-dimensional
architected material with predictable and tunable mechanics across scales.
Here, we show that knitted architectures fabricated additively can be recast as
periodic entangled solids whose responses are both fabric-like and
programmable. We reproduce the characteristic behavior of conventional planar
knits and extend knitting into the third dimension by interlooping along three
orthogonal directions, yielding volumetric knits whose stiffness and
dissipation are tuned by prescribed pre-strain. We propose a simple scaling
that unifies the responses across stitch geometries and constituent materials.
Further, we realize the same topology from centimeter to micrometer scales,
culminating in the fabrication of what is, to our knowledge, the smallest
knitted structure ever made. By demonstrating 3D-printed knits can be
interpreted both as a traditional fabric, as well as a novel architected
material with defined periodicity, this work establishes the dual nature of
entangled filaments and paves the way towards a new form of material
architectures with high degrees of entanglement.","Bradley Cline, Catherine Bai, Sehui Jeong, Ling Xu, Yue Wang, James U. Surjadi, Carlos M. Portela, Tian Chen",arXiv,2025,2025-11-10 18:53:35+00:00,"physics.app-ph, cond-mat.soft"
2511.07403v1,"SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial
  Rewards","Multimodal large language models (MLLMs) have achieved remarkable progress in
vision-language tasks, but they continue to struggle with spatial
understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
architecture-specific modifications, and remain constrained by large-scale
datasets or sparse supervision. To address these limitations, we introduce
SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
grounding with multi-step reasoning. The model simulates human-like spatial
perception by constructing a scene graph of task-relevant objects and spatial
relations, and reasoning towards an answer via dense spatial rewards.
SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
with a multi-objective dense spatial reward enforcing spatial grounding.
SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
on spatial understanding and real-world VQA benchmarks, nearly doubling the
base-model gain compared to sparse RL, and surpassing GPT-4o. These results
showcase the effectiveness of combining spatial supervision with reward-aligned
reasoning in enabling robust 3D spatial understanding with limited data and
advancing MLLMs towards human-level visual reasoning.","Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark",arXiv,2025,2025-11-10 18:52:47+00:00,"cs.CV, cs.AI, cs.CL, cs.LG"
2511.07402v1,"The ideal limit of rhombohedral graphene: Interaction-induced
  layer-skyrmion lattices and their collective excitations","We introduce an ideal limit of rhombohedral graphene multilayers. In this
limit, we show analytically how short-range repulsion stabilizes a
layer-pseudospin skyrmion lattice, which generates an effective magnetic field
and gives rise to a Chern band. This establishes the real-space origin of
interaction-driven topology in moir\'e rhombohedral graphene. The resulting
interaction-induced skyrmion lattice is physically analogous to magnetic
skyrmion crystals and hosts a hierarchy of collective excitations naturally
described within the framework of skyrmion-lattice dynamics.","Tixuan Tan, Patrick J. Ledwith, Trithep Devakul",arXiv,2025,2025-11-10 18:52:45+00:00,"cond-mat.mes-hall, cond-mat.str-el"
2511.07399v1,"StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video
  Generation","Generative models are reshaping the live-streaming industry by redefining how
content is created, styled, and delivered. Previous image-based streaming
diffusion models have powered efficient and creative live streaming products
but have hit limits on temporal consistency due to the foundation of
image-based designs. Recent advances in video diffusion have markedly improved
temporal consistency and sampling efficiency for offline generation. However,
offline generation systems primarily optimize throughput by batching large
workloads. In contrast, live online streaming operates under strict
service-level objectives (SLOs): time-to-first-frame must be minimal, and every
frame must meet a per-frame deadline with low jitter. Besides, scalable
multi-GPU serving for real-time streams remains largely unresolved so far. To
address this, we present StreamDiffusionV2, a training-free pipeline for
interactive live streaming with video diffusion models. StreamDiffusionV2
integrates an SLO-aware batching scheduler and a block scheduler, together with
a sink-token--guided rolling KV cache, a motion-aware noise controller, and
other system-level optimizations. Moreover, we introduce a scalable pipeline
orchestration that parallelizes the diffusion process across denoising steps
and network layers, achieving near-linear FPS scaling without violating latency
guarantees. The system scales seamlessly across heterogeneous GPU environments
and supports flexible denoising steps (e.g., 1--4), enabling both
ultra-low-latency and higher-quality modes. Without TensorRT or quantization,
StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS
with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four
H100 GPUs, making state-of-the-art generative live streaming practical and
accessible--from individual creators to enterprise-scale platforms.","Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li, Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt Keutzer, Akio Kodaira, Chenfeng Xu",arXiv,2025,2025-11-10 18:51:28+00:00,"cs.CV, cs.LG"
2511.07397v1,ConvFill: Model Collaboration for Responsive Conversational Voice Agents,"Deploying conversational voice agents with large language models faces a
critical challenge: cloud-based foundation models provide deep reasoning and
domain knowledge but introduce latency that disrupts natural conversation,
while on-device models respond immediately but lack sophistication. We propose
conversational infill, a task where a lightweight on-device model generates
contextually appropriate dialogue while seamlessly incorporating streaming
knowledge from a powerful backend model. This approach decouples response
latency from model capability, enabling systems that feel responsive while
accessing the full power of large-scale models. We present ConvFill, a 360M
parameter model trained on synthetic multi-domain conversations. Evaluation
across multiple backend models shows that conversational infill can be
successfully learned, with ConvFill achieving accuracy improvements of 36-42%
over standalone small models of the same size while consistently retaining
sub-200ms response latencies. Our results demonstrate the promise of this
approach for building on-device conversational agents that are both immediately
responsive and knowledgeable.","Vidya Srinivas, Zachary Englhardt, Maximus Powers, Shwetak Patel, Vikram Iyer",arXiv,2025,2025-11-10 18:50:30+00:00,cs.CL
2511.07396v1,"C3PO: Optimized Large Language Model Cascades with Probabilistic Cost
  Constraints for Reasoning","Large language models (LLMs) have achieved impressive results on complex
reasoning tasks, but their high inference cost remains a major barrier to
real-world deployment. A promising solution is to use cascaded inference, where
small, cheap models handle easy queries, and only the hardest examples are
escalated to more powerful models. However, existing cascade methods typically
rely on supervised training with labeled data, offer no theoretical
generalization guarantees, and provide limited control over test-time
computational cost. We introduce C3PO (Cost Controlled Cascaded Prediction
Optimization), a self-supervised framework for optimizing LLM cascades under
probabilistic cost constraints. By focusing on minimizing regret with respect
to the most powerful model (MPM), C3PO avoids the need for labeled data by
constructing a cascade using only unlabeled model outputs. It leverages
conformal prediction to bound the probability that inference cost exceeds a
user-specified budget. We provide theoretical guarantees on both cost control
and generalization error, and show that our optimization procedure is effective
even with small calibration sets. Empirically, C3PO achieves state-of-the-art
performance across a diverse set of reasoning benchmarks including GSM8K,
MATH-500, BigBench-Hard and AIME, outperforming strong LLM cascading baselines
in both accuracy and cost-efficiency. Our results demonstrate that principled,
label-free cascade optimization can enable scalable LLM deployment.","Antonios Valkanas, Soumyasundar Pal, Pavel Rumiantsev, Yingxue Zhang, Mark Coates",arXiv,2025,2025-11-10 18:50:27+00:00,cs.LG
2511.07395v1,The Landscape of Almost Equitable Allocations,"Equitability is a fundamental notion in fair division which requires that all
agents derive equal value from their allocated bundles. We study, for general
(possibly non-monotone) valuations, a popular relaxation of equitability known
as equitability up to one item (EQ1). An EQ1 allocation may fail to exist even
with additive non-monotone valuations; for instance, when there are two agents,
one valuing every item positively and the other negatively. This motivates a
mild and natural assumption: all agents agree on the sign of their value for
the grand bundle. Under this assumption, we prove the existence and provide an
efficient algorithm for computing EQ1 allocations for two agents with general
valuations. When there are more than two agents, we show the existence and
polynomial-time computability of EQ1 allocations for valuation classes beyond
additivity and monotonicity, in particular for (1) doubly monotone valuations
and (2) submodular (resp. supermodular) valuations where the value for the
grand bundle is nonnegative (resp. nonpositive) for all agents. Furthermore, we
settle an open question of Bil`o et al. by showing that an EQ1 allocation
always exists for nonnegative(resp. nonpositive) valuations, i.e., when every
agent values each subset of items nonnegatively (resp. nonpositively). Finally,
we complete the picture by showing that for general valuations with more than
two agents, EQ1 allocations may not exist even when agents agree on the sign of
the grand bundle, and that deciding the existence of an EQ1 allocation is
computationally intractable.","Hadi Hosseini, Vishwa Prakash HV, Aditi Sethia, Jatin Yadav",arXiv,2025,2025-11-10 18:50:07+00:00,"cs.GT, cs.DS"
2511.07393v1,"Surprisingly Similar: The Mass Function of Gaia Neutron Stars and
  First-Born Double Neutron Stars","The mass distribution of neutron stars encodes information about their
formation and binary evolution. We compare the masses of two distinct
populations: I) the recently identified Gaia neutron stars in wide orbits with
solar-like companions and, II) the assumed first-born recycled pulsar in
Galactic double neutron star systems. Naively, one would expect their masses to
differ due to both the presumed differences in their evolutionary histories, as
well as astrophysical selection effects that can filter out configurations that
would merge or be disrupted. Yet, we find that their mass distributions are
strikingly similar. Using a two-component Gaussian model, we find that both
populations exhibit a narrow component centred near $1.3 \text{ M}_\odot$,
accompanied by a broader, higher-mass component that extends the distribution
toward larger masses. The highest density regions of their fitted parameter
posteriors coincide by over 91.6%. Statistical tests further confirm the
agreement between these distributions with a Jensen-Shannon divergence $JS <
0.08$ and an earth mover's distance of $W <0.063 \text{ M}_\odot$ at 90%
credibility. This finding seems to imply that both mass functions reflect the
natal mass distribution of first-born neutron stars in binary systems,
supporting the hypothesis that neutron stars can be born with high masses.
Consequently and perhaps surprisingly, binary evolutionary processes need not
impart features on the NS mass distribution.","Aryanna Schiebelbein-Zwack, L. A. C van Son, Maya Fishbach, Will M. Farr",arXiv,2025,2025-11-10 18:48:03+00:00,astro-ph.SR
2511.07392v1,"Surgical Agent Orchestration Platform for Voice-directed Patient Data
  Interaction","In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in
the procedure, making it difficult to access and manipulate multimodal patient
data without interruption. We propose a voice-directed Surgical Agent
Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework,
consisting of an orchestration agent and three task-specific agents driven by
Large Language Models (LLMs). These LLM-based agents autonomously plan, refine,
validate, and reason to map voice commands into specific tasks such as
retrieving clinical information, manipulating CT scans, or navigating 3D
anatomical models on the surgical video. We also introduce a Multi-level
Orchestration Evaluation Metric (MOEM) to comprehensively assess the
performance and robustness from command-level and category-level perspectives.
The SAOP achieves high accuracy and success rates across 240 voice commands,
while LLM-based agents improve robustness against speech recognition errors and
diverse or ambiguous free-form commands, demonstrating strong potential to
support minimally invasive da Vinci robotic surgery.","Hyeryun Park, Byung Mo Gu, Jun Hee Lee, Byeong Hyeon Choi, Sekeun Kim, Hyun Koo Kim, Kyungsang Kim",arXiv,2025,2025-11-10 18:47:24+00:00,"cs.CL, cs.AI"
2511.07390v1,A Diffusion Model to Shrink Proteins While Maintaining Their Function,"Many proteins useful in modern medicine or bioengineering are challenging to
make in the lab, fuse with other proteins in cells, or deliver to tissues in
the body, because their sequences are too long. Shortening these sequences
typically involves costly, time-consuming experimental campaigns. Ideally, we
could instead use modern models of massive databases of sequences from nature
to learn how to propose shrunken proteins that resemble sequences found in
nature. Unfortunately, these models struggle to efficiently search the
combinatorial space of all deletions, and are not trained with inductive biases
to learn how to delete. To address this gap, we propose SCISOR, a novel
discrete diffusion model that deletes letters from sequences to generate
protein samples that resemble those found in nature. To do so, SCISOR trains a
de-noiser to reverse a forward noising process that adds random insertions to
natural sequences. As a generative model, SCISOR fits evolutionary sequence
data competitively with previous large models. In evaluation, SCISOR achieves
state-of-the-art predictions of the functional effects of deletions on
ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein
sequences, and show that its suggested deletions result in significantly more
realistic proteins and more often preserve functional motifs than previous
models of evolutionary sequences.","Ethan Baron, Alan N. Amin, Ruben Weitzman, Debora Marks, Andrew Gordon Wilson",arXiv,2025,2025-11-10 18:46:24+00:00,"cs.LG, q-bio.QM"
2511.07385v1,"samsara: A Continuous-Time Markov Chain Monte Carlo Sampler for
  Trans-Dimensional Bayesian Analysis","Bayesian inference requires determining the posterior distribution, a task
that becomes particularly challenging when the dimension of the parameter space
is large and unknown. This limitation arises in many physics problems, such as
Mixture Models (MM) with an unknown number of components or the inference of
overlapping signals in noisy data, as in the Laser Interferometer Space Antenna
(LISA) Global Fit problem. Traditional approaches, such as product-space
methods or Reversible-Jump Markov Chain Monte Carlo (RJMCMC), often face
efficiency and convergence limitations. This paper presents samsara, a
Continuous-Time Markov Chain Monte Carlo (CTMCMC) framework that models
parameter evolution through Poisson-driven birth, death, and mutation
processes. samsara is designed to sample models of unknown dimensionality. By
requiring detailed balance through adaptive rate definitions, CTMCMC achieves
automatic acceptance of trans-dimensional moves and high sampling efficiency.
The code features waiting time weighted estimators, optimized memory storage,
and a modular design for easy customization. We validate samsara on three
benchmark problems: an analytic trans-dimensional distribution, joint inference
of sine waves and Lorentzians in time series, and a Gaussian MM with an unknown
number of components. In all cases, the code shows excellent agreement with
analytical and Nested Sampling results. All these features push samsara as a
powerful alternative to RJMCMC for large- and variable-dimensional Bayesian
inference problems.","Gabriele Astorino, Lorenzo Valbusa Dall'Armi, Riccardo Buscicchio, Joachim Pomper, Angelo Ricciardone, Walter Del Pozzo",arXiv,2025,2025-11-10 18:44:14+00:00,"stat.CO, astro-ph.IM, gr-qc"
2511.07384v1,"Teaching Pretrained Language Models to Think Deeper with Retrofitted
  Recurrence","Recent advances in depth-recurrent language models show that recurrence can
decouple train-time compute and parameter count from test-time compute. In this
work, we study how to convert existing pretrained non-recurrent language models
into depth-recurrent models. We find that using a curriculum of recurrences to
increase the effective depth of the model over the course of training preserves
performance while reducing total computational cost. In our experiments, on
mathematics, we observe that converting pretrained models to recurrent ones
results in better performance at a given compute budget than simply
post-training the original non-recurrent language model.","Sean McLeish, Ang Li, John Kirchenbauer, Dayal Singh Kalra, Brian R. Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Jonas Geiping, Tom Goldstein, Micah Goldblum",arXiv,2025,2025-11-10 18:43:07+00:00,"cs.CL, cs.AI, cs.LG"
2511.07382v1,"Retriv at BLP-2025 Task 2: Test-Driven Feedback-Guided Framework for
  Bangla-to-Python Code Generation","Large Language Models (LLMs) have advanced the automated generation of code
from natural language prompts. However, low-resource languages (LRLs) like
Bangla remain underrepresented due to the limited availability of
instruction-to-code datasets and evaluation benchmarks. To address this, the
BLP Workshop at IJCNLP-AACL 2025 introduced a shared task on ""Code Generation
in Bangla"". In this work, we propose a method that combines instruction
prompting with a test-driven, feedback-guided iterative refinement process
using a fine-tuned Qwen2.5-14B model. The model generates code from Bangla
instructions, tests it against unit tests, and iteratively refines any failing
outputs through three evaluation passes, using test feedback to guide each
step. This approach helped our team ""Retriv"" to secure 2nd place in the shared
task with a Pass@1 score of 0.934. The analysis highlights challenges in Bangla
instruction understanding and Python code generation, emphasizing the need for
targeted methods in LRLs. We made experimental scripts publicly available for
the community.","K M Nafi Asib, Sourav Saha, Mohammed Moshiul Hoque",arXiv,2025,2025-11-10 18:41:44+00:00,cs.CL
2511.07380v1,"Selecting Auxiliary Data via Neural Tangent Kernels for Low-Resource
  Domains","Large language models (LLMs) have achieved remarkable success across
widespread tasks, yet their application in low-resource domains remains a
significant challenge due to data scarcity and the high risk of overfitting.
While in-domain data is limited, there exist vast amounts of similar
general-domain data, and our initial findings reveal that they could
potentially serve as auxiliary supervision for domain enhancement. This
observation leads us to our central research question: \textbf{\textit{how to
effectively select the most valuable auxiliary data to maximize domain-specific
performance}}, particularly when traditional methods are inapplicable due to a
lack of large in-domain data pools or validation sets. To address this, we
propose \textbf{NTK-Selector}, a principled and efficient framework for
selecting general-domain auxiliary data to enhance domain-specific performance
via neural tangent kernels (NTK). Our method tackles two challenges of directly
applying NTK to LLMs, theoretical assumptions and prohibitive computational
cost, by empirically demonstrating a stable NTK-like behavior in LLMs during
LoRA fine-tuning and proposing a Jacobian-free approximation method. Extensive
experiments across four low-resource domains (medical, financial, legal, and
psychological) demonstrate that NTK-Selector consistently improves downstream
performance. Specifically, fine-tuning on 1,000 in-domain samples alone only
yielded +0.8 points for Llama3-8B-Instruct and +0.9 points for Qwen3-8B. In
contrast, enriching with 9,000 auxiliary samples selected by NTK-Selector led
to substantial \textbf{gains of +8.7 and +5.1 points}, which corresponds to a
\textbf{10.9x and 5.7x improvement} over the domain-only setting.","Pingjie Wang, Hongcheng Liu, Yusheng Liao, Ziqing Fan, Yaxin Du, Shuo Tang, Yanfeng Wang, Yu Wang",arXiv,2025,2025-11-10 18:41:23+00:00,cs.CL
2511.07377v1,Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion,"LiDAR super-resolution addresses the challenge of achieving high-quality 3D
perception from cost-effective, low-resolution sensors. While recent
transformer-based approaches like TULIP show promise, they remain limited to
spatial-domain processing with restricted receptive fields. We introduce FLASH
(Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a
novel framework that overcomes these limitations through dual-domain
processing. FLASH integrates two key innovations: (i) Frequency-Aware Window
Attention that combines local spatial attention with global frequency-domain
analysis via FFT, capturing both fine-grained geometry and periodic scanning
patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that
replaces conventional skip connections with learned position-specific feature
aggregation, enhanced by CBAM attention for dynamic feature selection.
Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art
performance across all evaluation metrics, surpassing even uncertainty-enhanced
baselines that require multiple forward passes. Notably, FLASH outperforms
TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which
enables real-time deployment. The consistent superiority across all distance
ranges validates that our dual-domain approach effectively handles uncertainty
through architectural design rather than computationally expensive stochastic
inference, making it practical for autonomous systems.","June Moh Goo, Zichao Zeng, Jan Boehm",arXiv,2025,2025-11-10 18:38:15+00:00,"cs.CV, cs.AI, cs.RO"
2511.07376v1,"Enhanced GCD through ORBGRAND-AI: Exploiting Partial and Total
  Correlation in Noise","There have been significant advances in recent years in the development of
forward error correction decoders that can decode codes of any structure,
including practical realizations in synthesized circuits and taped out chips.
While essentially all soft-decision decoders assume that bits have been
impacted independently on the channel, for one of these new approaches it has
been established that channel dependencies can be exploited to achieve superior
decoding accuracy, resulting in Ordered Reliability Bits Guessing Random
Additive Noise Decoding Approximate Independence (ORBGRAND-AI). Building on
that capability, here we consider the integration of ORBGRAND-AI as a pattern
generator for Guessing Codeword Decoding (GCD). We first establish that a
direct approach delivers mildly degraded block error rate (BLER) but with
reduced number of queried patterns when compared to ORBGRAND-AI. We then show
that with a more nuanced approach it is possible to leverage total correlation
to deliver an additional BLER improvement of around 0.75 dB while retaining
reduced query numbers.","Jiewei Feng, Ken R. Duffy, Muriel Médard",arXiv,2025,2025-11-10 18:34:23+00:00,eess.SP
2511.07368v1,"Consistency Is Not Always Correct: Towards Understanding the Role of
  Exploration in Post-Training Reasoning","Foundation models exhibit broad knowledge but limited task-specific
reasoning, motivating post-training strategies such as RLVR and inference
scaling with outcome or process reward models (ORM/PRM). While recent work
highlights the role of exploration and entropy stability in improving pass@K,
empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce
existing tree-like reasoning paths rather than expanding the reasoning scope,
raising the question of why exploration helps at all if no new patterns emerge.
  To reconcile this paradox, we adopt the perspective of Kim et al. (2025),
viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a
symmetry) reasoning steps as low- versus high-probability Markov transitions,
and formalize post-training dynamics through Multi-task Tree-structured Markov
Chains (TMC). In this tractable model, pretraining corresponds to tree
expansion, while post-training corresponds to chain-of-thought reweighting. We
show that several phenomena recently observed in empirical studies arise
naturally in this setting: (1) RLVR induces a squeezing effect, reducing
reasoning entropy and forgetting some correct paths; (2) population rewards of
ORM/PRM encourage consistency rather than accuracy, thereby favoring common
patterns; and (3) certain rare, high-uncertainty reasoning paths by the base
model are responsible for solving hard problem instances.
  Together, these explain why exploration -- even when confined to the base
model's reasoning scope -- remains essential: it preserves access to rare but
crucial reasoning traces needed for difficult cases, which are squeezed out by
RLVR or unfavored by inference scaling. Building on this, we further show that
exploration strategies such as rejecting easy instances and KL regularization
help preserve rare reasoning traces. Empirical simulations corroborate our
theoretical results.","Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang, Hau-San Wong, Taiji Suzuki",arXiv,2025,2025-11-10 18:25:26+00:00,"cs.LG, cs.AI"
2511.07364v1,"Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence
  Estimation for Failure Detection","Reliability and failure detection of large language models (LLMs) is critical
for their deployment in high-stakes, multi-step reasoning tasks. Prior work
explores confidence estimation for self-evaluating LLM-scorer systems, with
confidence scorers estimating the likelihood of errors in LLM responses.
However, most methods focus on single-step outputs and overlook the challenges
of multi-step reasoning. In this work, we extend self-evaluation techniques to
multi-step tasks, testing two intuitive approaches: holistic scoring and
step-by-step scoring. Using two multi-step benchmark datasets, we show that
stepwise evaluation generally outperforms holistic scoring in detecting
potential errors, with up to 15% relative increase in AUC-ROC. Our findings
demonstrate that self-evaluating LLM systems provide meaningful confidence
estimates in complex reasoning, improving their trustworthiness and providing a
practical framework for failure detection.","Vaibhav Mavi, Shubh Jaroria, Weiqi Sun",arXiv,2025,2025-11-10 18:19:51+00:00,"cs.LG, cs.AI, cs.CL"
2511.07362v1,Inference-Time Scaling of Diffusion Models for Infrared Data Generation,"Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.","Kai A. Horstmann, Maxim Clouser, Kia Khezeli",arXiv,2025,2025-11-10 18:18:38+00:00,"cs.CV, cs.AI, cs.LG"
2511.07361v1,Locality Testing for NFAs is PSPACE-complete,"The class of local languages is a well-known subclass of the regular
languages that admits many equivalent characterizations. In this short note we
establish the PSPACE-completeness of the problem of determining, given as input
a nondeterministic finite automaton (NFA) A, whether the language recognized by
A is local or not. This contrasts with the case of deterministic finite
automata (DFA), for which the problem is known to be in PTIME.","Antoine Amarilli, Mikaël Monet, Rémi De Pretto",arXiv,2025,2025-11-10 18:16:58+00:00,cs.FL
2511.07350v1,Decoupling of clusters in independent sets in a percolated hypercube,"Independent sets in graphs are sets of vertices containing no neighbors, and
they represent a canonical spin system with hardcore constraints. Of particular
interest is the setting of the boolean hypercube, where counting independent
sets was the original motivator for Sapozhenko's famous graph container method.
A modern perspective on such problems is to consider the effect of disorder,
and the study of independent sets in random subgraphs of the hypercube obtained
via bond percolation with parameter $p$ was initiated by Kronenberg and Spinka.
They employed tools from statistical mechanics to obtain detailed information
about the moments of the number of independent sets (now a random variable),
and posed many interesting questions. Previous work by the authors addressed
many of these questions in the regime $p \geq \frac{2}{3}$, where the behavior
is relatively simple and can be modeled well by a related family of independent
particles.
  As $p$ decreases, though, typical independent sets become larger and feature
more intricate clustering behavior. In the present article we overcome many of
the challenges presented by this phenomenon and analyze the model for all $p>
0.465$. We obtain a sharp in-probability approximation for the number of
independent sets in the percolated hypercube in terms of explicit random
variables, as well as provide a sampling algorithm. Note that this shows,
curiously, that $p = \frac{1}{2}$ is not a natural barrier for this problem
unlike in many other problems where it appears as a point of a phase
transition. A key contribution of this work is the introduction of a new
probabilistic framework to handle the clustering behavior for these low values
of $p$. Although our analysis is restricted to $p > 0.465$, our arguments are
expected to be helpful for studying this model at even lower values of $p$, and
possibly for other related problems.","Mriganka Basu Roy Chowdhury, Shirshendu Ganguly, Vilas Winstein",arXiv,2025,2025-11-10 17:53:58+00:00,"math.PR, cond-mat.stat-mech, cs.DM, math-ph, math.CO, math.MP"
2511.07348v1,Classical gravity cannot mediate entanglement,"In Nature, 646, 813 (2025), Aziz and Howl claim that classical (unquantised)
gravity produces entanglement. We show that their model does not produce
entanglement. Even if the model produced entanglement, it would be mediated by
the quantised matter interaction, and not gravity. Hence entanglement mediated
by gravity remains an unambiguous witness of gravity's quantum features.","Chiara Marletto, Jonathan Oppenheim, Vlatko Vedral, Elizabeth Wilson",arXiv,2025,2025-11-10 17:51:36+00:00,"quant-ph, gr-qc"
2511.07347v1,"Walsh-Hadamard Neural Operators for Solving PDEs with Discontinuous
  Coefficients","Neural operators have emerged as powerful tools for learning solution
operators of partial differential equations (PDEs). However, standard spectral
methods based on Fourier transforms struggle with problems involving
discontinuous coefficients due to the Gibbs phenomenon and poor representation
of sharp interfaces. We introduce the Walsh-Hadamard Neural Operator (WHNO),
which leverages Walsh-Hadamard transforms-a spectral basis of rectangular wave
functions naturally suited for piecewise constant fields-combined with
learnable spectral weights that transform low-sequency Walsh coefficients to
capture global dependencies efficiently. We validate WHNO on three problems:
steady-state Darcy flow (preliminary validation), heat conduction with
discontinuous thermal conductivity, and the 2D Burgers equation with
discontinuous initial conditions. In controlled comparisons with Fourier Neural
Operators (FNO) under identical conditions, WHNO demonstrates superior accuracy
with better preservation of sharp solution features at material interfaces.
Critically, we discover that weighted ensemble combinations of WHNO and FNO
achieve substantial improvements over either model alone: for both heat
conduction and Burgers equation, optimal ensembles reduce mean squared error by
35-40 percent and maximum error by up to 25 percent compared to individual
models. This demonstrates that Walsh-Hadamard and Fourier representations
capture complementary aspects of discontinuous PDE solutions, with WHNO
excelling at sharp interfaces while FNO captures smooth features effectively.","Giorrgio M. Cavallazzi, Miguel Perex Cuadrado, Alfredo Pinelli",arXiv,2025,2025-11-10 17:49:20+00:00,"physics.comp-ph, cs.LG"
2511.07346v1,"On Subexponential Parameterized Algorithms for Steiner Tree on
  Intersection Graphs of Geometric Objects","We study the Steiner Tree problem on the intersection graph of most natural
families of geometric objects, e.g., disks, squares, polygons, etc. Given a set
of $n$ objects in the plane and a subset $T$ of $t$ terminal objects, the task
is to find a subset $S$ of $k$ objects such that the intersection graph of
$S\cup T$ is connected. Given how typical parameterized problems behave on
planar graphs and geometric intersection graphs, we would expect that exact
algorithms with some form of subexponential dependence on the solution size or
the number of terminals exist. Contrary to this expectation, we show that,
assuming the Exponential-Time Hypothesis (ETH), there is no $2^{o(k+t)}\cdot
n^{O(1)}$ time algorithm even for unit disks or unit squares, that is, there is
no FPT algorithm subexponential in the size of the Steiner tree. However,
subexponential dependence can appear in a different form: we show that Steiner
Tree can be solved in time $n^{O(\sqrt{t})}$ for many natural classes of
objects, including: Disks of arbitrary size. Axis-parallel squares of arbitrary
size. Similarly-sized fat polygons.
  This in particular significantly improves and generalizes two recent results:
(1) Steiner Tree on unit disks can be solved in time $n^{\Oh(\sqrt{k + t})}$
(Bhore, Carmi, Kolay, and Zehavi, Algorithmica 2023) and (2) Steiner Tree on
planar graphs can be solved in time $n^{O(\sqrt{t})}$ (Marx, Pilipczuk, and
Pilipczuk, FOCS 2018). We complement our algorithms with lower bounds that
demonstrate that the class of objects cannot be significantly extended, even if
we allow the running time to be $n^{o(k+t)/\log(k+t)}$.","Sujoy Bhore, Baris Can Esmer, Daniel Marx, Karol Wegrzycki",arXiv,2025,2025-11-10 17:49:14+00:00,"cs.CG, cs.DS"
2511.07343v1,TNT: Improving Chunkwise Training for Test-Time Memorization,"Recurrent neural networks (RNNs) with deep test-time memorization modules,
such as Titans and TTT, represent a promising, linearly-scaling paradigm
distinct from Transformers. While these expressive models do not yet match the
peak performance of state-of-the-art Transformers, their potential has been
largely untapped due to prohibitively slow training and low hardware
utilization. Existing parallelization methods force a fundamental conflict
governed by the chunksize hyperparameter: large chunks boost speed but degrade
performance, necessitating a fixed, suboptimal compromise. To solve this
challenge, we introduce TNT, a novel training paradigm that decouples training
efficiency from inference performance through a two-stage process. Stage one is
an efficiency-focused pre-training phase utilizing a hierarchical memory. A
global module processes large, hardware-friendly chunks for long-range context,
while multiple parallel local modules handle fine-grained details. Crucially,
by periodically resetting local memory states, we break sequential dependencies
to enable massive context parallelization. Stage two is a brief fine-tuning
phase where only the local memory modules are adapted to a smaller,
high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated
on Titans and TTT models, TNT achieves a substantial acceleration in training
speed-up to 17 times faster than the most accurate baseline configuration -
while simultaneously improving model accuracy. This improvement removes a
critical scalability barrier, establishing a practical foundation for
developing expressive RNNs and facilitating future work to close the
performance gap with Transformers.","Zeman Li, Ali Behrouz, Yuan Deng, Peilin Zhong, Praneeth Kacham, Mahdi Karami, Meisam Razaviyayn, Vahab Mirrokni",arXiv,2025,2025-11-10 17:45:09+00:00,"cs.LG, cs.AI"
2511.07340v1,"Smoothing Out Sticking Points: Sampling from Discrete-Continuous
  Mixtures with Dynamical Monte Carlo by Mapping Discrete Mass into a Latent
  Universe","Combining a continuous ""slab"" density with discrete ""spike"" mass at zero,
spike-and-slab priors provide important tools for inducing sparsity and
carrying out variable selection in Bayesian models. However, the presence of
discrete mass makes posterior inference challenging. ""Sticky"" extensions to
piecewise-deterministic Markov process samplers have shown promising
performance, where sampling from the spike is achieved by the process sticking
there for an exponentially distributed duration. As it turns out, the sampler
remains valid when the exponential sticking time is replaced with its
expectation. We justify this by mapping the spike to a continuous density over
a latent universe, allowing the sampler to be reinterpreted as traversing this
universe while being stuck in the original space. This perspective opens up an
array of possibilities to carry out posterior computation under spike-and-slab
type priors. Notably, it enables us to construct sticky samplers using other
dynamics-based paradigms such as Hamiltonian Monte Carlo, and, in fact,
original sticky process can be established as a partial position-momentum
refreshment limit of our Hamiltonian sticky sampler. Further, our theoretical
and empirical findings suggest these alternatives to be at least as efficient
as the original sticky approach.","Andrew Chin, Akihiko Nishimura",arXiv,2025,2025-11-10 17:40:12+00:00,"stat.CO, stat.ME"
2511.07338v1,DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas,"Simulating human profiles by instilling personas into large language models
(LLMs) is rapidly transforming research in agentic behavioral simulation, LLM
personalization, and human-AI alignment. However, most existing synthetic
personas remain shallow and simplistic, capturing minimal attributes and
failing to reflect the rich complexity and diversity of real human identities.
We introduce DEEPPERSONA, a scalable generative engine for synthesizing
narrative-complete synthetic personas through a two-stage, taxonomy-guided
method. First, we algorithmically construct the largest-ever human-attribute
taxonomy, comprising over hundreds of hierarchically organized attributes, by
mining thousands of real user-ChatGPT conversations. Second, we progressively
sample attributes from this taxonomy, conditionally generating coherent and
realistic personas that average hundreds of structured attributes and roughly 1
MB of narrative text, two orders of magnitude deeper than prior works.
Intrinsic evaluations confirm significant improvements in attribute diversity
(32 percent higher coverage) and profile uniqueness (44 percent greater)
compared to state-of-the-art baselines. Extrinsically, our personas enhance
GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on
average across ten metrics and substantially narrow (by 31.7 percent) the gap
between simulated LLM citizens and authentic human responses in social surveys.
Our generated national citizens reduced the performance gap on the Big Five
personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA
thus provides a rigorous, scalable, and privacy-free platform for high-fidelity
human simulation and personalized AI research.","Zhen Wang, Yufan Zhou, Zhongyan Luo, Lyumanshan Ye, Adam Wood, Man Yao, Luoshang Pan",arXiv,2025,2025-11-10 17:37:56+00:00,"cs.AI, cs.LG, 68T07, 68T20, I.2.7; I.2.6; I.2.11"
2511.07336v1,"AcousTools: A `Full-Stack', Python-Based, Acoustic Holography Library","Acoustic Holography is an emerging field where mid-air ultrasound is
controlled and manipulated for novel and exciting applications. These range
from mid-air haptics, volumetric displays, contactless fabrication, and even
chemical and biomedical applications such as drug delivery. To develop these
applications, a software framework to predict acoustic behaviour and simulating
resulting effects, such as applied forces or scattering patterns is desirable.
There have been various software libraries and platforms that attempt to fill
this role, but there is yet to be a single piece of software that acts as a
'full-stack' solution. We define this full-stack as the process from
abstraction to physicalisation starting with setup, modelling acoustic
propagation, transducer phase retrieval, sound field analysis, and control of
the acoustic holographic hardware itself. Existing methods fail to fulfil one
or more of these categories. To address this, we present AcousTools, a
Python-based acoustic holography library, designed to support the full suite of
acoustic holographic applications and we show AcousTools's ability to meet each
step of the full-stack's requirements. AcousTools has the potential to become
the standard code library for acoustic holography, with the uniquely complete
suite of features wrapped in a language that is known to be easy to use,
AcousTools will increase the ability for researchers to develop novel
applications as well as accurately review other's work. The full-stack, aside
from software, will also be useful for researchers - providing a way to view
and compare methodologies by understanding where they fit into the stack.","Joshua Mukherjee, Giorgos Christopoulos, Zhouyang Shen, Sriram Subramanian, Ryuji Hirayama",arXiv,2025,2025-11-10 17:36:33+00:00,"cs.SD, cs.ET"
2511.07332v1,Grounding Computer Use Agents on Human Demonstrations,"Building reliable computer-use agents requires grounding: accurately
connecting natural language instructions to the correct on-screen elements.
While large datasets exist for web and mobile interactions, high-quality
resources for desktop environments are limited. To address this gap, we
introduce GroundCUA, a large-scale desktop grounding dataset built from expert
human demonstrations. It covers 87 applications across 12 categories and
includes 56K screenshots, with every on-screen element carefully annotated for
a total of over 3.56M human-verified annotations. From these demonstrations, we
generate diverse instructions that capture a wide range of real-world tasks,
providing high-quality data for model training. Using GroundCUA, we develop the
GroundNext family of models that map instructions to their target UI elements.
At both 3B and 7B scales, GroundNext achieves state-of-the-art results across
five benchmarks using supervised fine-tuning, while requiring less than
one-tenth the training data of prior work. Reinforcement learning post-training
further improves performance, and when evaluated in an agentic setting on the
OSWorld benchmark using o3 as planner, GroundNext attains comparable or
superior results to models trained with substantially more data,. These results
demonstrate the critical role of high-quality, expert-driven datasets in
advancing general-purpose computer-use agents.","Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar",arXiv,2025,2025-11-10 17:35:21+00:00,"cs.LG, cs.AI"
2511.07330v1,"Roundabout Constrained Convex Generators: A Unified Framework for
  Multiply-Connected Reachable Sets","This paper introduces Roundabout Constrained Convex Generators (RCGs), a set
representation framework for modeling multiply connected regions in control and
verification applications. The RCG representation extends the constrained
convex generators framework by incorporating an inner exclusion zone, creating
sets with topological holes that naturally arise in collision avoidance and
safety-critical control problems. We present two equivalent formulations: a set
difference representation that provides geometric intuition and a unified
parametric representation that facilitates computational implementation. The
paper establishes closure properties under fundamental operations, including
linear transformations, Minkowski sums, and intersections with convex generator
sets. We derive special cases, including roundabout zonotopes and roundabout
ellipsotopes, which offer computational advantages for specific norm
selections. The framework maintains compatibility with existing optimization
solvers while enabling the representation of non-convex feasible regions that
were previously challenging to model efficiently.","Peng Xie, Sabin Diaconescu, Florin Stoican, Amr Alanwar",arXiv,2025,2025-11-10 17:32:24+00:00,"math.OC, cs.SY, eess.SY"
2511.07329v1,"Preparation of Fractal-Inspired Computational Architectures for Advanced
  Large Language Model Analysis","It introduces FractalNet, a fractal-inspired computational architectures for
advanced large language model analysis that mainly challenges model diversity
on a large scale in an efficient manner. The new set-up involves a
template-driven generator, runner, and evaluation framework that, through
systematic permutations of convolutional, normalization, activation, and
dropout layers, can create more than 1,200 variants of neural networks. Fractal
templates allow for structural recursion and multi-column pathways, thus,
models become deeper and wider in a balanced way. Training utilizes PyTorch,
Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out
on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based
architectures are capable of strong performance and are computationally
efficient. The paper positions fractal design as a feasible and
resource-efficient method of automated architecture exploration.","Yash Mittal, Dmitry Ignatov, Radu Timofte",arXiv,2025,2025-11-10 17:31:39+00:00,"cs.LG, cs.CV"
2511.07327v1,"IterResearch: Rethinking Long-Horizon Agents via Markovian State
  Reconstruction","Recent advances in deep-research agents have shown promise for autonomous
knowledge construction through dynamic reasoning over external sources.
However, existing approaches rely on a mono-contextual paradigm that
accumulates all information in a single, expanding context window, leading to
context suffocation and noise contamination that limit their effectiveness on
long-horizon tasks. We introduce IterResearch, a novel iterative deep-research
paradigm that reformulates long-horizon research as a Markov Decision Process
with strategic workspace reconstruction. By maintaining an evolving report as
memory and periodically synthesizing insights, our approach preserves
consistent reasoning capacity across arbitrary exploration depths. We further
develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning
framework that incentivizes efficient exploration through geometric reward
discounting and enables stable distributed training via adaptive downsampling.
Extensive experiments demonstrate that IterResearch achieves substantial
improvements over existing open-source agents with average +14.5pp across six
benchmarks and narrows the gap with frontier proprietary systems. Remarkably,
our paradigm exhibits unprecedented interaction scaling, extending to 2048
interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves
as an effective prompting strategy, improving frontier models by up to 19.2pp
over ReAct on long-horizon tasks. These findings position IterResearch as a
versatile solution for long-horizon reasoning, effective both as a trained
agent and as a prompting paradigm for frontier models.","Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",arXiv,2025,2025-11-10 17:30:08+00:00,"cs.AI, cs.CL"
2511.07322v1,"FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework
  for Equity Research Report Generation","While LLMs have shown great success in financial tasks like stock prediction
and question answering, their application in fully automating Equity Research
Report generation remains uncharted territory. In this paper, we formulate the
Equity Research Report (ERR) Generation task for the first time. To address the
data scarcity and the evaluation metrics absence, we present an open-source
evaluation benchmark for ERR generation - FinRpt. We frame a Dataset
Construction Pipeline that integrates 7 financial data types and produces a
high-quality ERR dataset automatically, which could be used for model training
and evaluation. We also introduce a comprehensive evaluation system including
11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent
framework specifically tailored to address this task, named FinRpt-Gen, and
train several LLM-based agents on the proposed datasets using Supervised
Fine-Tuning and Reinforcement Learning. Experimental results indicate the data
quality and metrics effectiveness of the benchmark FinRpt and the strong
performance of FinRpt-Gen, showcasing their potential to drive innovation in
the ERR generation field. All code and datasets are publicly available.","Song Jin, Shuqi Li, Shukun Zhang, Rui Yan",arXiv,2025,2025-11-10 17:22:32+00:00,"cs.CL, cs.AI"
2511.07319v1,Phases and properties of color superconductors,"Cold and dense matter is expected to be in a color-superconducting state.
Here we review two calculations, relevant for fundamental properties and
applications of color superconductivity, respectively: the weak-coupling QCD
calculation of the fermionic energy gap together with the magnetic screening
masses of the gauge bosons, and the calculation of bulk viscosity from a
non-leptonic electroweak process. These calculations are supplemented by a
discussion of color superconductors with mismatched Fermi momenta, and they are
embedded in the context of the state of the art by giving an overview of
previous and ongoing work and future directions.",Andreas Schmitt,arXiv,2025,2025-11-10 17:20:38+00:00,"hep-ph, cond-mat.supr-con, nucl-th"
2511.07318v1,"When Bias Pretends to Be Truth: How Spurious Correlations Undermine
  Hallucination Detection in LLMs","Despite substantial advances, large language models (LLMs) continue to
exhibit hallucinations, generating plausible yet incorrect responses. In this
paper, we highlight a critical yet previously underexplored class of
hallucinations driven by spurious correlations -- superficial but statistically
prominent associations between features (e.g., surnames) and attributes (e.g.,
nationality) present in the training data. We demonstrate that these spurious
correlations induce hallucinations that are confidently generated, immune to
model scaling, evade current detection methods, and persist even after refusal
fine-tuning. Through systematically controlled synthetic experiments and
empirical evaluations on state-of-the-art open-source and proprietary LLMs
(including GPT-5), we show that existing hallucination detection methods, such
as confidence-based filtering and inner-state probing, fundamentally fail in
the presence of spurious correlations. Our theoretical analysis further
elucidates why these statistical biases intrinsically undermine
confidence-based detection techniques. Our findings thus emphasize the urgent
need for new approaches explicitly designed to address hallucinations caused by
spurious correlations.","Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun, Kaifeng Lyu, Jian Li",arXiv,2025,2025-11-10 17:19:27+00:00,"cs.CL, cs.AI, cs.LG"
2511.07317v1,"RLVE: Scaling Up Reinforcement Learning for Language Models with
  Adaptive Verifiable Environments","We introduce Reinforcement Learning (RL) with Adaptive Verifiable
Environments (RLVE), an approach using verifiable environments that
procedurally generate problems and provide algorithmically verifiable rewards,
to scale up RL for language models (LMs). RLVE enables each verifiable
environment to dynamically adapt its problem difficulty distribution to the
policy model's capabilities as training progresses. In contrast, static data
distributions often lead to vanishing learning signals when problems are either
too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a
large-scale suite of 400 verifiable environments carefully developed through
manual environment engineering. Using RLVE-Gym, we show that environment
scaling, i.e., expanding the collection of training environments, consistently
improves generalizable reasoning capabilities. RLVE with joint training across
all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement
across six reasoning benchmarks, starting from one of the strongest 1.5B
reasoning LMs. By comparison, continuing this LM's original RL training yields
only a 0.49% average absolute gain despite using over 3x more compute. We
release our code publicly.","Zhiyuan Zeng, Hamish Ivison, Yiping Wang, Lifan Yuan, Shuyue Stella Li, Zhuorui Ye, Siting Li, Jacqueline He, Runlong Zhou, Tong Chen, Chenyang Zhao, Yulia Tsvetkov, Simon Shaolei Du, Natasha Jaques, Hao Peng, Pang Wei Koh, Hannaneh Hajishirzi",arXiv,2025,2025-11-10 17:18:35+00:00,"cs.CL, cs.LG"
2511.07314v1,The free bifibration on a functor,"We consider the problem of constructing the free bifibration generated by a
functor of categories $p : D \to C$. This problem was previously considered by
Lamarche, and is closely related to the problem, considered by Dawson, Par\'e,
and Pronk, of ""freely adjoining adjoints"" to a category. We develop a
proof-theoretic approach to the problem, beginning with a construction of the
free bifibration $\Lambda_p : \mathcal{B}\mathrm{if}(p)\to C$ in which objects
of $\mathcal{B}\mathrm{if}(p)$ are formulas of a primitive ""bifibrational
logic"", and arrows are derivations in a cut-free sequent calculus modulo a
notion of permutation equivalence. We show that instantiating the construction
to the identity functor generates a _zigzag double category_ $\mathbb{Z}(C)$,
which is also the free double category with companions and conjoints (or
fibrant double category) on $C$. The approach adapts smoothly to the more
general task of building $(P,N)$-fibrations, where one only asks for
pushforwards along arrows in $P$ and pullbacks along arrows in $N$ for some
subsets of arrows, which encompasses Kock and Joyal's notion of _ambifibration_
when $(P,N)$ form a factorization system. We establish a series of
progressively stronger normal forms, guided by ideas of _focusing_ from proof
theory, and obtain a canonicity result under assumption that the base category
is factorization preordered relative to $P$ and $N$. This canonicity result
allows us to decide the word problem and to enumerate relative homsets without
duplicates. Finally, we describe several examples of a combinatorial nature,
including a category of plane trees generated as a free bifibration over
$\omega$, and a category of increasing forests generated as a free
ambifibration over $\Delta$, which contains the lattices of noncrossing
partitions as quotients of its fibers by the Beck-Chevalley condition.","Bryce Clarke, Gabriel Scherer, Noam Zeilberger",arXiv,2025,2025-11-10 17:16:20+00:00,"math.CT, cs.LO, 18N10, 18D30, 03B47, 03F05"
2511.07311v1,ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding,"Automatic ICD coding, the task of assigning disease and procedure codes to
electronic medical records, is crucial for clinical documentation and billing.
While existing methods primarily enhance model understanding of code
hierarchies and synonyms, they often overlook the pervasive use of medical
acronyms in clinical notes, a key factor in ICD code inference. To address this
gap, we propose a novel effective data augmentation technique that leverages
large language models to expand medical acronyms, allowing models to be trained
on their full form representations. Moreover, we incorporate consistency
training to regularize predictions by enforcing agreement between the original
and augmented documents. Extensive experiments on the MIMIC-III dataset
demonstrate that our approach, ACE-ICD establishes new state-of-the-art
performance across multiple settings, including common codes, rare codes, and
full-code assignments. Our code is publicly available.","Tuan-Dung Le, Shohreh Haddadan, Thanh Q. Thieu",arXiv,2025,2025-11-10 17:11:20+00:00,cs.CL
2511.07310v1,"Low-Complexity ADMM-Based Multicast Beamforming in Cell-Free Massive
  MIMO Systems","The growing demand for efficient delivery of common content to multiple user
equipments (UEs) has motivated significant research in physical-layer
multicasting. By exploiting the beamforming capabilities of massive MIMO,
multicasting provides a spectrum-efficient solution that avoids unnecessary
intra-group interference. A key challenge, however, is solving the max-min fair
(MMF) and quality-of-service (QoS) multicast beamforming optimization problems,
which are NP-hard due to the non-convex structure and the requirement for
rank-1 solutions. Traditional approaches based on semidefinite relaxation (SDR)
followed by randomization exhibit poor scalability with system size, while
state-of-the-art successive convex approximation (SCA) methods only guarantee
convergence to stationary points. In this paper, we propose an alternating
direction method of multipliers (ADMM)-based framework for MMF and QoS
multicast beamforming in cell-free massive MIMO networks. The algorithm
leverages SDR but incorporates a novel iterative elimination strategy within
the ADMM updates to efficiently obtain near-global optimal rank-1 beamforming
solutions with reduced computational complexity compared to standard SDP
solvers and randomization methods. Numerical evaluations demonstrate that the
proposed ADMM-based procedure not only achieves superior spectral efficiency
but also scales favorably with the number of antennas and UEs compared to
state-of-the-art SCA-based algorithms, making it a practical tool for
next-generation multicast systems.","Mahmoud Zaher, Emil Björnson",arXiv,2025,2025-11-10 17:11:09+00:00,eess.SP
2511.07309v1,"Frequency Diverse (FD)-RIS-Enhanced Covert Communications: Defense
  Against Wiretapping via Joint Distance-Angle Beamforming","In response to the security blind zone challenges faced by traditional
reconfigurable intelligent surface (RIS)-aided covert communication (CC)
systems, the joint distance-angle beamforming capability of frequency diverse
RIS (FD-RIS) shows significant potential for addressing these limitations.
Therefore, this paper initially incorporates the FD-RIS into the CC systems and
proposes the corresponding CC transmission scheme. Specifically, we first
develop the signal processing model of the FD-RIS, which considers effective
control of harmonic signals by leveraging the time-delay techniques. The joint
distance-angle beamforming capability is then validated through its normalized
beampattern. Based on this model, we then construct an FD-RIS-assisted CC
system under a multi-warden scenario and derive an approximate closed-form
expression for the covert constraints by considering the worst-case
eavesdropping conditions and utilizing the logarithmic moment-generating
function. An optimization problem is formulated which aims at maximizing the
covert user's achievable rate under covert constrains by jointly designing the
time delays and modulation frequencies. To tackle this non-convex problem, an
iterative algorithm with assured convergence is proposed to effectively solve
the time-delay and modulation frequency variables. To evaluate the performance
of the proposed scheme, we consider three communication scenarios with varying
spatial correlations between the covert user and wardens. Simulation results
demonstrate that FD-RIS can significantly improve covert performance,
particularly in angular-overlap scenarios where traditional RIS experiences
severe degradation. These findings further highlight the effectiveness of
FD-RIS in enhancing CC robustness under challenging spatial environments.","Han Xiao, Xiaoyan Hu, Wenjie Wang, Kai-Kit Wong, Kun Yang, Chan-Byoung Chae",arXiv,2025,2025-11-10 17:10:06+00:00,"cs.IT, math.IT"
2511.07307v1,"Singling out people without knowing their names - Behavioural targeting,
  pseudonymous data, and the New Data Protection Regulation","Information about millions of people is collected for behavioural targeting,
a type of marketing that involves tracking people's online behaviour for
targeted advertising. It is hotly debated whether data protection law applies
to behavioural targeting. Many behavioural targeting companies say that, as
long as they do not tie names to data they hold about individuals, they do not
process any personal data, and that, therefore, data protection law does not
apply to them. European Data Protection Authorities, however, take the view
that a company processes personal data if it uses data to single out a person,
even if it cannot tie a name to these data. This paper argues that data
protection law should indeed apply to behavioural targeting. Companies can
often tie a name to nameless data about individuals. Furthermore, behavioural
targeting relies on collecting information about individuals, singling out
individuals, and targeting ads to individuals. Many privacy risks remain,
regardless of whether companies tie a name to the information they hold about a
person. A name is merely one of the identifiers that can be tied to data about
a person, and it is not even the most practical identifier for behavioural
targeting. Seeing data used to single out a person as personal data fits the
rationale for data protection law: protecting fairness and privacy.",Frederik J. Zuiderveen Borgesius,arXiv,2025,2025-11-10 17:09:31+00:00,cs.CY
