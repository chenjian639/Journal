数据仓库字段
wos_id
volume
title
target
refs
publish_date
pid
pages
journal
issue
doi
country
conference
citations
author
abstract
# 颠覆性 
==================================================
      增强型期刊颠覆性评分方法（EJDS）
 Enhanced Journal Disruption Score
           方法说明文档 v2.0
==================================================

📌 背景与问题：
传统的期刊评价常采用“所有论文 D-index 的平均值”作为指标。这种方法容易被大量普通论文稀释真实影响力，也无法反映期刊是否具备产生重大突破的能力。

更重要的是：  
不能简单认为“发得越多，贡献越大”。  
真正领先的期刊，应是在有限或合理规模下持续产出高影响力工作的“质量引擎”。
 因此，提出本增强型方法，旨在更公平地评估期刊的“颠覆性潜力”，避免大规模期刊仅因样本量大而占据榜单前列。

---

🌟 方法名称：增强型期刊颠覆性评分（EJDS）  
英文全称：Enhanced Journal Disruption Score

🔧 核心思想：
- 不依赖全体论文的平均表现；
- 聚焦每个期刊中最具影响力的前10篇论文（Top-10 D-index）；
- 在综合打分时，对发文总量进行合理性调节 ——  
  即：**同样头部质量下，发文越多，其“含金量密度”越受审慎对待**。

💡 设计理念：
我们相信，科学进步的关键驱动力不是“量产”，而是“突破”。  
因此，一个只发表少量论文但屡出高峰的期刊，理应获得比“海量平庸+个别亮点”的大刊更高的认可度。

为此，本方法引入了对规模效应的非线性调节机制，使得：
> “仅仅靠数量堆出几个高分论文” → 得分增长缓慢甚至受限  
> “以精取胜、持续引领” → 得分更具竞争力

---
 计算流程（技术实现简述）：

1. 获取每篇论文的 D-index（基于引文网络计算）；
2. 按期刊分组，提取其前10篇最高 D-index 论文，计算均值（top_k_mean）；
3. 引入对数缩放后的发文总量 log(1+N) 作为调节因子；
4. 综合得分公式如下：
   
   score = (1 − w) × top_k_mean + w × (top_k_mean / log(1+N))

   其中：
   - w = volume_weight，推荐设为 0.4
   - 分母形式确保：N 越大，第二项贡献越小 → 实现“规模稀释”

学术依据：
本方法融合了现代科学计量学中的多个主流理念：
1. 关注头部成果：参考“高被引论文占比”等指标设计
2. 规模归一化处理：使用对数压缩防止大刊垄断
3. 复合指标优于单一指标：结合质量与数量构建综合得分


# 新颖性：关键词年龄法
关键词组合


跨学科性（Interdisciplinarity）：
参考黄颖等人在《学科相似性度量如何影响跨学科测度》中的研究方法
1.	需要 期刊-wos类别 对照表，将参考文献映射到wos类别
2.	Salton余弦归一化系数
3.	计算单篇论文跨学科性
4.	聚合得到期刊跨学科性


现在开始我让你干什么你就干什么,禁止自行推进后续代码,自行添加验证功能等
简述.我的期刊分析项目根目录下有
1.data文件夹,下面有cleaned文件夹,里面放两个数据集:一个是all_data,装载全量数据;另一个是目标期刊数据target_data,根据选定的期刊从all_data筛选
2.python_analysis文件夹,里面有四个指标计算python代码
3.scripts/preprocess_wos_excel代码,用于从data/raw文件夹里面读取所有excel文件,经过清洗掉会议论文,为每个论文提取出citing引用字段后导出all_data.csv在data/cleaned.然后根据目标期刊列表(默认是论文数量最多的前十个期刊)导出target_data
4.outputs文件夹,用于保存每个指标的输出
5.main.py文件,用于调用执行所有指标计算代码并输出
我想要实现以下功能
1.每个指标代码封装完好,可以实现对任意符合要求的数据的分析.
2.既能计算手工导入的,又能计算数据库里的数据
我负责数据分析部分,后续数据需要给前端展示.代码我慢慢给你看.你先告诉我我的代码设计应该怎样,怎样才能不频繁修改代码就能实现对多昂数据的分析输出.