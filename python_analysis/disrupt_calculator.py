# -*- coding: utf-8 -*-
"""
python_analysis/disrupt_calculator.py  # æ³¨æ„ï¼šè·¯å¾„å·²æ”¹ä¸º python_analysis/
æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°åˆ†æç³»ç»Ÿï¼ˆæ¨¡å—åŒ–å°è£…ç‰ˆï¼‰
åŠŸèƒ½ï¼šè®¡ç®—è®ºæ–‡çº§ D-index â†’ ç”ŸæˆæœŸåˆŠçº§é¢ è¦†æ€§æ’å â†’ å¯¼å‡ºç»“æœè‡³ outputs/disrupt/
"""

# === åŸºç¡€åº“ ===
import os
import json
from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
from collections import defaultdict
import ast
import warnings
# === è®¾ç½® ===
pd.options.mode.chained_assignment = None  # å…³é—­è­¦å‘Š
os.makedirs('../outputs/disrupt', exist_ok=True)  # ä¿®æ­£ï¼šä» python_analysis æŒ‡å‘æ ¹ç›®å½• outputs
# === è®¾ç½® ===
warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['axes.unicode_minus'] = False   # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

class DisruptionIndexCalculator:
    """
    é¢ è¦†æ€§æŒ‡æ•°è®¡ç®—å™¨ï¼ˆåŸºäº Wu et al., Nature 2019ï¼‰
    """
    def __init__(self):
        self.citation_network = defaultdict(set)  # cited -> {citing}
        self.paper_references = {}               # paper_id -> {refs}

    def build_citation_network(self, df):
        """æ„å»ºå…¨å±€å¼•æ–‡ç½‘ç»œ"""
        print("æ­£åœ¨æ„å»ºå¼•æ–‡ç½‘ç»œ...")
        for _, row in df.iterrows():
            paper_id = row['DOI']
            citing_str = row.get('citing', None)
            
            refs = set()
            if pd.notna(citing_str):
                try:
                    if isinstance(citing_str, str):
                        refs = set(ast.literal_eval(citing_str))
                    else:
                        refs = set(citing_str)
                except (ValueError, SyntaxError):
                    pass  # è§£æå¤±è´¥åˆ™ç•™ç©º
            
            self.paper_references[paper_id] = refs
            for ref in refs:
                self.citation_network[ref].add(paper_id)
        
        print(f"å¼•æ–‡ç½‘ç»œæ„å»ºå®Œæˆ | æ¶‰åŠè®ºæ–‡æ•°: {len(df)}")
        return self

    def calculate_disruption_index(self, focal_paper_id):
        """è®¡ç®—å•ç¯‡è®ºæ–‡çš„ D-index"""
        R = self.paper_references.get(focal_paper_id, set())  # å‚è€ƒæ–‡çŒ®
        C = self.citation_network.get(focal_paper_id, set())  # æ–½å¼•æ–‡çŒ®
        
        ni = nj = nk = 0
        
        # ni: å¼•FPä½†ä¸å¼•Rï¼›nj: åŒæ—¶å¼•FPå’ŒR
        for citing_paper in C:
            citing_refs = self.paper_references.get(citing_paper, set())
            if citing_refs & R:
                nj += 1
            else:
                ni += 1
        
        # nk: å¼•Rä½†ä¸å¼•FP
        papers_citing_R = set()
        for r in R:
            papers_citing_R.update(self.citation_network.get(r, set()))
        nk = len(papers_citing_R - C)
        
        denom = ni + nj + nk
        d_index = (ni - nj) / denom if denom > 0 else 0.0
        return d_index, (ni, nj, nk)


def export_citation_network(calculator, paper_scores_df, output_file=None):
    """
    å¯¼å‡ºå¸¦ D-index çš„å¼•æ–‡ç½‘ç»œï¼ˆJSON æ ¼å¼ï¼‰
    
    Parameters:
        calculator: æ„å»ºå¥½çš„ DisruptionIndexCalculator å®ä¾‹
        paper_scores_df: åŒ…å« 'DOI' å’Œ 'disruption_index' çš„ DataFrame
        output_file: è¾“å‡ºè·¯å¾„ï¼›é»˜è®¤ä¸º PROJECT_ROOT/outputs/disrupt/citation_network.json
    """
    # ä¿®æ­£ï¼šä» python_analysis ç›®å½•æ¨å¯¼é¡¹ç›®æ ¹ç›®å½•ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
    try:
        current_dir = os.path.dirname(__file__)  # å½“å‰æ–‡ä»¶ç›®å½•ï¼špython_analysis/
    except NameError:
        current_dir = os.getcwd()
    project_root = os.path.abspath(os.path.join(current_dir, '..'))  # ä¸Šä¸€çº§ï¼šæ ¹ç›®å½•
    
    if output_file is None:
        output_file = os.path.join(project_root, 'outputs', 'disrupt', 'citation_network.json')

    print("ğŸ“¦ æ­£åœ¨å¯¼å‡ºå¸¦ D-index çš„å¼•æ–‡ç½‘ç»œ...")

    # æ„å»ºè¾¹
    edges = []
    for cited_doi, citing_set in calculator.citation_network.items():
        for citing_doi in citing_set:
            edges.append({'source': cited_doi, 'target': citing_doi})

    # æ„å»ºèŠ‚ç‚¹ï¼ˆç»Ÿä¸€ nan -> None -> JSON nullï¼‰
    d_index_series = paper_scores_df.set_index('DOI')['disruption_index']
    d_index_map = {}
    for doi, val in d_index_series.items():
        d_index_map[doi] = None if pd.isna(val) else val

    nodes = []
    for paper_id in calculator.paper_references.keys():
        nodes.append({
            'id': paper_id,
            'type': 'paper',
            'n_references': len(calculator.paper_references[paper_id]),
            'disruption_index': d_index_map.get(paper_id, None)
        })

    graph_data = {'nodes': nodes, 'edges': edges}
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(graph_data, f, ensure_ascii=False, indent=2)

    print(f"æˆåŠŸå¯¼å‡ºå¼•æ–‡ç½‘ç»œï¼šå…± {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(edges)} æ¡è¾¹")
    print(f"æ–‡ä»¶å·²ä¿å­˜è‡³: {output_file}")


def calculate_paper_disruption_scores(df_background, df_target):
    """
    ä¸»å‡½æ•°ï¼šä¸º df_target ä¸­çš„æ¯ç¯‡è®ºæ–‡è®¡ç®— D-index
    è¿”å›ç»“æœè¡¨ å’Œ æ„å»ºå¥½çš„è®¡ç®—å™¨
    """
    calc = DisruptionIndexCalculator().build_citation_network(df_background)
    
    results = []
    total = len(df_target)
    progress_checkpoint = 0

    print("ğŸ“Š å¼€å§‹è®¡ç®—è®ºæ–‡é¢ è¦†æ€§æŒ‡æ•°...")
    for i, (_, row) in enumerate(df_target.iterrows()):
        doi = row['DOI']
        try:
            d_index, _ = calc.calculate_disruption_index(doi)
            results.append({'DOI': doi, 'disruption_index': d_index})
        except Exception:
            results.append({'DOI': doi, 'disruption_index': np.nan})

        current_progress = (i + 1) / total
        if current_progress >= progress_checkpoint:
            print(f"âœ… è¿›åº¦: {int(progress_checkpoint * 100)}%", end="\r")
            progress_checkpoint += 0.1

    print("\nğŸ‰ è®¡ç®—å®Œæˆï¼")
    result_df = pd.DataFrame(results)
    final_df = result_df.merge(df_target[['DOI', 'Source Title']], on='DOI', how='left')
    
    return final_df, calc


def calculate_original_metrics(df):
    """åŸå§‹æ–¹æ³•ï¼šæ‰€æœ‰è®ºæ–‡å¹³å‡ D-index"""
    return (df.groupby('Source Title')
              .agg({'disruption_index': 'mean', 'DOI': 'count'})
              .rename(columns={'disruption_index': 'disruption_mean', 'DOI': 'paper_count'})
              .sort_values('disruption_mean', ascending=False)
              .reset_index())


def calculate_enhanced_metrics(df, top_k=10, volume_weight=0.4):
    """å¢å¼ºæ–¹æ³•ï¼šTop-k å¹³å‡ + è§„æ¨¡åŠ æƒ"""
    valid = df.dropna(subset=['disruption_index'])
    grouped = valid.groupby('Source Title')
    
    records = []
    for journal, group in grouped:
        n_papers = len(group)
        k = min(top_k, n_papers)
        top_avg = group.nlargest(k, 'disruption_index')['disruption_index'].mean()
        log_n = np.log1p(n_papers)
        score = (1 - volume_weight) * top_avg + volume_weight * (top_avg / log_n)

        records.append({
            'Source Title': journal,
            'n_papers': n_papers,
            'top_k_mean': top_avg,
            'enhanced_disruption': score
        })
    
    return pd.DataFrame(records).sort_values('enhanced_disruption', ascending=False).reset_index(drop=True)


def visualize_journal_ranking(journal_metrics, top_n=None, title=None, value_col='disruption_mean'):
    """
    é€šç”¨æœŸåˆŠæ’åå¯è§†åŒ–ï¼ˆéœ€è¦è°ƒç”¨ plt.show() æ˜¾ç¤ºï¼‰
    """
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print("âš ï¸ matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        return

    data = journal_metrics.head(top_n) if top_n is not None else journal_metrics.copy()
    
    plt.figure(figsize=(14, max(8, len(data) * 0.4)))
    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(data)))

    bars = plt.barh(
        data['Source Title'],
        data[value_col],
        color=colors,
        alpha=0.8,
        edgecolor='black',
        linewidth=0.5,
        height=0.7
    )

    max_val = data[value_col].max()
    text_x = max_val * 1.08

    for bar, val in zip(bars, data[value_col]):
        plt.text(text_x, bar.get_y() + bar.get_height()/2,
                 f'{val:.4f}', ha='left', va='center', fontsize=10,
                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))

    plt.xlabel("é¢ è¦†æ€§æŒ‡æ•°", fontsize=13, fontweight='bold')
    plt.ylabel("æœŸåˆŠåç§°", fontsize=13, fontweight='bold')
    plt.title(title or "æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°æ’å", fontsize=16, fontweight='bold', pad=20)

    ax = plt.gca()
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_linewidth(0.5)
    ax.spines['bottom'].set_linewidth(0.5)
    ax.grid(axis='x', linestyle='--', alpha=0.3, color='gray')
    ax.set_facecolor('#f8f9fa')
    plt.gcf().patch.set_facecolor('white')
    ax.invert_yaxis()
    plt.tight_layout()


def run_analysis(background_path=None, target_path=None, output_dir=None):
    """
    ä¸»æ‰§è¡Œå‡½æ•°ï¼šç«¯åˆ°ç«¯è¿è¡Œé¢ è¦†æ€§åˆ†æ
    
    è‡ªåŠ¨è¯†åˆ«é¡¹ç›®æ ¹ç›®å½•ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®ã€‚
    æ‰€æœ‰ç»“æœè¾“å‡ºè‡³ outputs/disrupt/
    """
    # ========== 1. æ¨å¯¼é¡¹ç›®æ ¹ç›®å½•ï¼ˆå…³é”®ä¿®æ”¹ï¼šé€‚é… python_analysis/ ç›®å½•ï¼‰ ==========
    try:
        current_dir = os.path.dirname(__file__)  # å½“å‰æ–‡ä»¶ç›®å½•ï¼špython_analysis/
    except NameError:
        current_dir = os.getcwd()
    project_root = os.path.abspath(os.path.join(current_dir, '..'))  # ä¸Šä¸€çº§ï¼šæ ¹ç›®å½•

    print(f"é¡¹ç›®æ ¹ç›®å½•è¯†åˆ«ä¸º: {project_root}")

    # ========== 2. è®¾ç½®é»˜è®¤è·¯å¾„ ==========
    if background_path is None:
        background_path = os.path.join(project_root, 'data', 'raw', 'data_with_citing.csv')  # æ ¹ç›®å½•/data/
    if target_path is None:
        target_path = os.path.join(project_root, 'data', 'raw', 'top10_journals_data.csv')  # æ ¹ç›®å½•/data/
    if output_dir is None:
        output_dir = os.path.join(project_root, 'outputs', 'disrupt')  # æ ¹ç›®å½•/outputs/

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # ========== 3. åŠ è½½æ•°æ® ==========
    print("æ­£åœ¨åŠ è½½èƒŒæ™¯æ•°æ®...")
    df_all = pd.read_csv(background_path)
    print("æ­£åœ¨åŠ è½½ç›®æ ‡æ•°æ®...")
    df_top10 = pd.read_csv(target_path)

    # ========== 4. è®¡ç®—è®ºæ–‡çº§ D-index ==========
    paper_scores, calculator = calculate_paper_disruption_scores(df_all, df_top10)

    # ========== 5. ç”ŸæˆæœŸåˆŠçº§æŒ‡æ ‡ ==========
    original_metrics = calculate_original_metrics(paper_scores)
    enhanced_metrics = calculate_enhanced_metrics(paper_scores, top_k=10, volume_weight=0.4)

    # ========== 6. å¯¼å‡ºæ‰€æœ‰ç»“æœ ==========
    # 6.1 å¼•æ–‡ç½‘ç»œ
    export_citation_network(calculator, paper_scores, 
                           output_file=os.path.join(output_dir, 'citation_network.json'))

    # 6.2 åŸå§‹æ–¹æ³•æ’å CSV
    orig_csv = os.path.join(output_dir, 'top10_original_ranking.csv')
    original_metrics.to_csv(orig_csv, index=False, encoding='utf-8-sig')
    print(f"åŸå§‹æ–¹æ³•æ’åå·²ä¿å­˜: {orig_csv}")

    # 6.3 å¢å¼ºæ–¹æ³•æ’å CSV
    enh_csv = os.path.join(output_dir, 'top10_enhanced_ranking.csv')
    enhanced_metrics.to_csv(enh_csv, index=False, encoding='utf-8-sig')
    print(f"å¢å¼ºæ–¹æ³•æ’åå·²ä¿å­˜: {enh_csv}")

    # 6.4 æœŸåˆŠåç§°åˆ—è¡¨ TXT
    txt_path = os.path.join(output_dir, 'top10_journals_list.txt')
    with open(txt_path, 'w', encoding='utf-8') as f:
        for journal in original_metrics['Source Title']:
            f.write(f"{journal}\n")
    print(f"æœŸåˆŠåˆ—è¡¨å·²ä¿å­˜: {txt_path}")

    # ========== 7. å¯è§†åŒ– ==========
    try:
        visualize_journal_ranking(
            original_metrics,
            top_n=10,
            title="ã€æ–¹æ³•ä¸€ã€‘æœŸåˆŠå¹³å‡é¢ è¦†æ€§æ’å",
            value_col='disruption_mean'
        )
        plt.show()

        visualize_journal_ranking(
            enhanced_metrics,
            top_n=10,
            title="ã€æ–¹æ³•äºŒã€‘Top10é«˜å½±å“åŠ›è®ºæ–‡+è§„æ¨¡åŠ æƒ",
            value_col='enhanced_disruption'
        )
        plt.show()
    except:
        print("âš ï¸ å¯è§†åŒ–æ˜¾ç¤ºå¤±è´¥ï¼ˆå¯èƒ½ç¯å¢ƒä¸æ”¯æŒï¼‰ï¼Œä½†æ•°æ®å·²æ­£å¸¸å¯¼å‡ºã€‚")

    # ========== 8. è¿”å›ç»“æœ ==========
    return {
        'paper_scores': paper_scores,
        'original_metrics': original_metrics,
        'enhanced_metrics': enhanced_metrics,
        'calculator': calculator
    }

# ========================
# å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œåˆ™æ‰§è¡Œä¸»æµç¨‹
# ========================
if __name__ == "__main__":
    run_analysis()