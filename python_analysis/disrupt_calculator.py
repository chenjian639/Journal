# -*- coding: utf-8 -*-
"""
python_analysis/disrupt_calculator.py
æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°åˆ†æç³»ç»Ÿ - æœ€ç»ˆç‰ˆ
è¾“å‡ºï¼šå¢å¼ºå‹å¾—åˆ†å›¾è¡¨ + ç™¾åˆ†åˆ¶å›¾è¡¨ + ç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨
ç™¾åˆ†åˆ¶å¾—åˆ† = å¢å¼ºå‹å¾—åˆ† Ã— 100
"""
import json
import ast
import warnings
from pathlib import Path
import pandas as pd
import numpy as np
from collections import defaultdict
import matplotlib.pyplot as plt
from matplotlib import font_manager

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
font_path = "C:/Windows/Fonts/simhei.ttf"
if Path(font_path).exists():
    font_manager.fontManager.addfont(font_path)
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    plt.rcParams['font.sans-serif'] = [font_name]
plt.rcParams['axes.unicode_minus'] = False

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path(__file__).resolve().parent.parent / 'config.json'
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    return config.get('disrupt', {})

def log(msg):
    print(f"[disrupt] {msg}")

class DisruptionIndexCalculator:
    def __init__(self, config=None):
        self.citation_network = defaultdict(set)
        self.paper_references = {}
        self.config = config or load_config()
        self.data_config = self.config.get('data_sources', {})
        self.column_config = self.config.get('columns', {})
        self.output_config = self.config.get('output', {})
        self.param_config = self.config.get('parameters', {})

    def get_column_name(self, column_type):
        column_mapping = {
            'id': self.column_config.get('id', 'DOI'),
            'journal': self.column_config.get('journal', 'Source Title'),
            'citing': self.column_config.get('citing', 'citing')
        }
        return column_mapping.get(column_type, column_type)

    def build_citation_network(self, df):
        log("æ„å»ºå¼•æ–‡ç½‘ç»œ...")
        
        id_col = self.get_column_name('id')
        citing_col = self.get_column_name('citing')
        
        self.citation_network = defaultdict(set)
        self.paper_references = {}
        
        for _, row in df.iterrows():
            pid = row.get(id_col)
            if pd.isna(pid):
                continue
                
            citing_str = row.get(citing_col)
            refs = set()
            
            if pd.notna(citing_str):
                try:
                    if isinstance(citing_str, str):
                        refs = set(ast.literal_eval(citing_str))
                except:
                    pass
            
            self.paper_references[pid] = refs
            for ref in refs:
                self.citation_network[ref].add(pid)
        
        log(f"ç½‘ç»œæ„å»ºå®Œæˆ | è®ºæ–‡: {len(self.paper_references)}")
        return self

    def calculate_disruption_index(self, focal_pid):
        R = self.paper_references.get(focal_pid, set())
        C = self.citation_network.get(focal_pid, set())
        
        ni = nj = nk = 0
        
        for citing_paper in C:
            citing_refs = self.paper_references.get(citing_paper, set())
            if citing_refs & R:
                nj += 1
            else:
                ni += 1
        
        papers_citing_R = set()
        for r in R:
            papers_citing_R.update(self.citation_network.get(r, set()))
        
        nk = len(papers_citing_R - C)
        denom = ni + nj + nk
        d_index = (ni - nj) / denom if denom > 0 else 0.0
        
        return d_index

def calculate_paper_scores(df_background, df_target):
    """è®¡ç®—æ‰€æœ‰è®ºæ–‡çš„é¢ è¦†æ€§æŒ‡æ•°"""
    calculator = DisruptionIndexCalculator().build_citation_network(df_background)
    
    id_col = calculator.get_column_name('id')
    journal_col = calculator.get_column_name('journal')
    
    results = []
    log("è®¡ç®—è®ºæ–‡é¢ è¦†æ€§æŒ‡æ•°...")
    
    for i, (_, row) in enumerate(df_target.iterrows()):
        pid = row.get(id_col)
        
        if pid and pd.notna(pid):
            try:
                d_index = calculator.calculate_disruption_index(pid)
                results.append({
                    id_col: pid,
                    'journal': row.get(journal_col),
                    'disruption_index': d_index
                })
            except:
                results.append({
                    id_col: pid,
                    'journal': row.get(journal_col),
                    'disruption_index': np.nan
                })
        
        # è¿›åº¦æ˜¾ç¤º
        if len(df_target) > 0 and (i + 1) % max(1, len(df_target) // 10) == 0:
            log(f"è¿›åº¦: {int((i + 1) / len(df_target) * 100)}%")
    
    log("è®ºæ–‡è®¡ç®—å®Œæˆ")
    return pd.DataFrame(results), calculator

def calculate_enhanced_metrics(df, top_k=10, volume_weight=0.4):
    """è®¡ç®—å¢å¼ºæœŸåˆŠæŒ‡æ ‡ï¼ˆTop-KåŠ æƒï¼‰"""
    if 'disruption_index' not in df.columns or df.empty:
        log("æ²¡æœ‰æœ‰æ•ˆçš„é¢ è¦†æ€§æŒ‡æ•°æ•°æ®")
        return pd.DataFrame(columns=['journal', 'n_papers', 'enhanced_score', 'original_score'])
    
    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    valid_df = df.dropna(subset=['disruption_index'])
    if valid_df.empty:
        return pd.DataFrame(columns=['journal', 'n_papers', 'enhanced_score', 'original_score'])
    
    # ç¡®ä¿æœŸåˆŠåˆ—å­˜åœ¨
    journal_col = 'journal' if 'journal' in valid_df.columns else 'Source Title'
    if journal_col not in valid_df.columns:
        log(f"ç¼ºå°‘æœŸåˆŠåˆ—: {journal_col}")
        return pd.DataFrame(columns=['journal', 'n_papers', 'enhanced_score', 'original_score'])
    
    records = []
    grouped = valid_df.groupby(journal_col)
    
    for journal, group in grouped:
        n_papers = len(group)
        
        # è®¡ç®—Top-Kå¹³å‡
        k = min(top_k, n_papers)
        if k > 0:
            top_avg = group.nlargest(k, 'disruption_index')['disruption_index'].mean()
            original_avg = group['disruption_index'].mean()
        else:
            top_avg = 0
            original_avg = 0
        
        # è®¡ç®—è§„æ¨¡åŠ æƒ
        log_n = np.log1p(n_papers) if n_papers > 0 else 1
        enhanced_score = (1 - volume_weight) * top_avg + volume_weight * (top_avg / log_n)
        
        records.append({
            'journal': journal,
            'n_papers': n_papers,
            'enhanced_score': enhanced_score,
            'original_score': original_avg
        })
    
    result_df = pd.DataFrame(records)
    if not result_df.empty:
        result_df = result_df.sort_values('enhanced_score', ascending=False).reset_index(drop=True)
    
    return result_df

def create_beautiful_bar_chart(data, title, filename, output_dir, value_col, ylabel, color_scheme='viridis'):
    """åˆ›å»ºç¾è§‚çš„æŸ±çŠ¶å›¾"""
    if data.empty:
        log("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
        return
    
    # è®¾ç½®å›¾è¡¨å°ºå¯¸ï¼ˆæ ¹æ®æœŸåˆŠæ•°é‡è°ƒæ•´é«˜åº¦ï¼‰
    n_journals = len(data)
    fig_height = max(6, n_journals * 0.4)  # æ¯ä¸ªæœŸåˆŠ0.4é«˜åº¦
    fig, ax = plt.subplots(figsize=(12, fig_height))
    
    # é€‰æ‹©é¢œè‰²æ–¹æ¡ˆ
    if color_scheme == 'blues':
        colors = plt.cm.Blues(np.linspace(0.4, 0.9, n_journals))
    elif color_scheme == 'greens':
        colors = plt.cm.Greens(np.linspace(0.4, 0.9, n_journals))
    else:
        colors = plt.cm.viridis(np.linspace(0.2, 0.9, n_journals))
    
    # åˆ›å»ºæ°´å¹³æŸ±çŠ¶å›¾
    y_positions = np.arange(n_journals)
    bars = ax.barh(y_positions, data[value_col], 
                  color=colors, 
                  alpha=0.85,
                  height=0.7,
                  edgecolor='white',
                  linewidth=1.2)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, val, journal_name, paper_count) in enumerate(zip(bars, data[value_col], 
                                                                  data['æœŸåˆŠåç§°'], 
                                                                  data['è®ºæ–‡æ•°é‡'])):
        # æ•°å€¼æ ‡ç­¾ï¼ˆå³ä¾§ï¼‰
        label_x = bar.get_width() + max(data[value_col]) * 0.02  # åŠ¨æ€åç§»
        
        # ç¡®å®šæ ‡ç­¾æ ¼å¼
        if value_col == 'ç™¾åˆ†åˆ¶å¾—åˆ†':
            label_text = f'{val:.1f}åˆ†'
        else:
            label_text = f'{val:.4f}'
        
        ax.text(label_x, bar.get_y() + bar.get_height()/2,
               label_text, 
               ha='left', va='center',
               fontsize=10, fontweight='bold',
               color='#2c3e50')
        
        # åœ¨æŸ±å­å·¦ä¾§æ˜¾ç¤ºæœŸåˆŠåç§°å’Œæ’å
        short_name = journal_name[:28] + "..." if len(journal_name) > 28 else journal_name
        rank_text = f"{i+1}. {short_name}"
        ax.text(-max(data[value_col]) * 0.02, bar.get_y() + bar.get_height()/2,
               rank_text,
               ha='right', va='center',
               fontsize=9.5,
               color='#34495e')
        
        # åœ¨æŸ±å­å†…éƒ¨æ˜¾ç¤ºè®ºæ–‡æ•°é‡ï¼ˆå¦‚æœæŸ±å­è¶³å¤Ÿå®½ï¼‰
        if bar.get_width() > max(data[value_col]) * 0.1:
            count_text = f"{paper_count}ç¯‡"
            ax.text(bar.get_width()/2, bar.get_y() + bar.get_height()/2,
                   count_text,
                   ha='center', va='center',
                   fontsize=8.5, color='white',
                   fontweight='bold')
    
    # è®¾ç½®yè½´
    ax.set_yticks(y_positions)
    ax.set_yticklabels([])  # éšè—yè½´æ ‡ç­¾
    
    # è®¾ç½®xè½´
    ax.set_xlabel(ylabel, fontsize=11, fontweight='bold', color='#2c3e50')
    
    # è®¾ç½®xè½´èŒƒå›´
    max_val = max(data[value_col]) * 1.15
    ax.set_xlim([0, max_val])
    
    # è®¾ç½®æ ‡é¢˜
    ax.set_title(title, fontsize=14, fontweight='bold', pad=18, color='#2c3e50')
    
    # ç¾åŒ–æ ·å¼
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_color('#95a5a6')
    
    # ç½‘æ ¼çº¿
    ax.grid(axis='x', linestyle='--', alpha=0.25, color='#bdc3c7')
    
    # åè½¬yè½´ï¼ˆä»é«˜åˆ°ä½ï¼‰
    ax.invert_yaxis()
    
    # èƒŒæ™¯è‰²
    ax.set_facecolor('#f8f9fa')
    fig.patch.set_facecolor('white')
    
    # åˆ»åº¦çº¿
    ax.tick_params(axis='x', colors='#7f8c8d')
    ax.tick_params(axis='y', length=0)
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    img_path = output_dir / filename
    plt.savefig(img_path, dpi=300, bbox_inches='tight', 
                facecolor=fig.get_facecolor(), edgecolor='none')
    plt.close()
    
    log(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {img_path}")

def run_analysis(config=None):
    """è¿è¡Œåˆ†æ"""
    log("=" * 60)
    log("æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°åˆ†æ")
    log("=" * 60)
    
    # åŠ è½½é…ç½®
    if config is None:
        config = load_config()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(config.get('output', {}).get('disrupt_dir', 'outputs/disrupt'))
    output_dir.mkdir(parents=True, exist_ok=True)
    log(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # åŠ è½½æ•°æ®
    project_root = Path(__file__).resolve().parent.parent
    data_config = config.get('data_sources', {})
    
    bg_path = project_root / data_config['all_data']
    tg_path = project_root / data_config['target_data']
    
    log(f"ğŸ“‚ åŠ è½½æ•°æ®...")
    log(f"  èƒŒæ™¯æ•°æ®: {bg_path}")
    log(f"  ç›®æ ‡æ•°æ®: {tg_path}")
    
    background_df = pd.read_csv(bg_path)
    target_df = pd.read_csv(tg_path)
    
    # è®¡ç®—è®ºæ–‡åˆ†æ•°
    log("\nğŸ“ˆ è®¡ç®—è®ºæ–‡é¢ è¦†æ€§æŒ‡æ•°...")
    paper_scores, _ = calculate_paper_scores(background_df, target_df)
    
    # è®¡ç®—å¢å¼ºæŒ‡æ ‡
    params = config.get('parameters', {})
    top_k = params.get('top_k', 10)
    volume_weight = params.get('volume_weight', 0.4)
    
    log("ğŸ“Š è®¡ç®—å¢å¼ºå‹æœŸåˆŠæŒ‡æ ‡...")
    enhanced_metrics = calculate_enhanced_metrics(paper_scores, top_k, volume_weight)
    
    if enhanced_metrics.empty:
        log("âš ï¸  è­¦å‘Š: æœªè®¡ç®—åˆ°æœ‰æ•ˆçš„æœŸåˆŠæŒ‡æ ‡")
        return
    
    # è®¡ç®—ç™¾åˆ†åˆ¶å¾—åˆ†ï¼šå¢å¼ºå‹å¾—åˆ† Ã— 100
    enhanced_metrics['percent_score'] = enhanced_metrics['enhanced_score'] * 100
    
    # é‡å‘½ååˆ—
    output_df = enhanced_metrics.copy()
    output_df = output_df.rename(columns={
        'journal': 'æœŸåˆŠåç§°',
        'n_papers': 'è®ºæ–‡æ•°é‡',
        'enhanced_score': 'å¢å¼ºå‹å¾—åˆ†',
        'original_score': 'åŸå§‹å¹³å‡å¾—åˆ†',
        'percent_score': 'ç™¾åˆ†åˆ¶å¾—åˆ†'
    })
    
    # ä¿å­˜å®Œæ•´çš„æœŸåˆŠåˆ—è¡¨ï¼ˆæ‰€æœ‰ç›®æ ‡æœŸåˆŠï¼‰
    final_list = output_df.sort_values('ç™¾åˆ†åˆ¶å¾—åˆ†', ascending=False).reset_index(drop=True)
    final_list.insert(0, 'æ’å', range(1, len(final_list) + 1))
    
    # 1. ç”Ÿæˆå¢å¼ºå‹å¾—åˆ†å›¾è¡¨ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æœŸåˆŠï¼‰
    log("\nğŸ¨ ç”Ÿæˆå¢å¼ºå‹å¾—åˆ†å›¾è¡¨...")
    create_beautiful_bar_chart(
        data=final_list,
        title='æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•° - å¢å¼ºå‹å¾—åˆ†',
        filename='enhanced_disruption_scores.png',
        output_dir=output_dir,
        value_col='å¢å¼ºå‹å¾—åˆ†',
        ylabel='å¢å¼ºå‹å¾—åˆ†',
        color_scheme='blues'
    )
    
    # 2. ç”Ÿæˆç™¾åˆ†åˆ¶å›¾è¡¨ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æœŸåˆŠï¼‰
    log("ğŸ¨ ç”Ÿæˆç™¾åˆ†åˆ¶å¾—åˆ†å›¾è¡¨...")
    create_beautiful_bar_chart(
        data=final_list,
        title='æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•° - ç™¾åˆ†åˆ¶å¾—åˆ†',
        filename='percent_disruption_scores.png',
        output_dir=output_dir,
        value_col='ç™¾åˆ†åˆ¶å¾—åˆ†',
        ylabel='ç™¾åˆ†åˆ¶å¾—åˆ† (å¢å¼ºå‹å¾—åˆ† Ã— 100)',
        color_scheme='greens'
    )
    
    # 3. ç”Ÿæˆç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨CSV
    csv_path = output_dir / "journal_disruption_scores.csv"
    final_list.to_csv(csv_path, index=False, encoding="utf-8-sig", float_format='%.2f')
    log(f"ğŸ“„ ç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨å·²ä¿å­˜: {csv_path}")
    
    # æ˜¾ç¤ºæ‰€æœ‰æœŸåˆŠæ•°é‡
    log(f"\nğŸ“‹ åˆ†æå®Œæˆï¼Œå…± {len(final_list)} ç§æœŸåˆŠ")
    
    log("\nâœ… åˆ†æå®Œæˆï¼")
    log(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    log(f"  1. enhanced_disruption_scores.png - å¢å¼ºå‹å¾—åˆ†æŸ±çŠ¶å›¾")
    log(f"  2. percent_disruption_scores.png - ç™¾åˆ†åˆ¶å¾—åˆ†æŸ±çŠ¶å›¾")
    log(f"  3. journal_disruption_scores.csv - ç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨")

if __name__ == '__main__':
    try:
        run_analysis()
    except FileNotFoundError as e:
        print(f"[é”™è¯¯] æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except Exception as e:
        print(f"[é”™è¯¯] ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()