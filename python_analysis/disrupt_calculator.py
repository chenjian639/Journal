# -*- coding: utf-8 -*-
"""
<<<<<<< HEAD
python_analysis/disrupt_calculator.py
æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°åˆ†æžç³»ç»Ÿ - æœ€ç»ˆç‰ˆ
è¾“å‡ºï¼šå¢žå¼ºåž‹å¾—åˆ†å›¾è¡¨ + ç™¾åˆ†åˆ¶å›¾è¡¨ + ç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨
ç™¾åˆ†åˆ¶å¾—åˆ† = å¢žå¼ºåž‹å¾—åˆ† Ã— 100
"""
import json
import ast
import warnings
from pathlib import Path
import pandas as pd
import numpy as np
from collections import defaultdict
import matplotlib.pyplot as plt
from matplotlib import font_manager

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
font_path = "C:/Windows/Fonts/simhei.ttf"
if Path(font_path).exists():
    font_manager.fontManager.addfont(font_path)
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    plt.rcParams['font.sans-serif'] = [font_name]
plt.rcParams['axes.unicode_minus'] = False

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path(__file__).resolve().parent.parent / 'config.json'
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    return config.get('disrupt', {})

def log(msg):
    print(f"[disrupt] {msg}")

class DisruptionIndexCalculator:
    def __init__(self, config=None):
        self.citation_network = defaultdict(set)
        self.paper_references = {}
        self.config = config or load_config()
        self.data_config = self.config.get('data_sources', {})
        self.column_config = self.config.get('columns', {})
        self.output_config = self.config.get('output', {})
        self.param_config = self.config.get('parameters', {})

    def get_column_name(self, column_type):
        column_mapping = {
            'id': self.column_config.get('id', 'DOI'),
            'journal': self.column_config.get('journal', 'Source Title'),
            'citing': self.column_config.get('citing', 'citing')
        }
        return column_mapping.get(column_type, column_type)

    def build_citation_network(self, df):
        log("æž„å»ºå¼•æ–‡ç½‘ç»œ...")
        
        id_col = self.get_column_name('id')
        citing_col = self.get_column_name('citing')
        
        self.citation_network = defaultdict(set)
        self.paper_references = {}
        
        for _, row in df.iterrows():
            pid = row.get(id_col)
            if pd.isna(pid):
                continue
                
            citing_str = row.get(citing_col)
            refs = set()
            
=======
python_analysis/disrupt_calculator.py  # æ³¨æ„ï¼šè·¯å¾„å·²æ”¹ä¸º python_analysis/
æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°åˆ†æžç³»ç»Ÿï¼ˆæ¨¡å—åŒ–å°è£…ç‰ˆï¼‰
åŠŸèƒ½ï¼šè®¡ç®—è®ºæ–‡çº§ D-index â†’ ç”ŸæˆæœŸåˆŠçº§é¢ è¦†æ€§æŽ’å â†’ å¯¼å‡ºç»“æžœè‡³ outputs/disrupt/
"""

# === åŸºç¡€åº“ ===
import os
import json
from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
from collections import defaultdict
import ast
import warnings
# === è®¾ç½® ===
pd.options.mode.chained_assignment = None  # å…³é—­è­¦å‘Š
os.makedirs('../outputs/disrupt', exist_ok=True)  # ä¿®æ­£ï¼šä»Ž python_analysis æŒ‡å‘æ ¹ç›®å½• outputs
# === è®¾ç½® ===
warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['axes.unicode_minus'] = False   # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

class DisruptionIndexCalculator:
    """
    é¢ è¦†æ€§æŒ‡æ•°è®¡ç®—å™¨ï¼ˆåŸºäºŽ Wu et al., Nature 2019ï¼‰
    """
    def __init__(self):
        self.citation_network = defaultdict(set)  # cited -> {citing}
        self.paper_references = {}               # paper_id -> {refs}

    def build_citation_network(self, df):
        """æž„å»ºå…¨å±€å¼•æ–‡ç½‘ç»œ"""
        print("æ­£åœ¨æž„å»ºå¼•æ–‡ç½‘ç»œ...")
        for _, row in df.iterrows():
            paper_id = row['DOI']
            citing_str = row.get('citing', None)
            
            refs = set()
>>>>>>> 325a45d1acde271d3e82f31155b95d174bbec114
            if pd.notna(citing_str):
                try:
                    if isinstance(citing_str, str):
                        refs = set(ast.literal_eval(citing_str))
<<<<<<< HEAD
                except:
                    pass
            
            self.paper_references[pid] = refs
            for ref in refs:
                self.citation_network[ref].add(pid)
        
        log(f"ç½‘ç»œæž„å»ºå®Œæˆ | è®ºæ–‡: {len(self.paper_references)}")
        return self

    def calculate_disruption_index(self, focal_pid):
        R = self.paper_references.get(focal_pid, set())
        C = self.citation_network.get(focal_pid, set())
        
        ni = nj = nk = 0
        
=======
                    else:
                        refs = set(citing_str)
                except (ValueError, SyntaxError):
                    pass  # è§£æžå¤±è´¥åˆ™ç•™ç©º
            
            self.paper_references[paper_id] = refs
            for ref in refs:
                self.citation_network[ref].add(paper_id)
        
        print(f"å¼•æ–‡ç½‘ç»œæž„å»ºå®Œæˆ | æ¶‰åŠè®ºæ–‡æ•°: {len(df)}")
        return self

    def calculate_disruption_index(self, focal_paper_id):
        """è®¡ç®—å•ç¯‡è®ºæ–‡çš„ D-index"""
        R = self.paper_references.get(focal_paper_id, set())  # å‚è€ƒæ–‡çŒ®
        C = self.citation_network.get(focal_paper_id, set())  # æ–½å¼•æ–‡çŒ®
        
        ni = nj = nk = 0
        
        # ni: å¼•FPä½†ä¸å¼•Rï¼›nj: åŒæ—¶å¼•FPå’ŒR
>>>>>>> 325a45d1acde271d3e82f31155b95d174bbec114
        for citing_paper in C:
            citing_refs = self.paper_references.get(citing_paper, set())
            if citing_refs & R:
                nj += 1
            else:
                ni += 1
        
<<<<<<< HEAD
        papers_citing_R = set()
        for r in R:
            papers_citing_R.update(self.citation_network.get(r, set()))
        
        nk = len(papers_citing_R - C)
        denom = ni + nj + nk
        d_index = (ni - nj) / denom if denom > 0 else 0.0
        
        return d_index

def calculate_paper_scores(df_background, df_target):
    """è®¡ç®—æ‰€æœ‰è®ºæ–‡çš„é¢ è¦†æ€§æŒ‡æ•°"""
    calculator = DisruptionIndexCalculator().build_citation_network(df_background)
    
    id_col = calculator.get_column_name('id')
    journal_col = calculator.get_column_name('journal')
    
    results = []
    log("è®¡ç®—è®ºæ–‡é¢ è¦†æ€§æŒ‡æ•°...")
    
    for i, (_, row) in enumerate(df_target.iterrows()):
        pid = row.get(id_col)
        
        if pid and pd.notna(pid):
            try:
                d_index = calculator.calculate_disruption_index(pid)
                results.append({
                    id_col: pid,
                    'journal': row.get(journal_col),
                    'disruption_index': d_index
                })
            except:
                results.append({
                    id_col: pid,
                    'journal': row.get(journal_col),
                    'disruption_index': np.nan
                })
        
        # è¿›åº¦æ˜¾ç¤º
        if len(df_target) > 0 and (i + 1) % max(1, len(df_target) // 10) == 0:
            log(f"è¿›åº¦: {int((i + 1) / len(df_target) * 100)}%")
    
    log("è®ºæ–‡è®¡ç®—å®Œæˆ")
    return pd.DataFrame(results), calculator

def calculate_enhanced_metrics(df, top_k=10, volume_weight=0.4):
    """è®¡ç®—å¢žå¼ºæœŸåˆŠæŒ‡æ ‡ï¼ˆTop-KåŠ æƒï¼‰"""
    if 'disruption_index' not in df.columns or df.empty:
        log("æ²¡æœ‰æœ‰æ•ˆçš„é¢ è¦†æ€§æŒ‡æ•°æ•°æ®")
        return pd.DataFrame(columns=['journal', 'n_papers', 'enhanced_score', 'original_score'])
    
    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    valid_df = df.dropna(subset=['disruption_index'])
    if valid_df.empty:
        return pd.DataFrame(columns=['journal', 'n_papers', 'enhanced_score', 'original_score'])
    
    # ç¡®ä¿æœŸåˆŠåˆ—å­˜åœ¨
    journal_col = 'journal' if 'journal' in valid_df.columns else 'Source Title'
    if journal_col not in valid_df.columns:
        log(f"ç¼ºå°‘æœŸåˆŠåˆ—: {journal_col}")
        return pd.DataFrame(columns=['journal', 'n_papers', 'enhanced_score', 'original_score'])
    
    records = []
    grouped = valid_df.groupby(journal_col)
    
    for journal, group in grouped:
        n_papers = len(group)
        
        # è®¡ç®—Top-Kå¹³å‡
        k = min(top_k, n_papers)
        if k > 0:
            top_avg = group.nlargest(k, 'disruption_index')['disruption_index'].mean()
            original_avg = group['disruption_index'].mean()
        else:
            top_avg = 0
            original_avg = 0
        
        # è®¡ç®—è§„æ¨¡åŠ æƒ
        log_n = np.log1p(n_papers) if n_papers > 0 else 1
        enhanced_score = (1 - volume_weight) * top_avg + volume_weight * (top_avg / log_n)
        
        records.append({
            'journal': journal,
            'n_papers': n_papers,
            'enhanced_score': enhanced_score,
            'original_score': original_avg
        })
    
    result_df = pd.DataFrame(records)
    if not result_df.empty:
        result_df = result_df.sort_values('enhanced_score', ascending=False).reset_index(drop=True)
    
    return result_df

def create_beautiful_bar_chart(data, title, filename, output_dir, value_col, ylabel, color_scheme='viridis'):
    """åˆ›å»ºç¾Žè§‚çš„æŸ±çŠ¶å›¾"""
    if data.empty:
        log("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
        return
    
    # è®¾ç½®å›¾è¡¨å°ºå¯¸ï¼ˆæ ¹æ®æœŸåˆŠæ•°é‡è°ƒæ•´é«˜åº¦ï¼‰
    n_journals = len(data)
    fig_height = max(6, n_journals * 0.4)  # æ¯ä¸ªæœŸåˆŠ0.4é«˜åº¦
    fig, ax = plt.subplots(figsize=(12, fig_height))
    
    # é€‰æ‹©é¢œè‰²æ–¹æ¡ˆ
    if color_scheme == 'blues':
        colors = plt.cm.Blues(np.linspace(0.4, 0.9, n_journals))
    elif color_scheme == 'greens':
        colors = plt.cm.Greens(np.linspace(0.4, 0.9, n_journals))
    else:
        colors = plt.cm.viridis(np.linspace(0.2, 0.9, n_journals))
    
    # åˆ›å»ºæ°´å¹³æŸ±çŠ¶å›¾
    y_positions = np.arange(n_journals)
    bars = ax.barh(y_positions, data[value_col], 
                  color=colors, 
                  alpha=0.85,
                  height=0.7,
                  edgecolor='white',
                  linewidth=1.2)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, val, journal_name, paper_count) in enumerate(zip(bars, data[value_col], 
                                                                  data['æœŸåˆŠåç§°'], 
                                                                  data['è®ºæ–‡æ•°é‡'])):
        # æ•°å€¼æ ‡ç­¾ï¼ˆå³ä¾§ï¼‰
        label_x = bar.get_width() + max(data[value_col]) * 0.02  # åŠ¨æ€åç§»
        
        # ç¡®å®šæ ‡ç­¾æ ¼å¼
        if value_col == 'ç™¾åˆ†åˆ¶å¾—åˆ†':
            label_text = f'{val:.1f}åˆ†'
        else:
            label_text = f'{val:.4f}'
        
        ax.text(label_x, bar.get_y() + bar.get_height()/2,
               label_text, 
               ha='left', va='center',
               fontsize=10, fontweight='bold',
               color='#2c3e50')
        
        # åœ¨æŸ±å­å·¦ä¾§æ˜¾ç¤ºæœŸåˆŠåç§°å’ŒæŽ’å
        short_name = journal_name[:28] + "..." if len(journal_name) > 28 else journal_name
        rank_text = f"{i+1}. {short_name}"
        ax.text(-max(data[value_col]) * 0.02, bar.get_y() + bar.get_height()/2,
               rank_text,
               ha='right', va='center',
               fontsize=9.5,
               color='#34495e')
        
        # åœ¨æŸ±å­å†…éƒ¨æ˜¾ç¤ºè®ºæ–‡æ•°é‡ï¼ˆå¦‚æžœæŸ±å­è¶³å¤Ÿå®½ï¼‰
        if bar.get_width() > max(data[value_col]) * 0.1:
            count_text = f"{paper_count}ç¯‡"
            ax.text(bar.get_width()/2, bar.get_y() + bar.get_height()/2,
                   count_text,
                   ha='center', va='center',
                   fontsize=8.5, color='white',
                   fontweight='bold')
    
    # è®¾ç½®yè½´
    ax.set_yticks(y_positions)
    ax.set_yticklabels([])  # éšè—yè½´æ ‡ç­¾
    
    # è®¾ç½®xè½´
    ax.set_xlabel(ylabel, fontsize=11, fontweight='bold', color='#2c3e50')
    
    # è®¾ç½®xè½´èŒƒå›´
    max_val = max(data[value_col]) * 1.15
    ax.set_xlim([0, max_val])
    
    # è®¾ç½®æ ‡é¢˜
    ax.set_title(title, fontsize=14, fontweight='bold', pad=18, color='#2c3e50')
    
    # ç¾ŽåŒ–æ ·å¼
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_color('#95a5a6')
    
    # ç½‘æ ¼çº¿
    ax.grid(axis='x', linestyle='--', alpha=0.25, color='#bdc3c7')
    
    # åè½¬yè½´ï¼ˆä»Žé«˜åˆ°ä½Žï¼‰
    ax.invert_yaxis()
    
    # èƒŒæ™¯è‰²
    ax.set_facecolor('#f8f9fa')
    fig.patch.set_facecolor('white')
    
    # åˆ»åº¦çº¿
    ax.tick_params(axis='x', colors='#7f8c8d')
    ax.tick_params(axis='y', length=0)
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    img_path = output_dir / filename
    plt.savefig(img_path, dpi=300, bbox_inches='tight', 
                facecolor=fig.get_facecolor(), edgecolor='none')
    plt.close()
    
    log(f"ðŸ“Š å›¾è¡¨å·²ä¿å­˜: {img_path}")

def run_analysis(config=None):
    """è¿è¡Œåˆ†æž"""
    log("=" * 60)
    log("æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°åˆ†æž")
    log("=" * 60)
    
    # åŠ è½½é…ç½®
    if config is None:
        config = load_config()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(config.get('output', {}).get('disrupt_dir', 'outputs/disrupt'))
    output_dir.mkdir(parents=True, exist_ok=True)
    log(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # åŠ è½½æ•°æ®
    project_root = Path(__file__).resolve().parent.parent
    data_config = config.get('data_sources', {})
    
    bg_path = project_root / data_config['all_data']
    tg_path = project_root / data_config['target_data']
    
    log(f"ðŸ“‚ åŠ è½½æ•°æ®...")
    log(f"  èƒŒæ™¯æ•°æ®: {bg_path}")
    log(f"  ç›®æ ‡æ•°æ®: {tg_path}")
    
    background_df = pd.read_csv(bg_path)
    target_df = pd.read_csv(tg_path)
    
    # è®¡ç®—è®ºæ–‡åˆ†æ•°
    log("\nðŸ“ˆ è®¡ç®—è®ºæ–‡é¢ è¦†æ€§æŒ‡æ•°...")
    paper_scores, _ = calculate_paper_scores(background_df, target_df)
    
    # è®¡ç®—å¢žå¼ºæŒ‡æ ‡
    params = config.get('parameters', {})
    top_k = params.get('top_k', 10)
    volume_weight = params.get('volume_weight', 0.4)
    
    log("ðŸ“Š è®¡ç®—å¢žå¼ºåž‹æœŸåˆŠæŒ‡æ ‡...")
    enhanced_metrics = calculate_enhanced_metrics(paper_scores, top_k, volume_weight)
    
    if enhanced_metrics.empty:
        log("âš ï¸  è­¦å‘Š: æœªè®¡ç®—åˆ°æœ‰æ•ˆçš„æœŸåˆŠæŒ‡æ ‡")
        return
    
    # è®¡ç®—ç™¾åˆ†åˆ¶å¾—åˆ†ï¼šå¢žå¼ºåž‹å¾—åˆ† Ã— 100
    enhanced_metrics['percent_score'] = enhanced_metrics['enhanced_score'] * 100
    
    # é‡å‘½ååˆ—
    output_df = enhanced_metrics.copy()
    output_df = output_df.rename(columns={
        'journal': 'æœŸåˆŠåç§°',
        'n_papers': 'è®ºæ–‡æ•°é‡',
        'enhanced_score': 'å¢žå¼ºåž‹å¾—åˆ†',
        'original_score': 'åŽŸå§‹å¹³å‡å¾—åˆ†',
        'percent_score': 'ç™¾åˆ†åˆ¶å¾—åˆ†'
    })
    
    # ä¿å­˜å®Œæ•´çš„æœŸåˆŠåˆ—è¡¨ï¼ˆæ‰€æœ‰ç›®æ ‡æœŸåˆŠï¼‰
    final_list = output_df.sort_values('ç™¾åˆ†åˆ¶å¾—åˆ†', ascending=False).reset_index(drop=True)
    final_list.insert(0, 'æŽ’å', range(1, len(final_list) + 1))
    
    # 1. ç”Ÿæˆå¢žå¼ºåž‹å¾—åˆ†å›¾è¡¨ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æœŸåˆŠï¼‰
    log("\nðŸŽ¨ ç”Ÿæˆå¢žå¼ºåž‹å¾—åˆ†å›¾è¡¨...")
    create_beautiful_bar_chart(
        data=final_list,
        title='æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•° - å¢žå¼ºåž‹å¾—åˆ†',
        filename='enhanced_disruption_scores.png',
        output_dir=output_dir,
        value_col='å¢žå¼ºåž‹å¾—åˆ†',
        ylabel='å¢žå¼ºåž‹å¾—åˆ†',
        color_scheme='blues'
    )
    
    # 2. ç”Ÿæˆç™¾åˆ†åˆ¶å›¾è¡¨ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æœŸåˆŠï¼‰
    log("ðŸŽ¨ ç”Ÿæˆç™¾åˆ†åˆ¶å¾—åˆ†å›¾è¡¨...")
    create_beautiful_bar_chart(
        data=final_list,
        title='æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•° - ç™¾åˆ†åˆ¶å¾—åˆ†',
        filename='percent_disruption_scores.png',
        output_dir=output_dir,
        value_col='ç™¾åˆ†åˆ¶å¾—åˆ†',
        ylabel='ç™¾åˆ†åˆ¶å¾—åˆ† (å¢žå¼ºåž‹å¾—åˆ† Ã— 100)',
        color_scheme='greens'
    )
    
    # 3. ç”Ÿæˆç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨CSV
    csv_path = output_dir / "journal_disruption_scores.csv"
    final_list.to_csv(csv_path, index=False, encoding="utf-8-sig", float_format='%.2f')
    log(f"ðŸ“„ ç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨å·²ä¿å­˜: {csv_path}")
    
    # æ˜¾ç¤ºæ‰€æœ‰æœŸåˆŠæ•°é‡
    log(f"\nðŸ“‹ åˆ†æžå®Œæˆï¼Œå…± {len(final_list)} ç§æœŸåˆŠ")
    
    log("\nâœ… åˆ†æžå®Œæˆï¼")
    log(f"ðŸ“ è¾“å‡ºæ–‡ä»¶:")
    log(f"  1. enhanced_disruption_scores.png - å¢žå¼ºåž‹å¾—åˆ†æŸ±çŠ¶å›¾")
    log(f"  2. percent_disruption_scores.png - ç™¾åˆ†åˆ¶å¾—åˆ†æŸ±çŠ¶å›¾")
    log(f"  3. journal_disruption_scores.csv - ç™¾åˆ†åˆ¶å¾—åˆ†åˆ—è¡¨")

if __name__ == '__main__':
    try:
        run_analysis()
    except FileNotFoundError as e:
        print(f"[é”™è¯¯] æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except Exception as e:
        print(f"[é”™è¯¯] ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
=======
        # nk: å¼•Rä½†ä¸å¼•FP
        papers_citing_R = set()
        for r in R:
            papers_citing_R.update(self.citation_network.get(r, set()))
        nk = len(papers_citing_R - C)
        
        denom = ni + nj + nk
        d_index = (ni - nj) / denom if denom > 0 else 0.0
        return d_index, (ni, nj, nk)


def export_citation_network(calculator, paper_scores_df, output_file=None):
    """
    å¯¼å‡ºå¸¦ D-index çš„å¼•æ–‡ç½‘ç»œï¼ˆJSON æ ¼å¼ï¼‰
    
    Parameters:
        calculator: æž„å»ºå¥½çš„ DisruptionIndexCalculator å®žä¾‹
        paper_scores_df: åŒ…å« 'DOI' å’Œ 'disruption_index' çš„ DataFrame
        output_file: è¾“å‡ºè·¯å¾„ï¼›é»˜è®¤ä¸º PROJECT_ROOT/outputs/disrupt/citation_network.json
    """
    # ä¿®æ­£ï¼šä»Ž python_analysis ç›®å½•æŽ¨å¯¼é¡¹ç›®æ ¹ç›®å½•ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
    try:
        current_dir = os.path.dirname(__file__)  # å½“å‰æ–‡ä»¶ç›®å½•ï¼špython_analysis/
    except NameError:
        current_dir = os.getcwd()
    project_root = os.path.abspath(os.path.join(current_dir, '..'))  # ä¸Šä¸€çº§ï¼šæ ¹ç›®å½•
    
    if output_file is None:
        output_file = os.path.join(project_root, 'outputs', 'disrupt', 'citation_network.json')

    print("ðŸ“¦ æ­£åœ¨å¯¼å‡ºå¸¦ D-index çš„å¼•æ–‡ç½‘ç»œ...")

    # æž„å»ºè¾¹
    edges = []
    for cited_doi, citing_set in calculator.citation_network.items():
        for citing_doi in citing_set:
            edges.append({'source': cited_doi, 'target': citing_doi})

    # æž„å»ºèŠ‚ç‚¹ï¼ˆç»Ÿä¸€ nan -> None -> JSON nullï¼‰
    d_index_series = paper_scores_df.set_index('DOI')['disruption_index']
    d_index_map = {}
    for doi, val in d_index_series.items():
        d_index_map[doi] = None if pd.isna(val) else val

    nodes = []
    for paper_id in calculator.paper_references.keys():
        nodes.append({
            'id': paper_id,
            'type': 'paper',
            'n_references': len(calculator.paper_references[paper_id]),
            'disruption_index': d_index_map.get(paper_id, None)
        })

    graph_data = {'nodes': nodes, 'edges': edges}
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(graph_data, f, ensure_ascii=False, indent=2)

    print(f"æˆåŠŸå¯¼å‡ºå¼•æ–‡ç½‘ç»œï¼šå…± {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(edges)} æ¡è¾¹")
    print(f"æ–‡ä»¶å·²ä¿å­˜è‡³: {output_file}")


def calculate_paper_disruption_scores(df_background, df_target):
    """
    ä¸»å‡½æ•°ï¼šä¸º df_target ä¸­çš„æ¯ç¯‡è®ºæ–‡è®¡ç®— D-index
    è¿”å›žç»“æžœè¡¨ å’Œ æž„å»ºå¥½çš„è®¡ç®—å™¨
    """
    calc = DisruptionIndexCalculator().build_citation_network(df_background)
    
    results = []
    total = len(df_target)
    progress_checkpoint = 0

    print("ðŸ“Š å¼€å§‹è®¡ç®—è®ºæ–‡é¢ è¦†æ€§æŒ‡æ•°...")
    for i, (_, row) in enumerate(df_target.iterrows()):
        doi = row['DOI']
        try:
            d_index, _ = calc.calculate_disruption_index(doi)
            results.append({'DOI': doi, 'disruption_index': d_index})
        except Exception:
            results.append({'DOI': doi, 'disruption_index': np.nan})

        current_progress = (i + 1) / total
        if current_progress >= progress_checkpoint:
            print(f"âœ… è¿›åº¦: {int(progress_checkpoint * 100)}%", end="\r")
            progress_checkpoint += 0.1

    print("\nðŸŽ‰ è®¡ç®—å®Œæˆï¼")
    result_df = pd.DataFrame(results)
    final_df = result_df.merge(df_target[['DOI', 'Source Title']], on='DOI', how='left')
    
    return final_df, calc


def calculate_original_metrics(df):
    """åŽŸå§‹æ–¹æ³•ï¼šæ‰€æœ‰è®ºæ–‡å¹³å‡ D-index"""
    return (df.groupby('Source Title')
              .agg({'disruption_index': 'mean', 'DOI': 'count'})
              .rename(columns={'disruption_index': 'disruption_mean', 'DOI': 'paper_count'})
              .sort_values('disruption_mean', ascending=False)
              .reset_index())


def calculate_enhanced_metrics(df, top_k=10, volume_weight=0.4):
    """å¢žå¼ºæ–¹æ³•ï¼šTop-k å¹³å‡ + è§„æ¨¡åŠ æƒ"""
    valid = df.dropna(subset=['disruption_index'])
    grouped = valid.groupby('Source Title')
    
    records = []
    for journal, group in grouped:
        n_papers = len(group)
        k = min(top_k, n_papers)
        top_avg = group.nlargest(k, 'disruption_index')['disruption_index'].mean()
        log_n = np.log1p(n_papers)
        score = (1 - volume_weight) * top_avg + volume_weight * (top_avg / log_n)

        records.append({
            'Source Title': journal,
            'n_papers': n_papers,
            'top_k_mean': top_avg,
            'enhanced_disruption': score
        })
    
    return pd.DataFrame(records).sort_values('enhanced_disruption', ascending=False).reset_index(drop=True)


def visualize_journal_ranking(journal_metrics, top_n=None, title=None, value_col='disruption_mean'):
    """
    é€šç”¨æœŸåˆŠæŽ’åå¯è§†åŒ–ï¼ˆéœ€è¦è°ƒç”¨ plt.show() æ˜¾ç¤ºï¼‰
    """
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print("âš ï¸ matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        return

    data = journal_metrics.head(top_n) if top_n is not None else journal_metrics.copy()
    
    plt.figure(figsize=(14, max(8, len(data) * 0.4)))
    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(data)))

    bars = plt.barh(
        data['Source Title'],
        data[value_col],
        color=colors,
        alpha=0.8,
        edgecolor='black',
        linewidth=0.5,
        height=0.7
    )

    max_val = data[value_col].max()
    text_x = max_val * 1.08

    for bar, val in zip(bars, data[value_col]):
        plt.text(text_x, bar.get_y() + bar.get_height()/2,
                 f'{val:.4f}', ha='left', va='center', fontsize=10,
                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'))

    plt.xlabel("é¢ è¦†æ€§æŒ‡æ•°", fontsize=13, fontweight='bold')
    plt.ylabel("æœŸåˆŠåç§°", fontsize=13, fontweight='bold')
    plt.title(title or "æœŸåˆŠé¢ è¦†æ€§æŒ‡æ•°æŽ’å", fontsize=16, fontweight='bold', pad=20)

    ax = plt.gca()
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_linewidth(0.5)
    ax.spines['bottom'].set_linewidth(0.5)
    ax.grid(axis='x', linestyle='--', alpha=0.3, color='gray')
    ax.set_facecolor('#f8f9fa')
    plt.gcf().patch.set_facecolor('white')
    ax.invert_yaxis()
    plt.tight_layout()


def run_analysis(background_path=None, target_path=None, output_dir=None):
    """
    ä¸»æ‰§è¡Œå‡½æ•°ï¼šç«¯åˆ°ç«¯è¿è¡Œé¢ è¦†æ€§åˆ†æž
    
    è‡ªåŠ¨è¯†åˆ«é¡¹ç›®æ ¹ç›®å½•ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®ã€‚
    æ‰€æœ‰ç»“æžœè¾“å‡ºè‡³ outputs/disrupt/
    """
    # ========== 1. æŽ¨å¯¼é¡¹ç›®æ ¹ç›®å½•ï¼ˆå…³é”®ä¿®æ”¹ï¼šé€‚é… python_analysis/ ç›®å½•ï¼‰ ==========
    try:
        current_dir = os.path.dirname(__file__)  # å½“å‰æ–‡ä»¶ç›®å½•ï¼špython_analysis/
    except NameError:
        current_dir = os.getcwd()
    project_root = os.path.abspath(os.path.join(current_dir, '..'))  # ä¸Šä¸€çº§ï¼šæ ¹ç›®å½•

    print(f"é¡¹ç›®æ ¹ç›®å½•è¯†åˆ«ä¸º: {project_root}")

    # ========== 2. è®¾ç½®é»˜è®¤è·¯å¾„ ==========
    if background_path is None:
        background_path = os.path.join(project_root, 'data', 'raw', 'data_with_citing.csv')  # æ ¹ç›®å½•/data/
    if target_path is None:
        target_path = os.path.join(project_root, 'data', 'raw', 'top10_journals_data.csv')  # æ ¹ç›®å½•/data/
    if output_dir is None:
        output_dir = os.path.join(project_root, 'outputs', 'disrupt')  # æ ¹ç›®å½•/outputs/

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # ========== 3. åŠ è½½æ•°æ® ==========
    print("æ­£åœ¨åŠ è½½èƒŒæ™¯æ•°æ®...")
    df_all = pd.read_csv(background_path)
    print("æ­£åœ¨åŠ è½½ç›®æ ‡æ•°æ®...")
    df_top10 = pd.read_csv(target_path)

    # ========== 4. è®¡ç®—è®ºæ–‡çº§ D-index ==========
    paper_scores, calculator = calculate_paper_disruption_scores(df_all, df_top10)

    # ========== 5. ç”ŸæˆæœŸåˆŠçº§æŒ‡æ ‡ ==========
    original_metrics = calculate_original_metrics(paper_scores)
    enhanced_metrics = calculate_enhanced_metrics(paper_scores, top_k=10, volume_weight=0.4)

    # ========== 6. å¯¼å‡ºæ‰€æœ‰ç»“æžœ ==========
    # 6.1 å¼•æ–‡ç½‘ç»œ
    export_citation_network(calculator, paper_scores, 
                           output_file=os.path.join(output_dir, 'citation_network.json'))

    # 6.2 åŽŸå§‹æ–¹æ³•æŽ’å CSV
    orig_csv = os.path.join(output_dir, 'top10_original_ranking.csv')
    original_metrics.to_csv(orig_csv, index=False, encoding='utf-8-sig')
    print(f"åŽŸå§‹æ–¹æ³•æŽ’åå·²ä¿å­˜: {orig_csv}")

    # 6.3 å¢žå¼ºæ–¹æ³•æŽ’å CSV
    enh_csv = os.path.join(output_dir, 'top10_enhanced_ranking.csv')
    enhanced_metrics.to_csv(enh_csv, index=False, encoding='utf-8-sig')
    print(f"å¢žå¼ºæ–¹æ³•æŽ’åå·²ä¿å­˜: {enh_csv}")

    # 6.4 æœŸåˆŠåç§°åˆ—è¡¨ TXT
    txt_path = os.path.join(output_dir, 'top10_journals_list.txt')
    with open(txt_path, 'w', encoding='utf-8') as f:
        for journal in original_metrics['Source Title']:
            f.write(f"{journal}\n")
    print(f"æœŸåˆŠåˆ—è¡¨å·²ä¿å­˜: {txt_path}")

    # ========== 7. å¯è§†åŒ– ==========
    try:
        visualize_journal_ranking(
            original_metrics,
            top_n=10,
            title="ã€æ–¹æ³•ä¸€ã€‘æœŸåˆŠå¹³å‡é¢ è¦†æ€§æŽ’å",
            value_col='disruption_mean'
        )
        plt.show()

        visualize_journal_ranking(
            enhanced_metrics,
            top_n=10,
            title="ã€æ–¹æ³•äºŒã€‘Top10é«˜å½±å“åŠ›è®ºæ–‡+è§„æ¨¡åŠ æƒ",
            value_col='enhanced_disruption'
        )
        plt.show()
    except:
        print("âš ï¸ å¯è§†åŒ–æ˜¾ç¤ºå¤±è´¥ï¼ˆå¯èƒ½çŽ¯å¢ƒä¸æ”¯æŒï¼‰ï¼Œä½†æ•°æ®å·²æ­£å¸¸å¯¼å‡ºã€‚")

    # ========== 8. è¿”å›žç»“æžœ ==========
    return {
        'paper_scores': paper_scores,
        'original_metrics': original_metrics,
        'enhanced_metrics': enhanced_metrics,
        'calculator': calculator
    }

# ========================
# å¦‚æžœç›´æŽ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œåˆ™æ‰§è¡Œä¸»æµç¨‹
# ========================
if __name__ == "__main__":
    run_analysis()
>>>>>>> 325a45d1acde271d3e82f31155b95d174bbec114
